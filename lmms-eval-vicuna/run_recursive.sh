CUDA_VISIBLE_DEVICES=3 python3 -m accelerate.commands.launch \
    --num_processes=1 \
    --main_process_port 29882 \
    -m lmms_eval \
    --model llava \
    --model_args pretrained="liuhaotian/llava-v1.6-vicuna-7b" \
    --tasks mme \
    --batch_size 1 \
    --log_samples \
    --log_samples_suffix llava_v1.6_pope \
    --output_path ./logs/ \
    --generation_type recursion \
    --fix_grid 2x2 \
    --attention_thresholding_type layer_mean_topk \
    --attention_threshold "[1.0,0.7,0.1]" \
    --positional_embedding_type bilinear \
    --remove_unpadding True \
    --attn_norm None \
    --stages "-2" "-1" "0" "1" \
    --verbosity DEBUG \
    --square 3 \
    --wandb_args "project=llava1.6_recursive_eval_1230,entity=VLM_Hallucination_Woohyeon,name=10_7_1_bilinear_s3_pad" \
    --contrastive_alphas "0.0" "0.0" "0.0" \
    --save_output True \
    --output_csv_path "./generation_output_mme_10_7_1_bilinear_s3_pad.csv" \

CUDA_VISIBLE_DEVICES=3 python3 -m accelerate.commands.launch \
    --num_processes=1 \
    --main_process_port 29882 \
    -m lmms_eval \
    --model llava \
    --model_args pretrained="liuhaotian/llava-v1.6-vicuna-7b" \
    --tasks mme \
    --batch_size 1 \
    --log_samples \
    --log_samples_suffix llava_v1.6_pope \
    --output_path ./logs/ \
    --generation_type recursion \
    --fix_grid 2x2 \
    --attention_thresholding_type layer_mean_topk \
    --attention_threshold "[1.0,0.7,0.1]" \
    --positional_embedding_type reduced \
    --remove_unpadding True \
    --attn_norm None \
    --stages "-2" "-1" "0" "1" \
    --verbosity DEBUG \
    --square 3 \
    --wandb_args "project=llava1.6_recursive_eval_1230,entity=VLM_Hallucination_Woohyeon,name=10_7_1_reduced_s3_pad" \
    --contrastive_alphas "0.0" "0.0" "0.0" \
    --save_output True \
    --output_csv_path "./generation_output_mme_10_7_1_reduced_s3_pad.csv" \

CUDA_VISIBLE_DEVICES=3 python3 -m accelerate.commands.launch \
    --num_processes=1 \
    --main_process_port 29882 \
    -m lmms_eval \
    --model llava \
    --model_args pretrained="liuhaotian/llava-v1.6-vicuna-7b" \
    --tasks pope_pop \
    --batch_size 1 \
    --log_samples \
    --log_samples_suffix llava_v1.6_pope \
    --output_path ./logs/ \
    --generation_type recursion \
    --fix_grid 2x2 \
    --attention_thresholding_type layer_mean_topk \
    --attention_threshold "[1.0,1.0,0.3]" \
    --positional_embedding_type reduced \
    --remove_unpadding True \
    --attn_norm None \
    --stages "-2" "-1" "0" "1" \
    --verbosity DEBUG \
    --square 3 \
    --wandb_args "project=llava1.6_recursive_eval_1230,entity=VLM_Hallucination_Woohyeon,name=10_10_3_reduced_s3_pad" \
    --contrastive_alphas "0.0" "0.0" "0.0" \
    --save_output True \
    --output_csv_path "./generation_output_pope_pop_10_10_3_reduced_s3_pad.csv" \

CUDA_VISIBLE_DEVICES=3 python3 -m accelerate.commands.launch \
    --num_processes=1 \
    --main_process_port 29882 \
    -m lmms_eval \
    --model llava \
    --model_args pretrained="liuhaotian/llava-v1.6-vicuna-7b" \
    --tasks pope_gqa_pop \
    --batch_size 1 \
    --log_samples \
    --log_samples_suffix llava_v1.6_pope \
    --output_path ./logs/ \
    --generation_type recursion \
    --fix_grid 2x2 \
    --attention_thresholding_type layer_mean_topk \
    --attention_threshold "[1.0,1.0,0.3]" \
    --positional_embedding_type reduced \
    --remove_unpadding True \
    --attn_norm None \
    --stages "-2" "-1" "0" "1" \
    --verbosity DEBUG \
    --square 3 \
    --wandb_args "project=llava1.6_recursive_eval_1230,entity=VLM_Hallucination_Woohyeon,name=10_10_3_reduced_s3_pad" \
    --contrastive_alphas "0.0" "0.0" "0.0" \
    --save_output True \
    --output_csv_path "./generation_output_pope_gqa_pop_10_10_3_reduced_s3_pad.csv" \

CUDA_VISIBLE_DEVICES=3 python3 -m accelerate.commands.launch \
    --num_processes=1 \
    --main_process_port 29882 \
    -m lmms_eval \
    --model llava \
    --model_args pretrained="liuhaotian/llava-v1.6-vicuna-7b" \
    --tasks pope_aokvqa_pop \
    --batch_size 1 \
    --log_samples \
    --log_samples_suffix llava_v1.6_pope \
    --output_path ./logs/ \
    --generation_type recursion \
    --fix_grid 2x2 \
    --attention_thresholding_type layer_mean_topk \
    --attention_threshold "[1.0,1.0,0.3]" \
    --positional_embedding_type reduced \
    --remove_unpadding True \
    --attn_norm None \
    --stages "-2" "-1" "0" "1" \
    --verbosity DEBUG \
    --square 3 \
    --wandb_args "project=llava1.6_recursive_eval_1230,entity=VLM_Hallucination_Woohyeon,name=10_10_3_reduced_s3_pad" \
    --contrastive_alphas "0.0" "0.0" "0.0" \
    --save_output True \
    --output_csv_path "./generation_output_pope_aokvqa_pop_10_10_3_reduced_s3_pad.csv" \


