The following values were not passed to `accelerate launch` and had defaults used instead:
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--num_machines` was set to a value of `1`
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
wandb: Currently logged in as: wjk9904 (VLM_Hallucination_Woohyeon). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: wjk9904 (VLM_Hallucination_Woohyeon). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: wjk9904 (VLM_Hallucination_Woohyeon). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: wjk9904 (VLM_Hallucination_Woohyeon). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.19.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.5
wandb: Run data is saved locally in /workspace/vlm/lmms-reverse/wandb/run-20241214_174222-rxni6ncf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run reverse1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/VLM_Hallucination_Woohyeon/llava1.6_recursive_eval_1126
wandb: üöÄ View run at https://wandb.ai/VLM_Hallucination_Woohyeon/llava1.6_recursive_eval_1126/runs/rxni6ncf/workspace
wandb: wandb version 0.19.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.5
wandb: Run data is saved locally in /workspace/vlm/lmms-reverse/wandb/run-20241214_174222-ssdmc9x9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run reverse1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/VLM_Hallucination_Woohyeon/llava1.6_recursive_eval_1126
wandb: üöÄ View run at https://wandb.ai/VLM_Hallucination_Woohyeon/llava1.6_recursive_eval_1126/runs/ssdmc9x9/workspace
wandb: wandb version 0.19.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.5
wandb: Run data is saved locally in /workspace/vlm/lmms-reverse/wandb/run-20241214_174222-vq3qd87z
wandb: Run `wandb offline` to turn off syncing.
[32m2024-12-14 17:42:24.741[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate[0m:[36m420[0m - [1mVerbosity set to DEBUG[0m
wandb: Syncing run reverse1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/VLM_Hallucination_Woohyeon/llava1.6_recursive_eval_1126
wandb: üöÄ View run at https://wandb.ai/VLM_Hallucination_Woohyeon/llava1.6_recursive_eval_1126/runs/vq3qd87z/workspace
wandb: wandb version 0.19.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.5
wandb: Run data is saved locally in /workspace/vlm/lmms-reverse/wandb/run-20241214_174222-8hotq4ss
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run reverse1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/VLM_Hallucination_Woohyeon/llava1.6_recursive_eval_1126
wandb: üöÄ View run at https://wandb.ai/VLM_Hallucination_Woohyeon/llava1.6_recursive_eval_1126/runs/8hotq4ss/workspace
[32m2024-12-14 17:42:24.829[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate[0m:[36m420[0m - [1mVerbosity set to DEBUG[0m
[32m2024-12-14 17:42:24.836[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate[0m:[36m420[0m - [1mVerbosity set to DEBUG[0m
[32m2024-12-14 17:42:24.865[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate[0m:[36m420[0m - [1mVerbosity set to DEBUG[0m
[32m2024-12-14 17:42:31.563[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.tasks[0m:[36m_get_task_and_group[0m:[36m452[0m - [34m[1m`group` and `group_alias` keys in tasks' configs will no longer be used in the next release of lmms-eval. `tag` will be used to allow to call a collection of tasks just like `group`. `group` will be removed in order to not cause confusion with the new ConfigurableGroup which will be the offical way to create groups with addition of group-wide configuations.[0m
[32m2024-12-14 17:42:32.353[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m503[0m - [1mEvaluation tracker args: {'output_path': './logs/'}[0m
[32m2024-12-14 17:42:32.354[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m592[0m - [1mSelected Tasks: ['pope_pop', 'vqav2_val_lite'][0m
[32m2024-12-14 17:42:32.358[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36msimple_evaluate[0m:[36m155[0m - [1mSetting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234[0m
[32m2024-12-14 17:42:32.421[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.tasks[0m:[36m_get_task_and_group[0m:[36m452[0m - [34m[1m`group` and `group_alias` keys in tasks' configs will no longer be used in the next release of lmms-eval. `tag` will be used to allow to call a collection of tasks just like `group`. `group` will be removed in order to not cause confusion with the new ConfigurableGroup which will be the offical way to create groups with addition of group-wide configuations.[0m
[32m2024-12-14 17:42:32.496[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.tasks[0m:[36m_get_task_and_group[0m:[36m452[0m - [34m[1m`group` and `group_alias` keys in tasks' configs will no longer be used in the next release of lmms-eval. `tag` will be used to allow to call a collection of tasks just like `group`. `group` will be removed in order to not cause confusion with the new ConfigurableGroup which will be the offical way to create groups with addition of group-wide configuations.[0m
[32m2024-12-14 17:42:32.613[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.tasks[0m:[36m_get_task_and_group[0m:[36m452[0m - [34m[1m`group` and `group_alias` keys in tasks' configs will no longer be used in the next release of lmms-eval. `tag` will be used to allow to call a collection of tasks just like `group`. `group` will be removed in order to not cause confusion with the new ConfigurableGroup which will be the offical way to create groups with addition of group-wide configuations.[0m
[32m2024-12-14 17:42:33.167[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m503[0m - [1mEvaluation tracker args: {'output_path': './logs/'}[0m
[32m2024-12-14 17:42:33.168[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m592[0m - [1mSelected Tasks: ['pope_pop', 'vqav2_val_lite'][0m
[32m2024-12-14 17:42:33.171[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36msimple_evaluate[0m:[36m155[0m - [1mSetting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234[0m
[32m2024-12-14 17:42:33.248[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m503[0m - [1mEvaluation tracker args: {'output_path': './logs/'}[0m
[32m2024-12-14 17:42:33.249[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m592[0m - [1mSelected Tasks: ['pope_pop', 'vqav2_val_lite'][0m
[32m2024-12-14 17:42:33.253[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36msimple_evaluate[0m:[36m155[0m - [1mSetting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234[0m
[32m2024-12-14 17:42:33.365[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m503[0m - [1mEvaluation tracker args: {'output_path': './logs/'}[0m
[32m2024-12-14 17:42:33.366[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m592[0m - [1mSelected Tasks: ['pope_pop', 'vqav2_val_lite'][0m
[32m2024-12-14 17:42:33.370[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36msimple_evaluate[0m:[36m155[0m - [1mSetting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234[0m
initialize llava model with modification
OpenCLIP not installed
initialize llava model with modification
initialize llava model with modification
initialize llava model with modification
self.merging= None
model_name: llava-v1.6-vicuna-7b
Rank 0:  Loaded LLaVA model: liuhaotian/llava-v1.6-vicuna-7b
loding from here
OpenCLIP not installed
OpenCLIP not installed
OpenCLIP not installed
self.merging= None
model_name: llava-v1.6-vicuna-7b
loding from here
self.merging= Noneself.merging= None
model_name: llava-v1.6-vicuna-7b

model_name: llava-v1.6-vicuna-7b
loding from hereloding from here

You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
Rank 0:  Loading vision tower: openai/clip-vit-large-patch14-336
You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:05<00:10,  5.49s/it]Loading checkpoint shards:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:06<00:12,  6.04s/it]Loading checkpoint shards:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:06<00:13,  6.74s/it]Loading checkpoint shards:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:05<00:11,  5.99s/it]Loading checkpoint shards:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:11<00:05,  5.85s/it]Loading checkpoint shards:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:11<00:05,  5.66s/it]Loading checkpoint shards:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:12<00:06,  6.06s/it]Loading checkpoint shards:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:11<00:05,  5.99s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:17<00:00,  5.64s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:17<00:00,  5.82s/it]
Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:16<00:00,  5.46s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:16<00:00,  5.50s/it]
Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:17<00:00,  5.66s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:17<00:00,  5.73s/it]
Rank 0:  Model Class: LlavaLlamaForCausalLM
device: cuda:0
generation_type: recursiondevice: cuda:0

fix_grid: 2x2generation_type: recursion

attention_thresholding_type: layer_mean_topkfix_grid: 2x2
attention_thresholding_type: layer_mean_topk

attention_norm: Noneattention_norm: None

attention_threshold: 0.9attention_threshold: 0.9

detection_strategy: Nonedetection_strategy: None

detection_threshold: 0.8detection_threshold: 0.8

save_output: Falsesave_output: False
save_output_csv_path: generation_output.csv

save_output_csv_path: generation_output.csvtarget_token_selection_strategy: first

target_token_selection_strategy: firststages: [1, 0, -1, -2]

stages: [1, 0, -1, -2]positional_embedding_type: bilinear_interpolation

positional_embedding_type: bilinear_interpolationvisualize_heatmap: False

square: 1
visualize_heatmap: Falseremove unpadding=True, change to 'spatial'

square: 1
remove unpadding=True, change to 'spatial'change positional embedding to bilinear_interpolation

change positional embedding to bilinear_interpolation
device: cuda:0
generation_type: recursion
fix_grid: 2x2
attention_thresholding_type: layer_mean_topk
attention_norm: None
attention_threshold: 0.9
detection_strategy: None
detection_threshold: 0.8
save_output: False
save_output_csv_path: generation_output.csv
target_token_selection_strategy: first
stages: [1, 0, -1, -2]
positional_embedding_type: bilinear_interpolation
visualize_heatmap: False
square: 1
remove unpadding=True, change to 'spatial'
change positional embedding to bilinear_interpolation
Bilienar interpolation embedding type.
Bilienar interpolation embedding type.
Bilienar interpolation embedding type.
[32m2024-12-14 17:43:02.679[0m | [1mINFO    [0m | [36mlmms_eval.models.llava[0m:[36m__init__[0m:[36m306[0m - [1mUsing 4 devices with data parallelism[0m
[32m2024-12-14 17:43:02.680[0m | [1mINFO    [0m | [36mlmms_eval.evaluator_utils[0m:[36mfrom_taskdict[0m:[36m91[0m - [1mNo metadata found in task config for vqav2_val_lite, using default n_shot=0[0m
[32m2024-12-14 17:43:02.681[0m | [1mINFO    [0m | [36mlmms_eval.evaluator_utils[0m:[36mfrom_taskdict[0m:[36m91[0m - [1mNo metadata found in task config for pope_pop, using default n_shot=0[0m
[32m2024-12-14 17:43:02.682[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.caching.cache[0m:[36mload_from_cache[0m:[36m33[0m - [34m[1mrequests-vqav2_val_lite-0shot-rank0-world_size4-tokenizer is not cached, generating...[0m
[32m2024-12-14 17:43:02.683[0m | [1mINFO    [0m | [36mlmms_eval.api.task[0m:[36mbuild_all_requests[0m:[36m425[0m - [1mBuilding contexts for vqav2_val_lite on rank 0...[0m
Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:17<00:00,  5.77s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:17<00:00,  5.83s/it]
Bilienar interpolation embedding type.
device: cuda:0
generation_type: recursion
fix_grid: 2x2
attention_thresholding_type: layer_mean_topk
attention_norm: None
attention_threshold: 0.9
detection_strategy: None
detection_threshold: 0.8
save_output: False
save_output_csv_path: generation_output.csv
target_token_selection_strategy: first
stages: [1, 0, -1, -2]
positional_embedding_type: bilinear_interpolation
visualize_heatmap: False
square: 1
remove unpadding=True, change to 'spatial'
change positional embedding to bilinear_interpolation
Bilienar interpolation embedding type.
Bilienar interpolation embedding type.
Bilienar interpolation embedding type.
  0%|          | 0/125 [00:00<?, ?it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [00:00<00:00, 101390.06it/s]
[32m2024-12-14 17:43:03.958[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m455[0m - [34m[1mTask: vqav2_val_lite; number of requests on this rank: 125[0m
Bilienar interpolation embedding type.
[32m2024-12-14 17:43:05.634[0m | [1mINFO    [0m | [36mlmms_eval.evaluator_utils[0m:[36mfrom_taskdict[0m:[36m91[0m - [1mNo metadata found in task config for vqav2_val_lite, using default n_shot=0[0m
[32m2024-12-14 17:43:05.635[0m | [1mINFO    [0m | [36mlmms_eval.evaluator_utils[0m:[36mfrom_taskdict[0m:[36m91[0m - [1mNo metadata found in task config for pope_pop, using default n_shot=0[0m
[32m2024-12-14 17:43:05.636[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.caching.cache[0m:[36mload_from_cache[0m:[36m33[0m - [34m[1mrequests-vqav2_val_lite-0shot-rank2-world_size4-tokenizer is not cached, generating...[0m
[32m2024-12-14 17:43:05.636[0m | [1mINFO    [0m | [36mlmms_eval.api.task[0m:[36mbuild_all_requests[0m:[36m425[0m - [1mBuilding contexts for vqav2_val_lite on rank 2...[0m
[32m2024-12-14 17:43:05.903[0m | [1mINFO    [0m | [36mlmms_eval.evaluator_utils[0m:[36mfrom_taskdict[0m:[36m91[0m - [1mNo metadata found in task config for vqav2_val_lite, using default n_shot=0[0m
[32m2024-12-14 17:43:05.904[0m | [1mINFO    [0m | [36mlmms_eval.evaluator_utils[0m:[36mfrom_taskdict[0m:[36m91[0m - [1mNo metadata found in task config for pope_pop, using default n_shot=0[0m
[32m2024-12-14 17:43:05.905[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.caching.cache[0m:[36mload_from_cache[0m:[36m33[0m - [34m[1mrequests-vqav2_val_lite-0shot-rank3-world_size4-tokenizer is not cached, generating...[0m
[32m2024-12-14 17:43:05.906[0m | [1mINFO    [0m | [36mlmms_eval.api.task[0m:[36mbuild_all_requests[0m:[36m425[0m - [1mBuilding contexts for vqav2_val_lite on rank 3...[0m
[32m2024-12-14 17:43:06.759[0m | [1mINFO    [0m | [36mlmms_eval.evaluator_utils[0m:[36mfrom_taskdict[0m:[36m91[0m - [1mNo metadata found in task config for vqav2_val_lite, using default n_shot=0[0m
[32m2024-12-14 17:43:06.761[0m | [1mINFO    [0m | [36mlmms_eval.evaluator_utils[0m:[36mfrom_taskdict[0m:[36m91[0m - [1mNo metadata found in task config for pope_pop, using default n_shot=0[0m
[32m2024-12-14 17:43:06.762[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.caching.cache[0m:[36mload_from_cache[0m:[36m33[0m - [34m[1mrequests-vqav2_val_lite-0shot-rank1-world_size4-tokenizer is not cached, generating...[0m
[32m2024-12-14 17:43:06.762[0m | [1mINFO    [0m | [36mlmms_eval.api.task[0m:[36mbuild_all_requests[0m:[36m425[0m - [1mBuilding contexts for vqav2_val_lite on rank 1...[0m
  0%|          | 0/125 [00:00<?, ?it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [00:00<00:00, 105831.25it/s]
[32m2024-12-14 17:43:06.931[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m455[0m - [34m[1mTask: vqav2_val_lite; number of requests on this rank: 125[0m
  0%|          | 0/125 [00:00<?, ?it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [00:00<00:00, 93622.86it/s]
[32m2024-12-14 17:43:07.132[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m455[0m - [34m[1mTask: vqav2_val_lite; number of requests on this rank: 125[0m
  0%|          | 0/125 [00:00<?, ?it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [00:00<00:00, 95273.12it/s]
[32m2024-12-14 17:43:07.991[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m455[0m - [34m[1mTask: vqav2_val_lite; number of requests on this rank: 125[0m
[32m2024-12-14 17:43:17.740[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.caching.cache[0m:[36mload_from_cache[0m:[36m33[0m - [34m[1mrequests-pope_pop-0shot-rank3-world_size4-tokenizer is not cached, generating...[0m
[32m2024-12-14 17:43:17.740[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.caching.cache[0m:[36mload_from_cache[0m:[36m33[0m - [34m[1mrequests-pope_pop-0shot-rank0-world_size4-tokenizer is not cached, generating...[0m
[32m2024-12-14 17:43:17.740[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.caching.cache[0m:[36mload_from_cache[0m:[36m33[0m - [34m[1mrequests-pope_pop-0shot-rank2-world_size4-tokenizer is not cached, generating...[0m
[32m2024-12-14 17:43:17.740[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.caching.cache[0m:[36mload_from_cache[0m:[36m33[0m - [34m[1mrequests-pope_pop-0shot-rank1-world_size4-tokenizer is not cached, generating...[0m
[32m2024-12-14 17:43:17.741[0m | [1mINFO    [0m | [36mlmms_eval.api.task[0m:[36mbuild_all_requests[0m:[36m425[0m - [1mBuilding contexts for pope_pop on rank 3...[0m
[32m2024-12-14 17:43:17.742[0m | [1mINFO    [0m | [36mlmms_eval.api.task[0m:[36mbuild_all_requests[0m:[36m425[0m - [1mBuilding contexts for pope_pop on rank 1...[0m
[32m2024-12-14 17:43:17.742[0m | [1mINFO    [0m | [36mlmms_eval.api.task[0m:[36mbuild_all_requests[0m:[36m425[0m - [1mBuilding contexts for pope_pop on rank 0...[0m
[32m2024-12-14 17:43:17.742[0m | [1mINFO    [0m | [36mlmms_eval.api.task[0m:[36mbuild_all_requests[0m:[36m425[0m - [1mBuilding contexts for pope_pop on rank 2...[0m
  0%|          | 0/750 [00:00<?, ?it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 750/750 [00:00<00:00, 104318.62it/s]
[32m2024-12-14 17:43:25.676[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m455[0m - [34m[1mTask: pope_pop; number of requests on this rank: 750[0m
  0%|          | 0/750 [00:00<?, ?it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 750/750 [00:00<00:00, 93173.63it/s]
  0%|          | 0/750 [00:00<?, ?it/s][32m2024-12-14 17:43:25.808[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m455[0m - [34m[1mTask: pope_pop; number of requests on this rank: 750[0m
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 750/750 [00:00<00:00, 103406.46it/s]
[32m2024-12-14 17:43:25.818[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m455[0m - [34m[1mTask: pope_pop; number of requests on this rank: 750[0m
  0%|          | 0/750 [00:00<?, ?it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 750/750 [00:00<00:00, 100970.25it/s]
[32m2024-12-14 17:43:25.944[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m455[0m - [34m[1mTask: pope_pop; number of requests on this rank: 750[0m
[32m2024-12-14 17:43:25.946[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m476[0m - [1mRunning generate_until requests[0m
[32m2024-12-14 17:43:25.946[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m476[0m - [1mRunning generate_until requests[0m
[32m2024-12-14 17:43:25.946[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m476[0m - [1mRunning generate_until requests[0m
[32m2024-12-14 17:43:25.946[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m476[0m - [1mRunning generate_until requests[0m
Model Responding:   0%|          | 0/875 [00:00<?, ?it/s]CLIPModel is using CLIPSdpaAttention, but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation="eager"` when loading the model.
CLIPModel is using CLIPSdpaAttention, but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation="eager"` when loading the model.
CLIPModel is using CLIPSdpaAttention, but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation="eager"` when loading the model.
CLIPModel is using CLIPSdpaAttention, but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation="eager"` when loading the model.
LlamaModel is using LlamaSdpaAttention, but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation="eager"` when loading the model.
LlamaModel is using LlamaSdpaAttention, but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation="eager"` when loading the model.
LlamaModel is using LlamaSdpaAttention, but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation="eager"` when loading the model.
LlamaModel is using LlamaSdpaAttention, but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation="eager"` when loading the model.
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
Model Responding:   0%|          | 1/875 [00:11<2:45:14, 11.34s/it]Model Responding:   0%|          | 2/875 [00:21<2:36:27, 10.75s/it]Model Responding:   0%|          | 3/875 [00:31<2:30:20, 10.34s/it]Model Responding:   0%|          | 4/875 [00:41<2:26:22, 10.08s/it]Model Responding:   1%|          | 5/875 [00:50<2:23:01,  9.86s/it]Model Responding:   1%|          | 6/875 [00:59<2:18:19,  9.55s/it]Model Responding:   1%|          | 7/875 [01:09<2:18:45,  9.59s/it]Model Responding:   1%|          | 8/875 [01:18<2:16:57,  9.48s/it]Model Responding:   1%|          | 9/875 [01:27<2:14:45,  9.34s/it]Model Responding:   1%|          | 10/875 [01:37<2:16:20,  9.46s/it]Model Responding:   1%|‚ñè         | 11/875 [01:47<2:17:30,  9.55s/it]Model Responding:   1%|‚ñè         | 12/875 [01:56<2:17:19,  9.55s/it]Model Responding:   1%|‚ñè         | 13/875 [02:06<2:17:51,  9.60s/it]Model Responding:   2%|‚ñè         | 14/875 [02:15<2:17:00,  9.55s/it]Model Responding:   2%|‚ñè         | 15/875 [02:25<2:18:51,  9.69s/it]Model Responding:   2%|‚ñè         | 16/875 [02:35<2:20:35,  9.82s/it]Model Responding:   2%|‚ñè         | 17/875 [02:46<2:22:10,  9.94s/it]Model Responding:   2%|‚ñè         | 18/875 [02:55<2:20:17,  9.82s/it]Model Responding:   2%|‚ñè         | 19/875 [03:05<2:18:05,  9.68s/it]Model Responding:   2%|‚ñè         | 20/875 [03:14<2:16:36,  9.59s/it]Model Responding:   2%|‚ñè         | 21/875 [03:23<2:15:24,  9.51s/it]Model Responding:   3%|‚ñé         | 22/875 [03:32<2:12:34,  9.33s/it]Model Responding:   3%|‚ñé         | 23/875 [03:42<2:13:55,  9.43s/it]Model Responding:   3%|‚ñé         | 24/875 [03:51<2:14:45,  9.50s/it]Model Responding:   3%|‚ñé         | 25/875 [04:01<2:15:33,  9.57s/it]Model Responding:   3%|‚ñé         | 26/875 [04:10<2:13:35,  9.44s/it]Model Responding:   3%|‚ñé         | 27/875 [04:19<2:12:00,  9.34s/it]Model Responding:   3%|‚ñé         | 28/875 [04:29<2:10:58,  9.28s/it]Model Responding:   3%|‚ñé         | 29/875 [04:38<2:11:38,  9.34s/it]Model Responding:   3%|‚ñé         | 30/875 [04:48<2:13:50,  9.50s/it]Model Responding:   4%|‚ñé         | 31/875 [04:57<2:13:11,  9.47s/it]Model Responding:   4%|‚ñé         | 32/875 [05:08<2:18:27,  9.85s/it]Model Responding:   4%|‚ñç         | 33/875 [05:18<2:18:35,  9.88s/it]Model Responding:   4%|‚ñç         | 34/875 [05:28<2:18:46,  9.90s/it]Model Responding:   4%|‚ñç         | 35/875 [05:38<2:17:22,  9.81s/it]Model Responding:   4%|‚ñç         | 36/875 [05:47<2:15:19,  9.68s/it]Model Responding:   4%|‚ñç         | 37/875 [05:57<2:16:18,  9.76s/it]Model Responding:   4%|‚ñç         | 38/875 [06:07<2:15:46,  9.73s/it]Model Responding:   4%|‚ñç         | 39/875 [06:17<2:17:50,  9.89s/it]Model Responding:   5%|‚ñç         | 40/875 [06:26<2:16:20,  9.80s/it]Model Responding:   5%|‚ñç         | 41/875 [06:36<2:15:28,  9.75s/it]Model Responding:   5%|‚ñç         | 42/875 [06:45<2:13:01,  9.58s/it]Model Responding:   5%|‚ñç         | 43/875 [06:55<2:14:18,  9.69s/it]Model Responding:   5%|‚ñå         | 44/875 [07:04<2:12:34,  9.57s/it]W1214 17:50:31.297000 2037759 site-packages/torch/distributed/elastic/agent/server/api.py:704] Received Signals.SIGHUP death signal, shutting down workers
W1214 17:50:31.298000 2037759 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 2038024 closing signal SIGHUP
W1214 17:50:31.298000 2037759 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 2038026 closing signal SIGHUP
W1214 17:50:31.298000 2037759 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 2038030 closing signal SIGHUP
W1214 17:50:31.299000 2037759 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 2038031 closing signal SIGHUP
Model Responding:   5%|‚ñå         | 45/875 [07:14<2:13:53,  9.68s/it]Model Responding:   5%|‚ñå         | 46/875 [07:23<2:10:45,  9.46s/it]Model Responding:   5%|‚ñå         | 47/875 [07:32<2:06:28,  9.16s/it]W1214 17:51:01.299000 2037759 site-packages/torch/distributed/elastic/multiprocessing/api.py:916] Unable to shutdown process 2038024 via Signals.SIGHUP, forcefully exiting via Signals.SIGKILL
W1214 17:51:01.838000 2037759 site-packages/torch/distributed/elastic/multiprocessing/api.py:916] Unable to shutdown process 2038026 via Signals.SIGHUP, forcefully exiting via Signals.SIGKILL
W1214 17:51:02.472000 2037759 site-packages/torch/distributed/elastic/multiprocessing/api.py:916] Unable to shutdown process 2038030 via Signals.SIGHUP, forcefully exiting via Signals.SIGKILL
W1214 17:51:03.088000 2037759 site-packages/torch/distributed/elastic/multiprocessing/api.py:916] Unable to shutdown process 2038031 via Signals.SIGHUP, forcefully exiting via Signals.SIGKILL
Traceback (most recent call last):
  File "/root/miniconda3/envs/wh_reverse/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/root/miniconda3/envs/wh_reverse/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/root/miniconda3/envs/wh_reverse/lib/python3.10/site-packages/accelerate/commands/launch.py", line 1178, in <module>
    main()
  File "/root/miniconda3/envs/wh_reverse/lib/python3.10/site-packages/accelerate/commands/launch.py", line 1174, in main
    launch_command(args)
  File "/root/miniconda3/envs/wh_reverse/lib/python3.10/site-packages/accelerate/commands/launch.py", line 1159, in launch_command
    multi_gpu_launcher(args)
  File "/root/miniconda3/envs/wh_reverse/lib/python3.10/site-packages/accelerate/commands/launch.py", line 793, in multi_gpu_launcher
    distrib_run.run(args)
  File "/root/miniconda3/envs/wh_reverse/lib/python3.10/site-packages/torch/distributed/run.py", line 910, in run
    elastic_launch(
  File "/root/miniconda3/envs/wh_reverse/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 138, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/root/miniconda3/envs/wh_reverse/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 260, in launch_agent
    result = agent.run()
  File "/root/miniconda3/envs/wh_reverse/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py", line 137, in wrapper
    result = f(*args, **kwargs)
  File "/root/miniconda3/envs/wh_reverse/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py", line 696, in run
    result = self._invoke_run(role)
  File "/root/miniconda3/envs/wh_reverse/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py", line 855, in _invoke_run
    time.sleep(monitor_interval)
  File "/root/miniconda3/envs/wh_reverse/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 84, in _terminate_process_handler
    raise SignalException(f"Process {os.getpid()} got signal: {sigval}", sigval=sigval)
torch.distributed.elastic.multiprocessing.api.SignalException: Process 2037759 got signal: 1
The following values were not passed to `accelerate launch` and had defaults used instead:
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--num_machines` was set to a value of `1`
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
wandb: Currently logged in as: wjk9904 (VLM_Hallucination_Woohyeon). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: wjk9904 (VLM_Hallucination_Woohyeon). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: wjk9904 (VLM_Hallucination_Woohyeon). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: wjk9904 (VLM_Hallucination_Woohyeon). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.19.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.5
wandb: Run data is saved locally in /workspace/vlm/lmms-reverse/wandb/run-20241214_175110-e9mmayzd
wandb: Run `wandb offline` to turn off syncing.
wandb: wandb version 0.19.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.5
wandb: Run data is saved locally in /workspace/vlm/lmms-reverse/wandb/run-20241214_175110-8qtv767e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run reverse2
wandb: ‚≠êÔ∏è View project at https://wandb.ai/VLM_Hallucination_Woohyeon/llava1.6_recursive_eval_1126
wandb: üöÄ View run at https://wandb.ai/VLM_Hallucination_Woohyeon/llava1.6_recursive_eval_1126/runs/e9mmayzd/workspace
wandb: Syncing run reverse2
wandb: ‚≠êÔ∏è View project at https://wandb.ai/VLM_Hallucination_Woohyeon/llava1.6_recursive_eval_1126
wandb: üöÄ View run at https://wandb.ai/VLM_Hallucination_Woohyeon/llava1.6_recursive_eval_1126/runs/8qtv767e/workspace
wandb: wandb version 0.19.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.5
wandb: Run data is saved locally in /workspace/vlm/lmms-reverse/wandb/run-20241214_175110-v101oiat
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run reverse2
wandb: ‚≠êÔ∏è View project at https://wandb.ai/VLM_Hallucination_Woohyeon/llava1.6_recursive_eval_1126
wandb: üöÄ View run at https://wandb.ai/VLM_Hallucination_Woohyeon/llava1.6_recursive_eval_1126/runs/v101oiat/workspace
[32m2024-12-14 17:51:13.179[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate[0m:[36m420[0m - [1mVerbosity set to DEBUG[0m
[32m2024-12-14 17:51:13.180[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate[0m:[36m420[0m - [1mVerbosity set to DEBUG[0m
[32m2024-12-14 17:51:13.198[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate[0m:[36m420[0m - [1mVerbosity set to DEBUG[0m
wandb: wandb version 0.19.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.5
wandb: Run data is saved locally in /workspace/vlm/lmms-reverse/wandb/run-20241214_175110-ki9kglb2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run reverse2
wandb: ‚≠êÔ∏è View project at https://wandb.ai/VLM_Hallucination_Woohyeon/llava1.6_recursive_eval_1126
wandb: üöÄ View run at https://wandb.ai/VLM_Hallucination_Woohyeon/llava1.6_recursive_eval_1126/runs/ki9kglb2/workspace
[32m2024-12-14 17:51:13.312[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate[0m:[36m420[0m - [1mVerbosity set to DEBUG[0m
[32m2024-12-14 17:51:19.639[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.tasks[0m:[36m_get_task_and_group[0m:[36m452[0m - [34m[1m`group` and `group_alias` keys in tasks' configs will no longer be used in the next release of lmms-eval. `tag` will be used to allow to call a collection of tasks just like `group`. `group` will be removed in order to not cause confusion with the new ConfigurableGroup which will be the offical way to create groups with addition of group-wide configuations.[0m
[32m2024-12-14 17:51:20.231[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.tasks[0m:[36m_get_task_and_group[0m:[36m452[0m - [34m[1m`group` and `group_alias` keys in tasks' configs will no longer be used in the next release of lmms-eval. `tag` will be used to allow to call a collection of tasks just like `group`. `group` will be removed in order to not cause confusion with the new ConfigurableGroup which will be the offical way to create groups with addition of group-wide configuations.[0m
[32m2024-12-14 17:51:20.381[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.tasks[0m:[36m_get_task_and_group[0m:[36m452[0m - [34m[1m`group` and `group_alias` keys in tasks' configs will no longer be used in the next release of lmms-eval. `tag` will be used to allow to call a collection of tasks just like `group`. `group` will be removed in order to not cause confusion with the new ConfigurableGroup which will be the offical way to create groups with addition of group-wide configuations.[0m
[32m2024-12-14 17:51:20.422[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m503[0m - [1mEvaluation tracker args: {'output_path': './logs/'}[0m
[32m2024-12-14 17:51:20.423[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m592[0m - [1mSelected Tasks: ['pope_pop', 'vqav2_val_lite'][0m
[32m2024-12-14 17:51:20.425[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36msimple_evaluate[0m:[36m155[0m - [1mSetting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234[0m
[32m2024-12-14 17:51:20.434[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.tasks[0m:[36m_get_task_and_group[0m:[36m452[0m - [34m[1m`group` and `group_alias` keys in tasks' configs will no longer be used in the next release of lmms-eval. `tag` will be used to allow to call a collection of tasks just like `group`. `group` will be removed in order to not cause confusion with the new ConfigurableGroup which will be the offical way to create groups with addition of group-wide configuations.[0m
[32m2024-12-14 17:51:20.981[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m503[0m - [1mEvaluation tracker args: {'output_path': './logs/'}[0m
[32m2024-12-14 17:51:20.982[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m592[0m - [1mSelected Tasks: ['pope_pop', 'vqav2_val_lite'][0m
[32m2024-12-14 17:51:20.984[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36msimple_evaluate[0m:[36m155[0m - [1mSetting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234[0m
[32m2024-12-14 17:51:21.133[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m503[0m - [1mEvaluation tracker args: {'output_path': './logs/'}[0m
[32m2024-12-14 17:51:21.134[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m592[0m - [1mSelected Tasks: ['pope_pop', 'vqav2_val_lite'][0m
[32m2024-12-14 17:51:21.136[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36msimple_evaluate[0m:[36m155[0m - [1mSetting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234[0m
[32m2024-12-14 17:51:21.187[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m503[0m - [1mEvaluation tracker args: {'output_path': './logs/'}[0m
[32m2024-12-14 17:51:21.189[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m592[0m - [1mSelected Tasks: ['pope_pop', 'vqav2_val_lite'][0m
[32m2024-12-14 17:51:21.193[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36msimple_evaluate[0m:[36m155[0m - [1mSetting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234[0m
initialize llava model with modification
OpenCLIP not installed
initialize llava model with modification
initialize llava model with modification
OpenCLIP not installed
self.merging= None
model_name: llava-v1.6-vicuna-7b
Rank 0:  Loaded LLaVA model: liuhaotian/llava-v1.6-vicuna-7b
loding from here
OpenCLIP not installed
initialize llava model with modification
self.merging= None
model_name: llava-v1.6-vicuna-7b
loding from here
OpenCLIP not installed
self.merging= None
model_name: llava-v1.6-vicuna-7b
loding from here
You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
Rank 0:  Loading vision tower: openai/clip-vit-large-patch14-336
self.merging= None
model_name: llava-v1.6-vicuna-7b
loding from here
You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:05<00:11,  5.72s/it]Loading checkpoint shards:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:06<00:12,  6.33s/it]Loading checkpoint shards:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:05<00:11,  5.62s/it]Loading checkpoint shards:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:05<00:11,  5.76s/it]Loading checkpoint shards:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:11<00:05,  5.53s/it]Loading checkpoint shards:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:11<00:05,  5.71s/it]Loading checkpoint shards:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:11<00:05,  5.86s/it]Loading checkpoint shards:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:11<00:05,  5.88s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:16<00:00,  5.44s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:16<00:00,  5.60s/it]
Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:16<00:00,  5.39s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:16<00:00,  5.48s/it]
Rank 0:  Model Class: LlavaLlamaForCausalLM
Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:16<00:00,  5.37s/it]device: cuda:0
generation_type: recursion
fix_grid: 2x2
attention_thresholding_type: layer_mean_topk
attention_norm: None
attention_threshold: 0.8
detection_strategy: None
detection_threshold: 0.8
save_output: False
save_output_csv_path: generation_output.csv
target_token_selection_strategy: first
stages: [1, 0, -1, -2]
positional_embedding_type: bilinear_interpolation
visualize_heatmap: False
Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:16<00:00,  5.43s/it]square: 1

remove unpadding=True, change to 'spatial'
change positional embedding to bilinear_interpolation
device: cuda:0
generation_type: recursion
fix_grid: 2x2
attention_thresholding_type: layer_mean_topk
attention_norm: None
attention_threshold: 0.8
detection_strategy: None
detection_threshold: 0.8
save_output: False
save_output_csv_path: generation_output.csv
target_token_selection_strategy: first
stages: [1, 0, -1, -2]
positional_embedding_type: bilinear_interpolation
visualize_heatmap: False
square: 1
remove unpadding=True, change to 'spatial'
change positional embedding to bilinear_interpolation
device: cuda:0
generation_type: recursion
fix_grid: 2x2
attention_thresholding_type: layer_mean_topk
attention_norm: None
attention_threshold: 0.8
detection_strategy: None
detection_threshold: 0.8
save_output: False
save_output_csv_path: generation_output.csv
target_token_selection_strategy: first
stages: [1, 0, -1, -2]
positional_embedding_type: bilinear_interpolation
visualize_heatmap: False
square: 1
remove unpadding=True, change to 'spatial'
change positional embedding to bilinear_interpolation
Bilienar interpolation embedding type.
Bilienar interpolation embedding type.
[32m2024-12-14 17:51:49.659[0m | [1mINFO    [0m | [36mlmms_eval.models.llava[0m:[36m__init__[0m:[36m306[0m - [1mUsing 4 devices with data parallelism[0m
[32m2024-12-14 17:51:49.660[0m | [1mINFO    [0m | [36mlmms_eval.evaluator_utils[0m:[36mfrom_taskdict[0m:[36m91[0m - [1mNo metadata found in task config for vqav2_val_lite, using default n_shot=0[0m
[32m2024-12-14 17:51:49.660[0m | [1mINFO    [0m | [36mlmms_eval.evaluator_utils[0m:[36mfrom_taskdict[0m:[36m91[0m - [1mNo metadata found in task config for pope_pop, using default n_shot=0[0m
[32m2024-12-14 17:51:49.660[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.caching.cache[0m:[36mload_from_cache[0m:[36m33[0m - [34m[1mrequests-vqav2_val_lite-0shot-rank0-world_size4-tokenizer is not cached, generating...[0m
[32m2024-12-14 17:51:49.661[0m | [1mINFO    [0m | [36mlmms_eval.api.task[0m:[36mbuild_all_requests[0m:[36m425[0m - [1mBuilding contexts for vqav2_val_lite on rank 0...[0m
Bilienar interpolation embedding type.
Bilienar interpolation embedding type.
Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:17<00:00,  5.65s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:17<00:00,  5.70s/it]
device: cuda:0
generation_type: recursion
fix_grid: 2x2
attention_thresholding_type: layer_mean_topk
attention_norm: None
attention_threshold: 0.8
detection_strategy: None
detection_threshold: 0.8
save_output: False
save_output_csv_path: generation_output.csv
target_token_selection_strategy: first
stages: [1, 0, -1, -2]
positional_embedding_type: bilinear_interpolation
visualize_heatmap: False
square: 1
remove unpadding=True, change to 'spatial'
change positional embedding to bilinear_interpolation
Bilienar interpolation embedding type.
  0%|          | 0/125 [00:00<?, ?it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [00:00<00:00, 116095.66it/s]
[32m2024-12-14 17:51:50.851[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m455[0m - [34m[1mTask: vqav2_val_lite; number of requests on this rank: 125[0m
Bilienar interpolation embedding type.
Bilienar interpolation embedding type.
[32m2024-12-14 17:51:52.289[0m | [1mINFO    [0m | [36mlmms_eval.evaluator_utils[0m:[36mfrom_taskdict[0m:[36m91[0m - [1mNo metadata found in task config for vqav2_val_lite, using default n_shot=0[0m
[32m2024-12-14 17:51:52.289[0m | [1mINFO    [0m | [36mlmms_eval.evaluator_utils[0m:[36mfrom_taskdict[0m:[36m91[0m - [1mNo metadata found in task config for pope_pop, using default n_shot=0[0m
[32m2024-12-14 17:51:52.290[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.caching.cache[0m:[36mload_from_cache[0m:[36m33[0m - [34m[1mrequests-vqav2_val_lite-0shot-rank3-world_size4-tokenizer is not cached, generating...[0m
[32m2024-12-14 17:51:52.290[0m | [1mINFO    [0m | [36mlmms_eval.api.task[0m:[36mbuild_all_requests[0m:[36m425[0m - [1mBuilding contexts for vqav2_val_lite on rank 3...[0m
Bilienar interpolation embedding type.
[32m2024-12-14 17:51:52.816[0m | [1mINFO    [0m | [36mlmms_eval.evaluator_utils[0m:[36mfrom_taskdict[0m:[36m91[0m - [1mNo metadata found in task config for vqav2_val_lite, using default n_shot=0[0m
[32m2024-12-14 17:51:52.817[0m | [1mINFO    [0m | [36mlmms_eval.evaluator_utils[0m:[36mfrom_taskdict[0m:[36m91[0m - [1mNo metadata found in task config for pope_pop, using default n_shot=0[0m
[32m2024-12-14 17:51:52.817[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.caching.cache[0m:[36mload_from_cache[0m:[36m33[0m - [34m[1mrequests-vqav2_val_lite-0shot-rank1-world_size4-tokenizer is not cached, generating...[0m
[32m2024-12-14 17:51:52.817[0m | [1mINFO    [0m | [36mlmms_eval.api.task[0m:[36mbuild_all_requests[0m:[36m425[0m - [1mBuilding contexts for vqav2_val_lite on rank 1...[0m
  0%|          | 0/125 [00:00<?, ?it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [00:00<00:00, 96287.97it/s]
[32m2024-12-14 17:51:53.468[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m455[0m - [34m[1mTask: vqav2_val_lite; number of requests on this rank: 125[0m
  0%|          | 0/125 [00:00<?, ?it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [00:00<00:00, 108931.64it/s]
[32m2024-12-14 17:51:53.986[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m455[0m - [34m[1mTask: vqav2_val_lite; number of requests on this rank: 125[0m
[32m2024-12-14 17:51:54.301[0m | [1mINFO    [0m | [36mlmms_eval.evaluator_utils[0m:[36mfrom_taskdict[0m:[36m91[0m - [1mNo metadata found in task config for vqav2_val_lite, using default n_shot=0[0m
[32m2024-12-14 17:51:54.302[0m | [1mINFO    [0m | [36mlmms_eval.evaluator_utils[0m:[36mfrom_taskdict[0m:[36m91[0m - [1mNo metadata found in task config for pope_pop, using default n_shot=0[0m
[32m2024-12-14 17:51:54.302[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.caching.cache[0m:[36mload_from_cache[0m:[36m33[0m - [34m[1mrequests-vqav2_val_lite-0shot-rank2-world_size4-tokenizer is not cached, generating...[0m
[32m2024-12-14 17:51:54.303[0m | [1mINFO    [0m | [36mlmms_eval.api.task[0m:[36mbuild_all_requests[0m:[36m425[0m - [1mBuilding contexts for vqav2_val_lite on rank 2...[0m
  0%|          | 0/125 [00:00<?, ?it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [00:00<00:00, 106217.18it/s]
[32m2024-12-14 17:51:55.447[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m455[0m - [34m[1mTask: vqav2_val_lite; number of requests on this rank: 125[0m
[32m2024-12-14 17:52:04.420[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.caching.cache[0m:[36mload_from_cache[0m:[36m33[0m - [34m[1mrequests-pope_pop-0shot-rank3-world_size4-tokenizer is not cached, generating...[0m
[32m2024-12-14 17:52:04.420[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.caching.cache[0m:[36mload_from_cache[0m:[36m33[0m - [34m[1mrequests-pope_pop-0shot-rank1-world_size4-tokenizer is not cached, generating...[0m
[32m2024-12-14 17:52:04.420[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.caching.cache[0m:[36mload_from_cache[0m:[36m33[0m - [34m[1mrequests-pope_pop-0shot-rank2-world_size4-tokenizer is not cached, generating...[0m
[32m2024-12-14 17:52:04.420[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.caching.cache[0m:[36mload_from_cache[0m:[36m33[0m - [34m[1mrequests-pope_pop-0shot-rank0-world_size4-tokenizer is not cached, generating...[0m
[32m2024-12-14 17:52:04.421[0m | [1mINFO    [0m | [36mlmms_eval.api.task[0m:[36mbuild_all_requests[0m:[36m425[0m - [1mBuilding contexts for pope_pop on rank 3...[0m
[32m2024-12-14 17:52:04.421[0m | [1mINFO    [0m | [36mlmms_eval.api.task[0m:[36mbuild_all_requests[0m:[36m425[0m - [1mBuilding contexts for pope_pop on rank 2...[0m
[32m2024-12-14 17:52:04.421[0m | [1mINFO    [0m | [36mlmms_eval.api.task[0m:[36mbuild_all_requests[0m:[36m425[0m - [1mBuilding contexts for pope_pop on rank 1...[0m
[32m2024-12-14 17:52:04.421[0m | [1mINFO    [0m | [36mlmms_eval.api.task[0m:[36mbuild_all_requests[0m:[36m425[0m - [1mBuilding contexts for pope_pop on rank 0...[0m
  0%|          | 0/750 [00:00<?, ?it/s]  0%|          | 0/750 [00:00<?, ?it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 750/750 [00:00<00:00, 111483.43it/s]
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 750/750 [00:00<00:00, 106152.66it/s]
[32m2024-12-14 17:52:11.625[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m455[0m - [34m[1mTask: pope_pop; number of requests on this rank: 750[0m
[32m2024-12-14 17:52:11.625[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m455[0m - [34m[1mTask: pope_pop; number of requests on this rank: 750[0m
  0%|          | 0/750 [00:00<?, ?it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 750/750 [00:00<00:00, 108563.22it/s]
[32m2024-12-14 17:52:11.913[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m455[0m - [34m[1mTask: pope_pop; number of requests on this rank: 750[0m
  0%|          | 0/750 [00:00<?, ?it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 750/750 [00:00<00:00, 109313.97it/s]
[32m2024-12-14 17:52:12.336[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m455[0m - [34m[1mTask: pope_pop; number of requests on this rank: 750[0m
[32m2024-12-14 17:52:12.337[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m476[0m - [1mRunning generate_until requests[0m
[32m2024-12-14 17:52:12.337[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m476[0m - [1mRunning generate_until requests[0m
[32m2024-12-14 17:52:12.337[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m476[0m - [1mRunning generate_until requests[0m
[32m2024-12-14 17:52:12.338[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m476[0m - [1mRunning generate_until requests[0m
Model Responding:   0%|          | 0/875 [00:00<?, ?it/s]CLIPModel is using CLIPSdpaAttention, but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation="eager"` when loading the model.
CLIPModel is using CLIPSdpaAttention, but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation="eager"` when loading the model.
CLIPModel is using CLIPSdpaAttention, but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation="eager"` when loading the model.
CLIPModel is using CLIPSdpaAttention, but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation="eager"` when loading the model.
LlamaModel is using LlamaSdpaAttention, but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation="eager"` when loading the model.
LlamaModel is using LlamaSdpaAttention, but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation="eager"` when loading the model.
LlamaModel is using LlamaSdpaAttention, but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation="eager"` when loading the model.
LlamaModel is using LlamaSdpaAttention, but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation="eager"` when loading the model.
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
Model Responding:   0%|          | 1/875 [00:10<2:26:21, 10.05s/it]Model Responding:   0%|          | 2/875 [00:18<2:10:22,  8.96s/it]Model Responding:   0%|          | 3/875 [00:26<2:07:15,  8.76s/it]Model Responding:   0%|          | 4/875 [00:34<2:03:27,  8.50s/it]Model Responding:   1%|          | 5/875 [00:43<2:02:35,  8.45s/it]Model Responding:   1%|          | 6/875 [00:51<2:03:27,  8.52s/it]Model Responding:   1%|          | 7/875 [01:01<2:06:36,  8.75s/it]Model Responding:   1%|          | 8/875 [01:10<2:07:48,  8.85s/it]Model Responding:   1%|          | 9/875 [01:19<2:07:53,  8.86s/it]Model Responding:   1%|          | 10/875 [01:27<2:05:05,  8.68s/it]Model Responding:   1%|‚ñè         | 11/875 [01:36<2:05:00,  8.68s/it]Model Responding:   1%|‚ñè         | 12/875 [01:44<2:02:13,  8.50s/it]Model Responding:   1%|‚ñè         | 13/875 [01:52<2:03:35,  8.60s/it]Model Responding:   2%|‚ñè         | 14/875 [02:00<2:00:53,  8.42s/it]Model Responding:   2%|‚ñè         | 15/875 [02:10<2:04:15,  8.67s/it]Model Responding:   2%|‚ñè         | 16/875 [02:17<2:00:19,  8.40s/it]Model Responding:   2%|‚ñè         | 17/875 [02:26<2:00:50,  8.45s/it]Model Responding:   2%|‚ñè         | 18/875 [02:34<1:59:16,  8.35s/it]Model Responding:   2%|‚ñè         | 19/875 [02:43<2:00:03,  8.41s/it]Model Responding:   2%|‚ñè         | 20/875 [02:51<2:00:06,  8.43s/it]Model Responding:   2%|‚ñè         | 21/875 [03:00<2:00:15,  8.45s/it]Model Responding:   3%|‚ñé         | 22/875 [03:08<2:00:49,  8.50s/it]Model Responding:   3%|‚ñé         | 23/875 [03:17<1:59:48,  8.44s/it]Model Responding:   3%|‚ñé         | 24/875 [03:25<1:59:57,  8.46s/it]Model Responding:   3%|‚ñé         | 25/875 [03:34<1:59:45,  8.45s/it]Model Responding:   3%|‚ñé         | 26/875 [03:42<1:58:12,  8.35s/it]Model Responding:   3%|‚ñé         | 27/875 [03:51<2:00:17,  8.51s/it]Model Responding:   3%|‚ñé         | 28/875 [03:59<1:59:47,  8.49s/it]Model Responding:   3%|‚ñé         | 29/875 [04:08<2:00:48,  8.57s/it]Model Responding:   3%|‚ñé         | 30/875 [04:16<1:58:53,  8.44s/it]Model Responding:   4%|‚ñé         | 31/875 [04:24<1:56:59,  8.32s/it]Model Responding:   4%|‚ñé         | 32/875 [04:32<1:56:00,  8.26s/it]Model Responding:   4%|‚ñç         | 33/875 [04:40<1:56:02,  8.27s/it]Model Responding:   4%|‚ñç         | 34/875 [04:48<1:54:53,  8.20s/it]Model Responding:   4%|‚ñç         | 35/875 [04:57<1:56:25,  8.32s/it]Model Responding:   4%|‚ñç         | 36/875 [05:05<1:55:45,  8.28s/it]Model Responding:   4%|‚ñç         | 37/875 [05:14<1:56:49,  8.36s/it]Model Responding:   4%|‚ñç         | 38/875 [05:22<1:56:07,  8.32s/it]Model Responding:   4%|‚ñç         | 39/875 [05:31<1:57:12,  8.41s/it]Model Responding:   5%|‚ñç         | 40/875 [05:39<1:55:28,  8.30s/it]Model Responding:   5%|‚ñç         | 41/875 [05:47<1:55:36,  8.32s/it]Model Responding:   5%|‚ñç         | 42/875 [05:56<1:57:27,  8.46s/it]Model Responding:   5%|‚ñç         | 43/875 [06:05<2:02:39,  8.85s/it]Model Responding:   5%|‚ñå         | 44/875 [06:14<2:01:50,  8.80s/it]Model Responding:   5%|‚ñå         | 45/875 [06:23<2:00:43,  8.73s/it]Model Responding:   5%|‚ñå         | 46/875 [06:32<2:01:18,  8.78s/it]Model Responding:   5%|‚ñå         | 47/875 [06:40<1:57:57,  8.55s/it]Model Responding:   5%|‚ñå         | 48/875 [06:48<1:56:46,  8.47s/it]Model Responding:   6%|‚ñå         | 49/875 [06:56<1:56:50,  8.49s/it]Model Responding:   6%|‚ñå         | 50/875 [07:04<1:54:31,  8.33s/it]Model Responding:   6%|‚ñå         | 51/875 [07:13<1:55:09,  8.39s/it]Model Responding:   6%|‚ñå         | 52/875 [07:22<1:58:50,  8.66s/it]Model Responding:   6%|‚ñå         | 53/875 [07:31<1:58:52,  8.68s/it]Model Responding:   6%|‚ñå         | 54/875 [07:40<2:00:18,  8.79s/it]Model Responding:   6%|‚ñã         | 55/875 [07:49<2:00:26,  8.81s/it]Model Responding:   6%|‚ñã         | 56/875 [07:58<2:03:15,  9.03s/it]Model Responding:   7%|‚ñã         | 57/875 [08:08<2:03:24,  9.05s/it]Model Responding:   7%|‚ñã         | 58/875 [08:16<2:01:46,  8.94s/it]Model Responding:   7%|‚ñã         | 59/875 [08:26<2:03:10,  9.06s/it]Model Responding:   7%|‚ñã         | 60/875 [08:35<2:03:07,  9.06s/it]Model Responding:   7%|‚ñã         | 61/875 [08:43<2:00:30,  8.88s/it]Model Responding:   7%|‚ñã         | 62/875 [08:51<1:57:57,  8.70s/it]Model Responding:   7%|‚ñã         | 63/875 [09:00<1:58:26,  8.75s/it]Model Responding:   7%|‚ñã         | 64/875 [09:08<1:54:57,  8.51s/it]Model Responding:   7%|‚ñã         | 65/875 [09:16<1:53:39,  8.42s/it]Model Responding:   8%|‚ñä         | 66/875 [09:25<1:53:43,  8.43s/it]Model Responding:   8%|‚ñä         | 67/875 [09:33<1:53:16,  8.41s/it]Model Responding:   8%|‚ñä         | 68/875 [09:42<1:55:58,  8.62s/it]Model Responding:   8%|‚ñä         | 69/875 [09:50<1:52:43,  8.39s/it]Model Responding:   8%|‚ñä         | 70/875 [09:59<1:54:38,  8.54s/it]Model Responding:   8%|‚ñä         | 71/875 [10:08<1:55:16,  8.60s/it]Model Responding:   8%|‚ñä         | 72/875 [10:16<1:54:23,  8.55s/it]Model Responding:   8%|‚ñä         | 73/875 [10:24<1:52:29,  8.42s/it]Model Responding:   8%|‚ñä         | 74/875 [10:33<1:54:32,  8.58s/it]Model Responding:   9%|‚ñä         | 75/875 [10:42<1:53:17,  8.50s/it]Model Responding:   9%|‚ñä         | 76/875 [10:50<1:52:27,  8.44s/it]Model Responding:   9%|‚ñâ         | 77/875 [10:59<1:54:09,  8.58s/it]Model Responding:   9%|‚ñâ         | 78/875 [11:07<1:52:30,  8.47s/it]Model Responding:   9%|‚ñâ         | 79/875 [11:16<1:54:42,  8.65s/it]Model Responding:   9%|‚ñâ         | 80/875 [11:25<1:57:12,  8.85s/it]Model Responding:   9%|‚ñâ         | 81/875 [11:35<2:00:31,  9.11s/it]Model Responding:   9%|‚ñâ         | 82/875 [11:43<1:56:37,  8.82s/it]Model Responding:   9%|‚ñâ         | 83/875 [11:53<1:59:33,  9.06s/it]Model Responding:  10%|‚ñâ         | 84/875 [12:02<2:00:42,  9.16s/it]Model Responding:  10%|‚ñâ         | 85/875 [12:11<2:00:17,  9.14s/it]Model Responding:  10%|‚ñâ         | 86/875 [12:20<1:57:24,  8.93s/it]Model Responding:  10%|‚ñâ         | 87/875 [12:28<1:55:18,  8.78s/it]Model Responding:  10%|‚ñà         | 88/875 [12:37<1:55:04,  8.77s/it]Model Responding:  10%|‚ñà         | 89/875 [12:45<1:53:17,  8.65s/it]Model Responding:  10%|‚ñà         | 90/875 [12:55<1:55:10,  8.80s/it]Model Responding:  10%|‚ñà         | 91/875 [13:04<1:57:09,  8.97s/it]Model Responding:  11%|‚ñà         | 92/875 [13:13<1:59:11,  9.13s/it]Model Responding:  11%|‚ñà         | 93/875 [13:23<2:01:22,  9.31s/it]Model Responding:  11%|‚ñà         | 94/875 [13:32<1:59:19,  9.17s/it]Model Responding:  11%|‚ñà         | 95/875 [13:41<1:58:14,  9.10s/it]Model Responding:  11%|‚ñà         | 96/875 [13:50<1:56:25,  8.97s/it]Model Responding:  11%|‚ñà         | 97/875 [13:58<1:55:39,  8.92s/it]Model Responding:  11%|‚ñà         | 98/875 [14:07<1:53:04,  8.73s/it]Model Responding:  11%|‚ñà‚ñè        | 99/875 [14:15<1:52:03,  8.66s/it]Model Responding:  11%|‚ñà‚ñè        | 100/875 [14:24<1:52:09,  8.68s/it]Model Responding:  12%|‚ñà‚ñè        | 101/875 [14:32<1:50:03,  8.53s/it]Model Responding:  12%|‚ñà‚ñè        | 102/875 [14:41<1:51:06,  8.62s/it]Model Responding:  12%|‚ñà‚ñè        | 103/875 [14:50<1:52:02,  8.71s/it]Model Responding:  12%|‚ñà‚ñè        | 104/875 [14:58<1:51:06,  8.65s/it]Model Responding:  12%|‚ñà‚ñè        | 105/875 [15:07<1:50:32,  8.61s/it]Model Responding:  12%|‚ñà‚ñè        | 106/875 [15:15<1:49:04,  8.51s/it]Model Responding:  12%|‚ñà‚ñè        | 107/875 [15:24<1:49:53,  8.59s/it]Model Responding:  12%|‚ñà‚ñè        | 108/875 [15:33<1:51:18,  8.71s/it]Model Responding:  12%|‚ñà‚ñè        | 109/875 [15:41<1:50:53,  8.69s/it]Model Responding:  13%|‚ñà‚ñé        | 110/875 [15:51<1:52:24,  8.82s/it]Model Responding:  13%|‚ñà‚ñé        | 111/875 [16:00<1:52:44,  8.85s/it]Model Responding:  13%|‚ñà‚ñé        | 112/875 [16:08<1:51:21,  8.76s/it]Model Responding:  13%|‚ñà‚ñé        | 113/875 [16:16<1:49:42,  8.64s/it]Model Responding:  13%|‚ñà‚ñé        | 114/875 [16:25<1:48:44,  8.57s/it]Model Responding:  13%|‚ñà‚ñé        | 115/875 [16:34<1:49:39,  8.66s/it]Model Responding:  13%|‚ñà‚ñé        | 116/875 [16:42<1:48:49,  8.60s/it]Model Responding:  13%|‚ñà‚ñé        | 117/875 [16:51<1:49:04,  8.63s/it]Model Responding:  13%|‚ñà‚ñé        | 118/875 [16:59<1:48:01,  8.56s/it]Model Responding:  14%|‚ñà‚ñé        | 119/875 [17:08<1:47:18,  8.52s/it]Model Responding:  14%|‚ñà‚ñé        | 120/875 [17:16<1:45:53,  8.41s/it]Model Responding:  14%|‚ñà‚ñç        | 121/875 [17:24<1:45:47,  8.42s/it]Model Responding:  14%|‚ñà‚ñç        | 122/875 [17:33<1:47:12,  8.54s/it]Model Responding:  14%|‚ñà‚ñç        | 123/875 [17:42<1:50:01,  8.78s/it]Model Responding:  14%|‚ñà‚ñç        | 124/875 [17:52<1:54:12,  9.13s/it]Model Responding:  14%|‚ñà‚ñç        | 125/875 [18:01<1:51:41,  8.94s/it]Model Responding:  14%|‚ñà‚ñç        | 126/875 [18:09<1:50:00,  8.81s/it]Model Responding:  15%|‚ñà‚ñç        | 127/875 [18:18<1:48:41,  8.72s/it]Model Responding:  15%|‚ñà‚ñç        | 128/875 [18:27<1:48:03,  8.68s/it]Model Responding:  15%|‚ñà‚ñç        | 129/875 [18:35<1:46:24,  8.56s/it]Model Responding:  15%|‚ñà‚ñç        | 130/875 [18:44<1:47:30,  8.66s/it]Model Responding:  15%|‚ñà‚ñç        | 131/875 [18:52<1:47:33,  8.67s/it]Model Responding:  15%|‚ñà‚ñå        | 132/875 [19:00<1:44:59,  8.48s/it]Model Responding:  15%|‚ñà‚ñå        | 133/875 [19:09<1:44:04,  8.42s/it]Model Responding:  15%|‚ñà‚ñå        | 134/875 [19:17<1:41:49,  8.25s/it]Model Responding:  15%|‚ñà‚ñå        | 135/875 [19:25<1:41:08,  8.20s/it]Model Responding:  16%|‚ñà‚ñå        | 136/875 [19:33<1:40:20,  8.15s/it]Model Responding:  16%|‚ñà‚ñå        | 137/875 [19:41<1:41:03,  8.22s/it]Model Responding:  16%|‚ñà‚ñå        | 138/875 [19:50<1:42:27,  8.34s/it]Model Responding:  16%|‚ñà‚ñå        | 139/875 [19:58<1:43:56,  8.47s/it]Model Responding:  16%|‚ñà‚ñå        | 140/875 [20:06<1:41:34,  8.29s/it]Model Responding:  16%|‚ñà‚ñå        | 141/875 [20:15<1:42:17,  8.36s/it]Model Responding:  16%|‚ñà‚ñå        | 142/875 [20:24<1:44:42,  8.57s/it]Model Responding:  16%|‚ñà‚ñã        | 143/875 [20:33<1:47:43,  8.83s/it]Model Responding:  16%|‚ñà‚ñã        | 144/875 [20:42<1:47:37,  8.83s/it]Model Responding:  17%|‚ñà‚ñã        | 145/875 [20:51<1:46:34,  8.76s/it]Model Responding:  17%|‚ñà‚ñã        | 146/875 [20:59<1:46:07,  8.73s/it]Model Responding:  17%|‚ñà‚ñã        | 147/875 [21:08<1:44:30,  8.61s/it]Model Responding:  17%|‚ñà‚ñã        | 148/875 [21:16<1:42:25,  8.45s/it]Model Responding:  17%|‚ñà‚ñã        | 149/875 [21:24<1:40:33,  8.31s/it]Model Responding:  17%|‚ñà‚ñã        | 150/875 [21:33<1:42:18,  8.47s/it]Model Responding:  17%|‚ñà‚ñã        | 151/875 [21:41<1:41:47,  8.44s/it]Model Responding:  17%|‚ñà‚ñã        | 152/875 [21:49<1:40:55,  8.38s/it]Model Responding:  17%|‚ñà‚ñã        | 153/875 [21:58<1:41:17,  8.42s/it]Model Responding:  18%|‚ñà‚ñä        | 154/875 [22:06<1:40:33,  8.37s/it]Model Responding:  18%|‚ñà‚ñä        | 155/875 [22:15<1:41:49,  8.49s/it]Model Responding:  18%|‚ñà‚ñä        | 156/875 [22:23<1:40:57,  8.42s/it]Model Responding:  18%|‚ñà‚ñä        | 157/875 [22:32<1:42:00,  8.52s/it]Model Responding:  18%|‚ñà‚ñä        | 158/875 [22:41<1:45:22,  8.82s/it]Model Responding:  18%|‚ñà‚ñä        | 159/875 [22:51<1:46:39,  8.94s/it]Model Responding:  18%|‚ñà‚ñä        | 160/875 [23:00<1:46:43,  8.96s/it]Model Responding:  18%|‚ñà‚ñä        | 161/875 [23:08<1:45:57,  8.90s/it]Model Responding:  19%|‚ñà‚ñä        | 162/875 [23:16<1:41:43,  8.56s/it]Model Responding:  19%|‚ñà‚ñä        | 163/875 [23:24<1:41:06,  8.52s/it]Model Responding:  19%|‚ñà‚ñä        | 164/875 [23:34<1:42:50,  8.68s/it]Model Responding:  19%|‚ñà‚ñâ        | 165/875 [23:43<1:44:22,  8.82s/it]Model Responding:  19%|‚ñà‚ñâ        | 166/875 [23:52<1:44:16,  8.82s/it]Model Responding:  19%|‚ñà‚ñâ        | 167/875 [24:00<1:43:54,  8.81s/it]Model Responding:  19%|‚ñà‚ñâ        | 168/875 [24:09<1:42:01,  8.66s/it]Model Responding:  19%|‚ñà‚ñâ        | 169/875 [24:17<1:40:28,  8.54s/it]Model Responding:  19%|‚ñà‚ñâ        | 170/875 [24:25<1:40:00,  8.51s/it]Model Responding:  20%|‚ñà‚ñâ        | 171/875 [24:33<1:38:08,  8.36s/it]Model Responding:  20%|‚ñà‚ñâ        | 172/875 [24:42<1:39:02,  8.45s/it]Model Responding:  20%|‚ñà‚ñâ        | 173/875 [24:51<1:41:18,  8.66s/it]Model Responding:  20%|‚ñà‚ñâ        | 174/875 [25:00<1:40:56,  8.64s/it]Model Responding:  20%|‚ñà‚ñà        | 175/875 [25:09<1:41:16,  8.68s/it]Model Responding:  20%|‚ñà‚ñà        | 176/875 [25:18<1:42:16,  8.78s/it]Model Responding:  20%|‚ñà‚ñà        | 177/875 [25:26<1:41:32,  8.73s/it]Model Responding:  20%|‚ñà‚ñà        | 178/875 [25:34<1:40:06,  8.62s/it]Model Responding:  20%|‚ñà‚ñà        | 179/875 [25:43<1:40:14,  8.64s/it]Model Responding:  21%|‚ñà‚ñà        | 180/875 [25:52<1:41:00,  8.72s/it]Model Responding:  21%|‚ñà‚ñà        | 181/875 [26:01<1:39:50,  8.63s/it]Model Responding:  21%|‚ñà‚ñà        | 182/875 [26:09<1:39:13,  8.59s/it]Model Responding:  21%|‚ñà‚ñà        | 183/875 [26:17<1:37:15,  8.43s/it]Model Responding:  21%|‚ñà‚ñà        | 184/875 [26:25<1:36:28,  8.38s/it]Model Responding:  21%|‚ñà‚ñà        | 185/875 [26:34<1:36:56,  8.43s/it]Model Responding:  21%|‚ñà‚ñà‚ñè       | 186/875 [26:43<1:38:35,  8.59s/it]Model Responding:  21%|‚ñà‚ñà‚ñè       | 187/875 [26:52<1:41:06,  8.82s/it]Model Responding:  21%|‚ñà‚ñà‚ñè       | 188/875 [27:01<1:39:48,  8.72s/it]Model Responding:  22%|‚ñà‚ñà‚ñè       | 189/875 [27:10<1:40:08,  8.76s/it]Model Responding:  22%|‚ñà‚ñà‚ñè       | 190/875 [27:18<1:40:09,  8.77s/it]Model Responding:  22%|‚ñà‚ñà‚ñè       | 191/875 [27:27<1:40:16,  8.80s/it]Model Responding:  22%|‚ñà‚ñà‚ñè       | 192/875 [27:36<1:41:44,  8.94s/it]Model Responding:  22%|‚ñà‚ñà‚ñè       | 193/875 [27:45<1:40:58,  8.88s/it]Model Responding:  22%|‚ñà‚ñà‚ñè       | 194/875 [27:55<1:42:44,  9.05s/it]Model Responding:  22%|‚ñà‚ñà‚ñè       | 195/875 [28:03<1:40:53,  8.90s/it]Model Responding:  22%|‚ñà‚ñà‚ñè       | 196/875 [28:12<1:39:24,  8.78s/it]Model Responding:  23%|‚ñà‚ñà‚ñé       | 197/875 [28:20<1:38:15,  8.70s/it]Model Responding:  23%|‚ñà‚ñà‚ñé       | 198/875 [28:28<1:36:32,  8.56s/it]Model Responding:  23%|‚ñà‚ñà‚ñé       | 199/875 [28:37<1:36:17,  8.55s/it]Model Responding:  23%|‚ñà‚ñà‚ñé       | 200/875 [28:45<1:36:01,  8.54s/it]Model Responding:  23%|‚ñà‚ñà‚ñé       | 201/875 [28:54<1:35:09,  8.47s/it]Model Responding:  23%|‚ñà‚ñà‚ñé       | 202/875 [29:02<1:33:27,  8.33s/it]Model Responding:  23%|‚ñà‚ñà‚ñé       | 203/875 [29:10<1:33:09,  8.32s/it]Model Responding:  23%|‚ñà‚ñà‚ñé       | 204/875 [29:18<1:31:28,  8.18s/it]Model Responding:  23%|‚ñà‚ñà‚ñé       | 205/875 [29:26<1:31:53,  8.23s/it]Model Responding:  24%|‚ñà‚ñà‚ñé       | 206/875 [29:35<1:32:23,  8.29s/it]Model Responding:  24%|‚ñà‚ñà‚ñé       | 207/875 [29:43<1:32:13,  8.28s/it]Model Responding:  24%|‚ñà‚ñà‚ñç       | 208/875 [29:51<1:31:53,  8.27s/it]Model Responding:  24%|‚ñà‚ñà‚ñç       | 209/875 [30:00<1:32:22,  8.32s/it]Model Responding:  24%|‚ñà‚ñà‚ñç       | 210/875 [30:09<1:34:14,  8.50s/it]Model Responding:  24%|‚ñà‚ñà‚ñç       | 211/875 [30:17<1:34:53,  8.57s/it]Model Responding:  24%|‚ñà‚ñà‚ñç       | 212/875 [30:26<1:34:44,  8.57s/it]Model Responding:  24%|‚ñà‚ñà‚ñç       | 213/875 [30:34<1:34:23,  8.56s/it]Model Responding:  24%|‚ñà‚ñà‚ñç       | 214/875 [30:44<1:36:11,  8.73s/it]Model Responding:  25%|‚ñà‚ñà‚ñç       | 215/875 [30:53<1:37:54,  8.90s/it]Model Responding:  25%|‚ñà‚ñà‚ñç       | 216/875 [31:02<1:37:51,  8.91s/it]Model Responding:  25%|‚ñà‚ñà‚ñç       | 217/875 [31:10<1:36:37,  8.81s/it]Model Responding:  25%|‚ñà‚ñà‚ñç       | 218/875 [31:19<1:34:55,  8.67s/it]Model Responding:  25%|‚ñà‚ñà‚ñå       | 219/875 [31:27<1:33:47,  8.58s/it]Model Responding:  25%|‚ñà‚ñà‚ñå       | 220/875 [31:36<1:33:22,  8.55s/it]Model Responding:  25%|‚ñà‚ñà‚ñå       | 221/875 [31:44<1:33:20,  8.56s/it]Model Responding:  25%|‚ñà‚ñà‚ñå       | 222/875 [31:53<1:33:57,  8.63s/it]Model Responding:  25%|‚ñà‚ñà‚ñå       | 223/875 [32:01<1:33:08,  8.57s/it]Model Responding:  26%|‚ñà‚ñà‚ñå       | 224/875 [32:09<1:30:23,  8.33s/it]Model Responding:  26%|‚ñà‚ñà‚ñå       | 225/875 [32:18<1:31:47,  8.47s/it]Model Responding:  26%|‚ñà‚ñà‚ñå       | 226/875 [32:27<1:33:54,  8.68s/it]Model Responding:  26%|‚ñà‚ñà‚ñå       | 227/875 [32:36<1:34:16,  8.73s/it]Model Responding:  26%|‚ñà‚ñà‚ñå       | 228/875 [32:45<1:34:26,  8.76s/it]Model Responding:  26%|‚ñà‚ñà‚ñå       | 229/875 [32:54<1:35:39,  8.88s/it]Model Responding:  26%|‚ñà‚ñà‚ñã       | 230/875 [33:02<1:34:01,  8.75s/it]Model Responding:  26%|‚ñà‚ñà‚ñã       | 231/875 [33:10<1:31:52,  8.56s/it]Model Responding:  27%|‚ñà‚ñà‚ñã       | 232/875 [33:18<1:29:12,  8.32s/it]Model Responding:  27%|‚ñà‚ñà‚ñã       | 233/875 [33:27<1:30:30,  8.46s/it]Model Responding:  27%|‚ñà‚ñà‚ñã       | 234/875 [33:36<1:31:01,  8.52s/it]Model Responding:  27%|‚ñà‚ñà‚ñã       | 235/875 [33:44<1:29:23,  8.38s/it]Model Responding:  27%|‚ñà‚ñà‚ñã       | 236/875 [33:53<1:31:50,  8.62s/it]Model Responding:  27%|‚ñà‚ñà‚ñã       | 237/875 [34:02<1:32:00,  8.65s/it]Model Responding:  27%|‚ñà‚ñà‚ñã       | 238/875 [34:11<1:32:29,  8.71s/it]Model Responding:  27%|‚ñà‚ñà‚ñã       | 239/875 [34:18<1:29:36,  8.45s/it]Model Responding:  27%|‚ñà‚ñà‚ñã       | 240/875 [34:27<1:28:51,  8.40s/it]Model Responding:  28%|‚ñà‚ñà‚ñä       | 241/875 [34:35<1:28:46,  8.40s/it]Model Responding:  28%|‚ñà‚ñà‚ñä       | 242/875 [34:44<1:29:37,  8.50s/it]Model Responding:  28%|‚ñà‚ñà‚ñä       | 243/875 [34:52<1:28:57,  8.45s/it]Model Responding:  28%|‚ñà‚ñà‚ñä       | 244/875 [35:00<1:27:27,  8.32s/it]Model Responding:  28%|‚ñà‚ñà‚ñä       | 245/875 [35:09<1:27:42,  8.35s/it]Model Responding:  28%|‚ñà‚ñà‚ñä       | 246/875 [35:17<1:29:06,  8.50s/it]Model Responding:  28%|‚ñà‚ñà‚ñä       | 247/875 [35:27<1:31:59,  8.79s/it]Model Responding:  28%|‚ñà‚ñà‚ñä       | 248/875 [35:36<1:31:52,  8.79s/it]Model Responding:  28%|‚ñà‚ñà‚ñä       | 249/875 [35:44<1:31:52,  8.81s/it]Model Responding:  29%|‚ñà‚ñà‚ñä       | 250/875 [35:54<1:32:34,  8.89s/it]Model Responding:  29%|‚ñà‚ñà‚ñä       | 251/875 [36:02<1:30:40,  8.72s/it]Model Responding:  29%|‚ñà‚ñà‚ñâ       | 252/875 [36:10<1:29:41,  8.64s/it]Model Responding:  29%|‚ñà‚ñà‚ñâ       | 253/875 [36:19<1:28:07,  8.50s/it]Model Responding:  29%|‚ñà‚ñà‚ñâ       | 254/875 [36:26<1:25:54,  8.30s/it]Model Responding:  29%|‚ñà‚ñà‚ñâ       | 255/875 [36:35<1:25:27,  8.27s/it]Model Responding:  29%|‚ñà‚ñà‚ñâ       | 256/875 [36:43<1:24:49,  8.22s/it]Model Responding:  29%|‚ñà‚ñà‚ñâ       | 257/875 [36:51<1:26:34,  8.41s/it]Model Responding:  29%|‚ñà‚ñà‚ñâ       | 258/875 [36:59<1:24:34,  8.22s/it]Model Responding:  30%|‚ñà‚ñà‚ñâ       | 259/875 [37:08<1:25:48,  8.36s/it]Model Responding:  30%|‚ñà‚ñà‚ñâ       | 260/875 [37:17<1:26:26,  8.43s/it]Model Responding:  30%|‚ñà‚ñà‚ñâ       | 261/875 [37:25<1:24:57,  8.30s/it]Model Responding:  30%|‚ñà‚ñà‚ñâ       | 262/875 [37:34<1:27:22,  8.55s/it]Model Responding:  30%|‚ñà‚ñà‚ñà       | 263/875 [37:43<1:28:33,  8.68s/it]Model Responding:  30%|‚ñà‚ñà‚ñà       | 264/875 [37:52<1:29:31,  8.79s/it]Model Responding:  30%|‚ñà‚ñà‚ñà       | 265/875 [38:00<1:27:23,  8.60s/it]Model Responding:  30%|‚ñà‚ñà‚ñà       | 266/875 [38:08<1:26:25,  8.51s/it]Model Responding:  31%|‚ñà‚ñà‚ñà       | 267/875 [38:16<1:25:09,  8.40s/it]Model Responding:  31%|‚ñà‚ñà‚ñà       | 268/875 [38:25<1:24:35,  8.36s/it]Model Responding:  31%|‚ñà‚ñà‚ñà       | 269/875 [38:33<1:24:13,  8.34s/it]Model Responding:  31%|‚ñà‚ñà‚ñà       | 270/875 [38:41<1:23:31,  8.28s/it]Model Responding:  31%|‚ñà‚ñà‚ñà       | 271/875 [38:50<1:24:26,  8.39s/it]Model Responding:  31%|‚ñà‚ñà‚ñà       | 272/875 [38:59<1:26:35,  8.62s/it]Model Responding:  31%|‚ñà‚ñà‚ñà       | 273/875 [39:07<1:25:55,  8.56s/it]Model Responding:  31%|‚ñà‚ñà‚ñà‚ñè      | 274/875 [39:16<1:26:55,  8.68s/it]Model Responding:  31%|‚ñà‚ñà‚ñà‚ñè      | 275/875 [39:25<1:28:07,  8.81s/it]Model Responding:  32%|‚ñà‚ñà‚ñà‚ñè      | 276/875 [39:34<1:27:45,  8.79s/it]Model Responding:  32%|‚ñà‚ñà‚ñà‚ñè      | 277/875 [39:42<1:24:37,  8.49s/it]Model Responding:  32%|‚ñà‚ñà‚ñà‚ñè      | 278/875 [39:50<1:24:09,  8.46s/it]Model Responding:  32%|‚ñà‚ñà‚ñà‚ñè      | 279/875 [39:59<1:23:51,  8.44s/it]Model Responding:  32%|‚ñà‚ñà‚ñà‚ñè      | 280/875 [40:07<1:23:01,  8.37s/it]Model Responding:  32%|‚ñà‚ñà‚ñà‚ñè      | 281/875 [40:15<1:23:06,  8.40s/it]Model Responding:  32%|‚ñà‚ñà‚ñà‚ñè      | 282/875 [40:24<1:22:58,  8.40s/it]Model Responding:  32%|‚ñà‚ñà‚ñà‚ñè      | 283/875 [40:32<1:22:39,  8.38s/it]Model Responding:  32%|‚ñà‚ñà‚ñà‚ñè      | 284/875 [40:40<1:22:19,  8.36s/it]Model Responding:  33%|‚ñà‚ñà‚ñà‚ñé      | 285/875 [40:48<1:21:19,  8.27s/it]Model Responding:  33%|‚ñà‚ñà‚ñà‚ñé      | 286/875 [40:57<1:22:23,  8.39s/it]Model Responding:  33%|‚ñà‚ñà‚ñà‚ñé      | 287/875 [41:05<1:21:38,  8.33s/it]Model Responding:  33%|‚ñà‚ñà‚ñà‚ñé      | 288/875 [41:14<1:21:33,  8.34s/it]Model Responding:  33%|‚ñà‚ñà‚ñà‚ñé      | 289/875 [41:22<1:22:02,  8.40s/it]Model Responding:  33%|‚ñà‚ñà‚ñà‚ñé      | 290/875 [41:31<1:22:13,  8.43s/it]Model Responding:  33%|‚ñà‚ñà‚ñà‚ñé      | 291/875 [41:39<1:21:39,  8.39s/it]Model Responding:  33%|‚ñà‚ñà‚ñà‚ñé      | 292/875 [41:48<1:22:23,  8.48s/it]Model Responding:  33%|‚ñà‚ñà‚ñà‚ñé      | 293/875 [41:56<1:22:25,  8.50s/it]Model Responding:  34%|‚ñà‚ñà‚ñà‚ñé      | 294/875 [42:05<1:22:29,  8.52s/it]Model Responding:  34%|‚ñà‚ñà‚ñà‚ñé      | 295/875 [42:13<1:20:33,  8.33s/it]Model Responding:  34%|‚ñà‚ñà‚ñà‚ñç      | 296/875 [42:22<1:23:48,  8.68s/it]Model Responding:  34%|‚ñà‚ñà‚ñà‚ñç      | 297/875 [42:31<1:23:46,  8.70s/it]Model Responding:  34%|‚ñà‚ñà‚ñà‚ñç      | 298/875 [42:40<1:23:22,  8.67s/it]Model Responding:  34%|‚ñà‚ñà‚ñà‚ñç      | 299/875 [42:48<1:22:57,  8.64s/it]Model Responding:  34%|‚ñà‚ñà‚ñà‚ñç      | 300/875 [42:57<1:23:44,  8.74s/it]Model Responding:  34%|‚ñà‚ñà‚ñà‚ñç      | 301/875 [43:05<1:21:39,  8.54s/it]Model Responding:  35%|‚ñà‚ñà‚ñà‚ñç      | 302/875 [43:13<1:20:31,  8.43s/it]Model Responding:  35%|‚ñà‚ñà‚ñà‚ñç      | 303/875 [43:22<1:20:23,  8.43s/it]Model Responding:  35%|‚ñà‚ñà‚ñà‚ñç      | 304/875 [43:30<1:19:14,  8.33s/it]Model Responding:  35%|‚ñà‚ñà‚ñà‚ñç      | 305/875 [43:38<1:18:51,  8.30s/it]Model Responding:  35%|‚ñà‚ñà‚ñà‚ñç      | 306/875 [43:46<1:18:48,  8.31s/it]Model Responding:  35%|‚ñà‚ñà‚ñà‚ñå      | 307/875 [43:55<1:19:12,  8.37s/it]Model Responding:  35%|‚ñà‚ñà‚ñà‚ñå      | 308/875 [44:03<1:18:17,  8.28s/it]Model Responding:  35%|‚ñà‚ñà‚ñà‚ñå      | 309/875 [44:12<1:19:05,  8.38s/it]Model Responding:  35%|‚ñà‚ñà‚ñà‚ñå      | 310/875 [44:20<1:18:15,  8.31s/it]Model Responding:  36%|‚ñà‚ñà‚ñà‚ñå      | 311/875 [44:28<1:18:03,  8.30s/it]Model Responding:  36%|‚ñà‚ñà‚ñà‚ñå      | 312/875 [44:36<1:16:54,  8.20s/it]Model Responding:  36%|‚ñà‚ñà‚ñà‚ñå      | 313/875 [44:44<1:17:01,  8.22s/it]Model Responding:  36%|‚ñà‚ñà‚ñà‚ñå      | 314/875 [44:53<1:18:08,  8.36s/it]Model Responding:  36%|‚ñà‚ñà‚ñà‚ñå      | 315/875 [45:01<1:17:20,  8.29s/it]Model Responding:  36%|‚ñà‚ñà‚ñà‚ñå      | 316/875 [45:09<1:17:06,  8.28s/it]Model Responding:  36%|‚ñà‚ñà‚ñà‚ñå      | 317/875 [45:18<1:19:29,  8.55s/it]Model Responding:  36%|‚ñà‚ñà‚ñà‚ñã      | 318/875 [45:27<1:20:35,  8.68s/it]Model Responding:  36%|‚ñà‚ñà‚ñà‚ñã      | 319/875 [45:37<1:21:46,  8.83s/it]Model Responding:  37%|‚ñà‚ñà‚ñà‚ñã      | 320/875 [45:45<1:20:41,  8.72s/it]Model Responding:  37%|‚ñà‚ñà‚ñà‚ñã      | 321/875 [45:54<1:21:24,  8.82s/it]Model Responding:  37%|‚ñà‚ñà‚ñà‚ñã      | 322/875 [46:03<1:20:11,  8.70s/it]Model Responding:  37%|‚ñà‚ñà‚ñà‚ñã      | 323/875 [46:10<1:17:24,  8.41s/it]Model Responding:  37%|‚ñà‚ñà‚ñà‚ñã      | 324/875 [46:19<1:18:37,  8.56s/it]Model Responding:  37%|‚ñà‚ñà‚ñà‚ñã      | 325/875 [46:28<1:20:04,  8.74s/it]Model Responding:  37%|‚ñà‚ñà‚ñà‚ñã      | 326/875 [46:37<1:19:50,  8.73s/it]Model Responding:  37%|‚ñà‚ñà‚ñà‚ñã      | 327/875 [46:45<1:18:32,  8.60s/it]Model Responding:  37%|‚ñà‚ñà‚ñà‚ñã      | 328/875 [46:54<1:19:08,  8.68s/it]Model Responding:  38%|‚ñà‚ñà‚ñà‚ñä      | 329/875 [47:03<1:18:31,  8.63s/it]Model Responding:  38%|‚ñà‚ñà‚ñà‚ñä      | 330/875 [47:11<1:17:55,  8.58s/it]Model Responding:  38%|‚ñà‚ñà‚ñà‚ñä      | 331/875 [47:20<1:19:37,  8.78s/it]Model Responding:  38%|‚ñà‚ñà‚ñà‚ñä      | 332/875 [47:30<1:20:58,  8.95s/it]Model Responding:  38%|‚ñà‚ñà‚ñà‚ñä      | 333/875 [47:39<1:21:52,  9.06s/it]Model Responding:  38%|‚ñà‚ñà‚ñà‚ñä      | 334/875 [47:48<1:22:05,  9.10s/it]Model Responding:  38%|‚ñà‚ñà‚ñà‚ñä      | 335/875 [47:58<1:23:16,  9.25s/it]Model Responding:  38%|‚ñà‚ñà‚ñà‚ñä      | 336/875 [48:07<1:22:28,  9.18s/it]Model Responding:  39%|‚ñà‚ñà‚ñà‚ñä      | 337/875 [48:16<1:21:15,  9.06s/it]Model Responding:  39%|‚ñà‚ñà‚ñà‚ñä      | 338/875 [48:25<1:21:57,  9.16s/it]Model Responding:  39%|‚ñà‚ñà‚ñà‚ñä      | 339/875 [48:34<1:21:31,  9.13s/it]Model Responding:  39%|‚ñà‚ñà‚ñà‚ñâ      | 340/875 [48:44<1:22:36,  9.26s/it]Model Responding:  39%|‚ñà‚ñà‚ñà‚ñâ      | 341/875 [48:53<1:23:16,  9.36s/it]Model Responding:  39%|‚ñà‚ñà‚ñà‚ñâ      | 342/875 [49:02<1:21:59,  9.23s/it]Model Responding:  39%|‚ñà‚ñà‚ñà‚ñâ      | 343/875 [49:11<1:20:40,  9.10s/it]Model Responding:  39%|‚ñà‚ñà‚ñà‚ñâ      | 344/875 [49:20<1:20:06,  9.05s/it]Model Responding:  39%|‚ñà‚ñà‚ñà‚ñâ      | 345/875 [49:29<1:19:30,  9.00s/it]Model Responding:  40%|‚ñà‚ñà‚ñà‚ñâ      | 346/875 [49:38<1:20:05,  9.08s/it]Model Responding:  40%|‚ñà‚ñà‚ñà‚ñâ      | 347/875 [49:47<1:18:16,  8.90s/it]Model Responding:  40%|‚ñà‚ñà‚ñà‚ñâ      | 348/875 [49:55<1:16:56,  8.76s/it]Model Responding:  40%|‚ñà‚ñà‚ñà‚ñâ      | 349/875 [50:04<1:15:54,  8.66s/it]Model Responding:  40%|‚ñà‚ñà‚ñà‚ñà      | 350/875 [50:12<1:16:00,  8.69s/it]Model Responding:  40%|‚ñà‚ñà‚ñà‚ñà      | 351/875 [50:21<1:16:34,  8.77s/it]Model Responding:  40%|‚ñà‚ñà‚ñà‚ñà      | 352/875 [50:30<1:17:35,  8.90s/it]Model Responding:  40%|‚ñà‚ñà‚ñà‚ñà      | 353/875 [50:39<1:17:23,  8.90s/it]Model Responding:  40%|‚ñà‚ñà‚ñà‚ñà      | 354/875 [50:48<1:16:04,  8.76s/it]Model Responding:  41%|‚ñà‚ñà‚ñà‚ñà      | 355/875 [50:57<1:17:00,  8.88s/it]Model Responding:  41%|‚ñà‚ñà‚ñà‚ñà      | 356/875 [51:06<1:17:25,  8.95s/it]Model Responding:  41%|‚ñà‚ñà‚ñà‚ñà      | 357/875 [51:15<1:16:04,  8.81s/it]Model Responding:  41%|‚ñà‚ñà‚ñà‚ñà      | 358/875 [51:23<1:16:08,  8.84s/it]Model Responding:  41%|‚ñà‚ñà‚ñà‚ñà      | 359/875 [51:32<1:15:27,  8.77s/it]Model Responding:  41%|‚ñà‚ñà‚ñà‚ñà      | 360/875 [51:41<1:15:31,  8.80s/it]Model Responding:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 361/875 [51:50<1:15:19,  8.79s/it]Model Responding:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 362/875 [51:59<1:16:37,  8.96s/it]Model Responding:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 363/875 [52:08<1:16:02,  8.91s/it]Model Responding:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 364/875 [52:16<1:14:44,  8.78s/it]Model Responding:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 365/875 [52:25<1:14:11,  8.73s/it]Model Responding:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 366/875 [52:33<1:13:17,  8.64s/it]Model Responding:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 367/875 [52:42<1:13:05,  8.63s/it]Model Responding:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 368/875 [52:51<1:13:17,  8.67s/it]Model Responding:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 369/875 [53:00<1:13:40,  8.74s/it]Model Responding:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 370/875 [53:09<1:14:42,  8.88s/it]Model Responding:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 371/875 [53:17<1:13:09,  8.71s/it]Model Responding:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 372/875 [53:26<1:13:23,  8.75s/it]Model Responding:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 373/875 [53:34<1:12:12,  8.63s/it]Model Responding:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 374/875 [53:43<1:11:24,  8.55s/it]Model Responding:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 375/875 [53:52<1:12:44,  8.73s/it]Model Responding:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 376/875 [54:01<1:13:01,  8.78s/it]Model Responding:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 377/875 [54:09<1:12:26,  8.73s/it]Model Responding:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 378/875 [54:18<1:12:02,  8.70s/it]Model Responding:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 379/875 [54:27<1:12:48,  8.81s/it]Model Responding:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 380/875 [54:36<1:11:55,  8.72s/it]Model Responding:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 381/875 [54:44<1:11:15,  8.66s/it]Model Responding:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 382/875 [54:53<1:11:39,  8.72s/it]Model Responding:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 383/875 [55:02<1:12:23,  8.83s/it]Model Responding:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 384/875 [55:12<1:15:05,  9.18s/it]Model Responding:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 385/875 [55:21<1:15:41,  9.27s/it]Model Responding:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 386/875 [55:31<1:16:43,  9.41s/it]Model Responding:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 387/875 [55:41<1:16:25,  9.40s/it]Model Responding:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 388/875 [55:50<1:16:13,  9.39s/it]Model Responding:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 389/875 [55:59<1:14:30,  9.20s/it]Model Responding:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 390/875 [56:07<1:13:07,  9.05s/it]Model Responding:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 391/875 [56:16<1:11:33,  8.87s/it]Model Responding:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 392/875 [56:24<1:09:51,  8.68s/it]Model Responding:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 393/875 [56:33<1:09:20,  8.63s/it]Model Responding:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 394/875 [56:42<1:11:59,  8.98s/it]Model Responding:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 395/875 [56:52<1:13:07,  9.14s/it]Model Responding:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 396/875 [57:01<1:11:36,  8.97s/it]Model Responding:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 397/875 [57:09<1:10:48,  8.89s/it]Model Responding:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 398/875 [57:18<1:10:45,  8.90s/it]Model Responding:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 399/875 [57:27<1:09:22,  8.74s/it]Model Responding:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 400/875 [57:35<1:08:20,  8.63s/it]Model Responding:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 401/875 [57:43<1:07:29,  8.54s/it]Model Responding:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 402/875 [57:52<1:07:32,  8.57s/it]Model Responding:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 403/875 [58:00<1:06:37,  8.47s/it]Model Responding:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 404/875 [58:10<1:09:10,  8.81s/it]Model Responding:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 405/875 [58:19<1:10:13,  8.97s/it]Model Responding:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 406/875 [58:28<1:10:18,  8.99s/it]Model Responding:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 407/875 [58:37<1:10:12,  9.00s/it]Model Responding:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 408/875 [58:46<1:09:11,  8.89s/it]Model Responding:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 409/875 [58:55<1:10:02,  9.02s/it]Model Responding:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 410/875 [59:04<1:09:19,  8.95s/it]Model Responding:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 411/875 [59:13<1:09:22,  8.97s/it]Model Responding:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 412/875 [59:22<1:08:54,  8.93s/it]Model Responding:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 413/875 [59:30<1:07:09,  8.72s/it]Model Responding:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 414/875 [59:39<1:06:56,  8.71s/it]Model Responding:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 415/875 [59:48<1:07:27,  8.80s/it]Model Responding:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 416/875 [59:56<1:07:12,  8.79s/it]Model Responding:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 417/875 [1:00:05<1:05:35,  8.59s/it]Model Responding:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 418/875 [1:00:13<1:05:02,  8.54s/it]Model Responding:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 419/875 [1:00:21<1:04:12,  8.45s/it]Model Responding:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 420/875 [1:00:31<1:06:44,  8.80s/it]Model Responding:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 421/875 [1:00:40<1:07:10,  8.88s/it]Model Responding:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 422/875 [1:00:49<1:06:47,  8.85s/it]Model Responding:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 423/875 [1:00:57<1:05:59,  8.76s/it]Model Responding:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 424/875 [1:01:06<1:04:52,  8.63s/it]Model Responding:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 425/875 [1:01:14<1:05:25,  8.72s/it]Model Responding:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 426/875 [1:01:24<1:06:23,  8.87s/it]Model Responding:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 427/875 [1:01:33<1:06:30,  8.91s/it]Model Responding:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 428/875 [1:01:41<1:06:03,  8.87s/it]Model Responding:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 429/875 [1:01:51<1:06:50,  8.99s/it]Model Responding:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 430/875 [1:02:00<1:07:29,  9.10s/it]Model Responding:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 431/875 [1:02:08<1:05:51,  8.90s/it]Model Responding:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 432/875 [1:02:17<1:05:15,  8.84s/it]Model Responding:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 433/875 [1:02:26<1:04:46,  8.79s/it]Model Responding:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 434/875 [1:02:35<1:05:24,  8.90s/it]Model Responding:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 435/875 [1:02:44<1:05:28,  8.93s/it]Model Responding:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 436/875 [1:02:53<1:06:16,  9.06s/it]Model Responding:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 437/875 [1:03:03<1:06:17,  9.08s/it]Model Responding:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 438/875 [1:03:11<1:05:22,  8.98s/it]Model Responding:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 439/875 [1:03:20<1:03:54,  8.79s/it]Model Responding:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 440/875 [1:03:28<1:03:02,  8.70s/it]Model Responding:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 441/875 [1:03:37<1:03:04,  8.72s/it]Model Responding:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 442/875 [1:03:46<1:04:22,  8.92s/it]Model Responding:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 443/875 [1:03:55<1:04:10,  8.91s/it]Model Responding:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 444/875 [1:04:03<1:02:25,  8.69s/it]Model Responding:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 445/875 [1:04:12<1:02:05,  8.66s/it]Model Responding:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 446/875 [1:04:20<1:01:37,  8.62s/it]Model Responding:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 447/875 [1:04:28<59:26,  8.33s/it]  Model Responding:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 448/875 [1:04:36<58:53,  8.27s/it]Model Responding:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 449/875 [1:04:45<59:01,  8.31s/it]Model Responding:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 450/875 [1:04:53<1:00:00,  8.47s/it]Model Responding:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 451/875 [1:05:03<1:01:13,  8.66s/it]Model Responding:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 452/875 [1:05:11<1:01:00,  8.65s/it]Model Responding:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 453/875 [1:05:20<1:01:38,  8.76s/it]Model Responding:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 454/875 [1:05:29<1:01:50,  8.81s/it]Model Responding:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 455/875 [1:05:39<1:03:15,  9.04s/it]Model Responding:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 456/875 [1:05:47<1:02:21,  8.93s/it]Model Responding:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 457/875 [1:05:56<1:02:04,  8.91s/it]Model Responding:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 458/875 [1:06:05<1:01:06,  8.79s/it]Model Responding:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 459/875 [1:06:13<1:00:21,  8.71s/it]Model Responding:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 460/875 [1:06:22<1:00:33,  8.76s/it]Model Responding:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 461/875 [1:06:31<1:00:21,  8.75s/it]Model Responding:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 462/875 [1:06:40<1:01:32,  8.94s/it]Model Responding:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 463/875 [1:06:50<1:02:22,  9.08s/it]Model Responding:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 464/875 [1:06:59<1:01:47,  9.02s/it]Model Responding:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 465/875 [1:07:08<1:01:54,  9.06s/it]Model Responding:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 466/875 [1:07:17<1:01:29,  9.02s/it]Model Responding:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 467/875 [1:07:25<59:57,  8.82s/it]  Model Responding:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 468/875 [1:07:34<59:24,  8.76s/it]Model Responding:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 469/875 [1:07:42<58:38,  8.67s/it]Model Responding:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 470/875 [1:07:51<59:22,  8.80s/it]Model Responding:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 471/875 [1:08:01<1:01:16,  9.10s/it]Model Responding:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 472/875 [1:08:09<59:31,  8.86s/it]  Model Responding:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 473/875 [1:08:18<59:49,  8.93s/it]Model Responding:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 474/875 [1:08:27<59:51,  8.96s/it]Model Responding:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 475/875 [1:08:37<1:00:13,  9.03s/it]Model Responding:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 476/875 [1:08:45<59:44,  8.98s/it]  Model Responding:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 477/875 [1:08:54<59:21,  8.95s/it]Model Responding:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 478/875 [1:09:03<58:25,  8.83s/it]Model Responding:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 479/875 [1:09:11<57:38,  8.73s/it]Model Responding:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 480/875 [1:09:20<57:45,  8.77s/it]Model Responding:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 481/875 [1:09:29<57:54,  8.82s/it]Model Responding:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 482/875 [1:09:38<57:59,  8.85s/it]Model Responding:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 483/875 [1:09:47<58:30,  8.95s/it]Model Responding:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 484/875 [1:09:56<58:42,  9.01s/it]Model Responding:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 485/875 [1:10:05<57:59,  8.92s/it]Model Responding:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 486/875 [1:10:14<57:30,  8.87s/it]Model Responding:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 487/875 [1:10:24<58:46,  9.09s/it]Model Responding:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 488/875 [1:10:32<58:03,  9.00s/it]Model Responding:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 489/875 [1:10:41<57:00,  8.86s/it]Model Responding:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 490/875 [1:10:49<55:46,  8.69s/it]Model Responding:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 491/875 [1:10:58<55:58,  8.75s/it]Model Responding:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 492/875 [1:11:07<55:56,  8.76s/it]Model Responding:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 493/875 [1:11:15<54:54,  8.62s/it]Model Responding:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 494/875 [1:11:23<53:43,  8.46s/it]Model Responding:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 495/875 [1:11:31<53:01,  8.37s/it]Model Responding:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 496/875 [1:11:40<53:28,  8.46s/it]Model Responding:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 497/875 [1:11:48<52:38,  8.36s/it]Model Responding:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 498/875 [1:11:56<52:28,  8.35s/it]Model Responding:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 499/875 [1:12:05<52:14,  8.34s/it]Model Responding:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 500/875 [1:12:13<51:44,  8.28s/it]Model Responding:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 501/875 [1:12:21<51:14,  8.22s/it]Model Responding:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 502/875 [1:12:29<51:07,  8.22s/it]Model Responding:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 503/875 [1:12:38<52:34,  8.48s/it]Model Responding:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 504/875 [1:12:47<53:04,  8.58s/it]Model Responding:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 505/875 [1:12:57<55:10,  8.95s/it]Model Responding:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 506/875 [1:13:05<54:04,  8.79s/it]Model Responding:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 507/875 [1:13:15<54:39,  8.91s/it]Model Responding:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 508/875 [1:13:23<53:35,  8.76s/it]Model Responding:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 509/875 [1:13:31<52:42,  8.64s/it]Model Responding:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 510/875 [1:13:40<52:35,  8.65s/it]Model Responding:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 511/875 [1:13:48<52:02,  8.58s/it]Model Responding:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 512/875 [1:13:57<51:30,  8.51s/it]Model Responding:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 513/875 [1:14:05<51:22,  8.51s/it]Model Responding:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 514/875 [1:14:14<51:09,  8.50s/it]Model Responding:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 515/875 [1:14:22<51:03,  8.51s/it]Model Responding:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 516/875 [1:14:31<50:42,  8.48s/it]Model Responding:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 517/875 [1:14:39<49:44,  8.34s/it]Model Responding:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 518/875 [1:14:47<50:01,  8.41s/it]Model Responding:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 519/875 [1:14:56<51:09,  8.62s/it]Model Responding:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 520/875 [1:15:05<51:44,  8.75s/it]Model Responding:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 521/875 [1:15:14<51:07,  8.66s/it]Model Responding:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 522/875 [1:15:22<50:33,  8.59s/it]Model Responding:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 523/875 [1:15:30<49:32,  8.44s/it]Model Responding:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 524/875 [1:15:39<49:28,  8.46s/it]Model Responding:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 525/875 [1:15:48<49:36,  8.50s/it]Model Responding:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 526/875 [1:15:56<49:02,  8.43s/it]Model Responding:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 527/875 [1:16:04<48:34,  8.37s/it]Model Responding:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 528/875 [1:16:12<48:09,  8.33s/it]Model Responding:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 529/875 [1:16:21<48:14,  8.36s/it]Model Responding:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 530/875 [1:16:29<48:26,  8.43s/it]Model Responding:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 531/875 [1:16:38<48:34,  8.47s/it]Model Responding:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 532/875 [1:16:46<48:25,  8.47s/it]Model Responding:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 533/875 [1:16:55<48:05,  8.44s/it]Model Responding:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 534/875 [1:17:03<47:14,  8.31s/it]Model Responding:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 535/875 [1:17:11<47:27,  8.37s/it]Model Responding:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 536/875 [1:17:19<47:09,  8.35s/it]Model Responding:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 537/875 [1:17:29<48:35,  8.62s/it]Model Responding:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 538/875 [1:17:38<49:18,  8.78s/it]Model Responding:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 539/875 [1:17:47<48:55,  8.74s/it]Model Responding:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 540/875 [1:17:56<50:44,  9.09s/it]Model Responding:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 541/875 [1:18:06<50:35,  9.09s/it]Model Responding:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 542/875 [1:18:14<49:58,  9.00s/it]Model Responding:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 543/875 [1:18:23<48:35,  8.78s/it]Model Responding:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 544/875 [1:18:31<48:35,  8.81s/it]Model Responding:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 545/875 [1:18:40<47:41,  8.67s/it]Model Responding:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 546/875 [1:18:48<46:56,  8.56s/it]Model Responding:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 547/875 [1:18:57<46:44,  8.55s/it]Model Responding:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 548/875 [1:19:05<46:57,  8.62s/it]Model Responding:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 549/875 [1:19:14<46:18,  8.52s/it]Model Responding:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 550/875 [1:19:22<46:14,  8.54s/it]Model Responding:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 551/875 [1:19:30<44:48,  8.30s/it]Model Responding:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 552/875 [1:19:38<44:32,  8.27s/it]Model Responding:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 553/875 [1:19:47<44:55,  8.37s/it]Model Responding:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 554/875 [1:19:56<45:38,  8.53s/it]Model Responding:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 555/875 [1:20:04<45:03,  8.45s/it]Model Responding:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 556/875 [1:20:12<44:41,  8.41s/it]Model Responding:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 557/875 [1:20:21<44:50,  8.46s/it]Model Responding:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 558/875 [1:20:30<44:58,  8.51s/it]Model Responding:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 559/875 [1:20:38<44:05,  8.37s/it]Model Responding:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 560/875 [1:20:46<44:20,  8.45s/it]Model Responding:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 561/875 [1:20:55<44:29,  8.50s/it]Model Responding:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 562/875 [1:21:03<44:09,  8.46s/it]Model Responding:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 563/875 [1:21:12<44:08,  8.49s/it]Model Responding:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 564/875 [1:21:20<43:43,  8.44s/it]Model Responding:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 565/875 [1:21:29<44:35,  8.63s/it]Model Responding:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 566/875 [1:21:38<45:21,  8.81s/it]Model Responding:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 567/875 [1:21:47<44:15,  8.62s/it]Model Responding:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 568/875 [1:21:55<44:32,  8.71s/it]Model Responding:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 569/875 [1:22:03<43:01,  8.44s/it]Model Responding:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 570/875 [1:22:12<43:09,  8.49s/it]Model Responding:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 571/875 [1:22:21<43:34,  8.60s/it]Model Responding:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 572/875 [1:22:30<44:06,  8.73s/it]Model Responding:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 573/875 [1:22:38<43:32,  8.65s/it]Model Responding:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 574/875 [1:22:47<43:20,  8.64s/it]Model Responding:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 575/875 [1:22:56<43:45,  8.75s/it]Model Responding:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 576/875 [1:23:04<43:17,  8.69s/it]Model Responding:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 577/875 [1:23:13<42:57,  8.65s/it]Model Responding:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 578/875 [1:23:22<42:55,  8.67s/it]Model Responding:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 579/875 [1:23:31<42:56,  8.70s/it]Model Responding:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 580/875 [1:23:39<42:25,  8.63s/it]Model Responding:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 581/875 [1:23:47<41:39,  8.50s/it]Model Responding:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 582/875 [1:23:56<42:43,  8.75s/it]Model Responding:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 583/875 [1:24:05<41:55,  8.61s/it]Model Responding:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 584/875 [1:24:13<41:11,  8.49s/it]Model Responding:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 585/875 [1:24:21<40:04,  8.29s/it]Model Responding:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 586/875 [1:24:30<40:45,  8.46s/it]Model Responding:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 587/875 [1:24:38<39:58,  8.33s/it]Model Responding:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 588/875 [1:24:46<39:56,  8.35s/it]Model Responding:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 589/875 [1:24:55<40:35,  8.52s/it]Model Responding:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 590/875 [1:25:05<42:01,  8.85s/it]Model Responding:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 591/875 [1:25:13<41:11,  8.70s/it]Model Responding:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 592/875 [1:25:22<40:55,  8.68s/it]Model Responding:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 593/875 [1:25:30<40:36,  8.64s/it]Model Responding:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 594/875 [1:25:38<39:45,  8.49s/it]Model Responding:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 595/875 [1:25:47<39:25,  8.45s/it]Model Responding:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 596/875 [1:25:56<40:27,  8.70s/it]Model Responding:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 597/875 [1:26:06<41:44,  9.01s/it]Model Responding:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 598/875 [1:26:14<40:28,  8.77s/it]Model Responding:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 599/875 [1:26:22<39:55,  8.68s/it]Model Responding:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 600/875 [1:26:31<40:15,  8.78s/it]Model Responding:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 601/875 [1:26:40<40:27,  8.86s/it]Model Responding:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 602/875 [1:26:49<40:01,  8.80s/it]Model Responding:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 603/875 [1:26:58<39:33,  8.73s/it]Model Responding:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 604/875 [1:27:06<39:13,  8.68s/it]Model Responding:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 605/875 [1:27:15<38:47,  8.62s/it]Model Responding:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 606/875 [1:27:23<37:58,  8.47s/it]Model Responding:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 607/875 [1:27:31<37:20,  8.36s/it]Model Responding:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 608/875 [1:27:39<37:18,  8.38s/it]Model Responding:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 609/875 [1:27:48<36:56,  8.33s/it]Model Responding:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 610/875 [1:27:56<37:22,  8.46s/it]Model Responding:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 611/875 [1:28:05<37:11,  8.45s/it]Model Responding:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 612/875 [1:28:13<36:58,  8.44s/it]Model Responding:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 613/875 [1:28:22<37:11,  8.52s/it]Model Responding:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 614/875 [1:28:30<36:28,  8.39s/it]Model Responding:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 615/875 [1:28:39<36:41,  8.47s/it]Model Responding:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 616/875 [1:28:47<36:07,  8.37s/it]Model Responding:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 617/875 [1:28:55<36:08,  8.41s/it]Model Responding:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 618/875 [1:29:04<36:11,  8.45s/it]Model Responding:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 619/875 [1:29:12<36:01,  8.44s/it]Model Responding:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 620/875 [1:29:21<35:45,  8.42s/it]Model Responding:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 621/875 [1:29:28<35:00,  8.27s/it]Model Responding:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 622/875 [1:29:37<34:58,  8.29s/it]Model Responding:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 623/875 [1:29:45<34:33,  8.23s/it]Model Responding:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 624/875 [1:29:54<34:53,  8.34s/it]Model Responding:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 625/875 [1:30:02<34:43,  8.33s/it]Model Responding:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 626/875 [1:30:10<34:41,  8.36s/it]Model Responding:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 627/875 [1:30:19<34:51,  8.43s/it]Model Responding:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 628/875 [1:30:27<34:47,  8.45s/it]Model Responding:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 629/875 [1:30:36<34:52,  8.51s/it]Model Responding:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 630/875 [1:30:45<35:08,  8.61s/it]Model Responding:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 631/875 [1:30:54<35:26,  8.71s/it]Model Responding:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 632/875 [1:31:02<35:15,  8.71s/it]Model Responding:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 633/875 [1:31:11<35:13,  8.73s/it]Model Responding:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 634/875 [1:31:19<34:14,  8.53s/it]Model Responding:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 635/875 [1:31:27<33:32,  8.38s/it]Model Responding:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 636/875 [1:31:36<33:24,  8.39s/it]Model Responding:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 637/875 [1:31:44<33:04,  8.34s/it]Model Responding:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 638/875 [1:31:53<33:25,  8.46s/it]Model Responding:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 639/875 [1:32:01<33:23,  8.49s/it]Model Responding:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 640/875 [1:32:09<32:50,  8.39s/it]Model Responding:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 641/875 [1:32:18<32:50,  8.42s/it]Model Responding:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 642/875 [1:32:26<32:16,  8.31s/it]Model Responding:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 643/875 [1:32:35<32:32,  8.42s/it]Model Responding:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 644/875 [1:32:44<33:06,  8.60s/it]Model Responding:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 645/875 [1:32:53<33:40,  8.79s/it]Model Responding:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 646/875 [1:33:02<33:23,  8.75s/it]Model Responding:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 647/875 [1:33:10<32:42,  8.61s/it]Model Responding:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 648/875 [1:33:18<32:03,  8.48s/it]Model Responding:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 649/875 [1:33:27<31:59,  8.49s/it]Model Responding:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 650/875 [1:33:36<32:48,  8.75s/it]Model Responding:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 651/875 [1:33:45<33:00,  8.84s/it]Model Responding:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 652/875 [1:33:54<33:19,  8.97s/it]Model Responding:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 653/875 [1:34:03<33:20,  9.01s/it]Model Responding:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 654/875 [1:34:12<32:17,  8.77s/it]Model Responding:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 655/875 [1:34:20<31:48,  8.68s/it]Model Responding:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 656/875 [1:34:29<31:32,  8.64s/it]Model Responding:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 657/875 [1:34:38<31:50,  8.76s/it]Model Responding:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 658/875 [1:34:46<31:15,  8.64s/it]Model Responding:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 659/875 [1:34:55<31:22,  8.72s/it]Model Responding:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 660/875 [1:35:03<31:06,  8.68s/it]Model Responding:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 661/875 [1:35:12<30:44,  8.62s/it]Model Responding:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 662/875 [1:35:20<30:24,  8.57s/it]Model Responding:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 663/875 [1:35:29<30:09,  8.53s/it]Model Responding:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 664/875 [1:35:37<29:30,  8.39s/it]Model Responding:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 665/875 [1:35:45<28:53,  8.25s/it]Model Responding:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 666/875 [1:35:53<29:02,  8.34s/it]Model Responding:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 667/875 [1:36:02<29:03,  8.38s/it]Model Responding:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 668/875 [1:36:11<29:37,  8.59s/it]Model Responding:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 669/875 [1:36:20<29:37,  8.63s/it]Model Responding:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 670/875 [1:36:28<29:12,  8.55s/it]Model Responding:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 671/875 [1:36:36<29:01,  8.54s/it]Model Responding:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 672/875 [1:36:45<28:35,  8.45s/it]Model Responding:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 673/875 [1:36:53<28:35,  8.49s/it]Model Responding:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 674/875 [1:37:02<28:47,  8.59s/it]Model Responding:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 675/875 [1:37:10<28:06,  8.43s/it]Model Responding:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 676/875 [1:37:18<27:31,  8.30s/it]Model Responding:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 677/875 [1:37:27<28:14,  8.56s/it]Model Responding:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 678/875 [1:37:36<28:24,  8.65s/it]Model Responding:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 679/875 [1:37:45<28:17,  8.66s/it]Model Responding:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 680/875 [1:37:54<28:41,  8.83s/it]Model Responding:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 681/875 [1:38:03<28:43,  8.88s/it]Model Responding:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 682/875 [1:38:12<28:12,  8.77s/it]Model Responding:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 683/875 [1:38:20<27:45,  8.67s/it]Model Responding:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 684/875 [1:38:29<27:44,  8.71s/it]Model Responding:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 685/875 [1:38:38<27:30,  8.69s/it]Model Responding:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 686/875 [1:38:47<27:50,  8.84s/it]Model Responding:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 687/875 [1:38:56<28:05,  8.97s/it]Model Responding:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 688/875 [1:39:04<27:28,  8.82s/it]Model Responding:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 689/875 [1:39:14<27:35,  8.90s/it]Model Responding:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 690/875 [1:39:22<27:12,  8.82s/it]Model Responding:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 691/875 [1:39:31<26:37,  8.68s/it]Model Responding:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 692/875 [1:39:39<26:35,  8.72s/it]Model Responding:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 693/875 [1:39:48<26:07,  8.61s/it]Model Responding:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 694/875 [1:39:56<26:06,  8.66s/it]Model Responding:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 695/875 [1:40:05<26:03,  8.68s/it]Model Responding:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 696/875 [1:40:14<26:08,  8.76s/it]Model Responding:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 697/875 [1:40:23<25:49,  8.70s/it]Model Responding:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 698/875 [1:40:31<25:33,  8.66s/it]Model Responding:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 699/875 [1:40:40<25:30,  8.69s/it]Model Responding:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 700/875 [1:40:48<24:35,  8.43s/it]Model Responding:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 701/875 [1:40:56<24:24,  8.41s/it]Model Responding:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 702/875 [1:41:05<24:31,  8.51s/it]Model Responding:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 703/875 [1:41:13<24:06,  8.41s/it]Model Responding:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 704/875 [1:41:22<24:01,  8.43s/it]Model Responding:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 705/875 [1:41:30<23:39,  8.35s/it]Model Responding:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 706/875 [1:41:39<24:04,  8.54s/it]Model Responding:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 707/875 [1:41:48<24:04,  8.60s/it]Model Responding:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 708/875 [1:41:56<23:49,  8.56s/it]Model Responding:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 709/875 [1:42:05<23:57,  8.66s/it]Model Responding:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 710/875 [1:42:13<23:33,  8.57s/it]Model Responding:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 711/875 [1:42:22<23:27,  8.58s/it]Model Responding:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 712/875 [1:42:30<23:07,  8.51s/it]Model Responding:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 713/875 [1:42:38<22:48,  8.45s/it]Model Responding:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 714/875 [1:42:47<22:32,  8.40s/it]Model Responding:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 715/875 [1:42:56<22:40,  8.51s/it]Model Responding:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 716/875 [1:43:04<22:32,  8.50s/it]Model Responding:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 717/875 [1:43:12<22:05,  8.39s/it]Model Responding:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 718/875 [1:43:21<22:16,  8.51s/it]Model Responding:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 719/875 [1:43:30<22:37,  8.70s/it]Model Responding:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 720/875 [1:43:39<22:34,  8.74s/it]Model Responding:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 721/875 [1:43:47<22:01,  8.58s/it]Model Responding:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 722/875 [1:43:56<22:03,  8.65s/it]Model Responding:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 723/875 [1:44:04<21:50,  8.62s/it]Model Responding:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 724/875 [1:44:14<22:06,  8.78s/it]Model Responding:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 725/875 [1:44:22<21:38,  8.66s/it]Model Responding:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 726/875 [1:44:30<21:05,  8.50s/it]Model Responding:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 727/875 [1:44:38<20:50,  8.45s/it]Model Responding:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 728/875 [1:44:47<20:33,  8.39s/it]Model Responding:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 729/875 [1:44:56<20:44,  8.53s/it]Model Responding:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 730/875 [1:45:05<20:54,  8.65s/it]Model Responding:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 731/875 [1:45:13<20:50,  8.69s/it]Model Responding:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 732/875 [1:45:22<20:50,  8.74s/it]Model Responding:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 733/875 [1:45:31<20:26,  8.64s/it]Model Responding:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 734/875 [1:45:39<20:03,  8.53s/it]Model Responding:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 735/875 [1:45:47<19:54,  8.53s/it]Model Responding:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 736/875 [1:45:57<20:27,  8.83s/it]Model Responding:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 737/875 [1:46:06<20:25,  8.88s/it]Model Responding:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 738/875 [1:46:15<20:44,  9.08s/it]Model Responding:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 739/875 [1:46:25<21:09,  9.33s/it]Model Responding:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 740/875 [1:46:34<20:22,  9.05s/it]Model Responding:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 741/875 [1:46:42<19:57,  8.94s/it]Model Responding:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 742/875 [1:46:51<19:41,  8.88s/it]Model Responding:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 743/875 [1:47:00<19:17,  8.77s/it]Model Responding:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 744/875 [1:47:09<19:28,  8.92s/it]Model Responding:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 745/875 [1:47:18<19:27,  8.98s/it]Model Responding:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 746/875 [1:47:27<19:09,  8.91s/it]Model Responding:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 747/875 [1:47:36<19:02,  8.93s/it]Model Responding:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 748/875 [1:47:45<19:03,  9.01s/it]Model Responding:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 749/875 [1:47:54<19:07,  9.11s/it]Model Responding:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 750/875 [1:48:03<18:53,  9.07s/it]Model Responding:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 751/875 [1:48:12<18:41,  9.04s/it]Model Responding:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 752/875 [1:48:21<18:17,  8.93s/it]Model Responding:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 753/875 [1:48:30<18:27,  9.08s/it]Model Responding:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 754/875 [1:48:39<18:08,  9.00s/it]Model Responding:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 755/875 [1:48:48<17:58,  8.99s/it]Model Responding:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 756/875 [1:48:57<17:55,  9.04s/it]Model Responding:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 757/875 [1:49:07<18:00,  9.16s/it]Model Responding:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 758/875 [1:49:16<17:38,  9.05s/it]Model Responding:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 759/875 [1:49:24<17:16,  8.94s/it]Model Responding:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 760/875 [1:49:33<17:10,  8.96s/it]Model Responding:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 761/875 [1:49:42<17:05,  9.00s/it]Model Responding:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 762/875 [1:49:51<16:31,  8.78s/it]Model Responding:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 763/875 [1:49:59<16:09,  8.65s/it]Model Responding:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 764/875 [1:50:07<15:30,  8.39s/it]Model Responding:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 765/875 [1:50:15<15:19,  8.36s/it]Model Responding:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 766/875 [1:50:23<15:09,  8.34s/it]Model Responding:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 767/875 [1:50:31<14:51,  8.26s/it]Model Responding:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 768/875 [1:50:40<14:53,  8.35s/it]Model Responding:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 769/875 [1:50:48<14:50,  8.40s/it]Model Responding:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 770/875 [1:50:57<14:40,  8.39s/it]Model Responding:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 771/875 [1:51:05<14:28,  8.35s/it]Model Responding:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 772/875 [1:51:14<14:29,  8.44s/it]Model Responding:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 773/875 [1:51:22<14:29,  8.53s/it]Model Responding:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 774/875 [1:51:31<14:32,  8.64s/it]Model Responding:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 775/875 [1:51:40<14:29,  8.70s/it]Model Responding:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 776/875 [1:51:49<14:17,  8.66s/it]Model Responding:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 777/875 [1:51:57<14:06,  8.64s/it]Model Responding:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 778/875 [1:52:05<13:41,  8.47s/it]Model Responding:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 779/875 [1:52:14<13:28,  8.43s/it]Model Responding:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 780/875 [1:52:23<13:40,  8.64s/it]Model Responding:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 781/875 [1:52:32<13:40,  8.72s/it]Model Responding:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 782/875 [1:52:41<13:32,  8.74s/it]Model Responding:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 783/875 [1:52:49<13:28,  8.79s/it]Model Responding:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 784/875 [1:52:58<13:18,  8.77s/it]Model Responding:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 785/875 [1:53:07<13:11,  8.79s/it]Model Responding:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 786/875 [1:53:16<12:53,  8.69s/it]Model Responding:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 787/875 [1:53:25<12:54,  8.80s/it]Model Responding:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 788/875 [1:53:34<12:49,  8.84s/it]Model Responding:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 789/875 [1:53:42<12:40,  8.84s/it]Model Responding:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 790/875 [1:53:52<12:48,  9.04s/it]Model Responding:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 791/875 [1:54:00<12:27,  8.90s/it]Model Responding:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 792/875 [1:54:09<12:19,  8.91s/it]Model Responding:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 793/875 [1:54:18<12:00,  8.78s/it]Model Responding:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 794/875 [1:54:27<11:49,  8.76s/it]Model Responding:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 795/875 [1:54:35<11:43,  8.79s/it]Model Responding:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 796/875 [1:54:44<11:35,  8.80s/it]Model Responding:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 797/875 [1:54:53<11:32,  8.88s/it]Model Responding:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 798/875 [1:55:02<11:19,  8.82s/it]Model Responding:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 799/875 [1:55:11<11:10,  8.82s/it]Model Responding:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 800/875 [1:55:19<10:47,  8.64s/it]Model Responding:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 801/875 [1:55:27<10:28,  8.49s/it]Model Responding:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 802/875 [1:55:35<10:14,  8.41s/it]Model Responding:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 803/875 [1:55:44<10:14,  8.53s/it]Model Responding:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 804/875 [1:55:54<10:29,  8.87s/it]Model Responding:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 805/875 [1:56:03<10:19,  8.86s/it]Model Responding:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 806/875 [1:56:11<10:04,  8.77s/it]Model Responding:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 807/875 [1:56:20<09:51,  8.69s/it]Model Responding:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 808/875 [1:56:29<09:53,  8.85s/it]Model Responding:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 809/875 [1:56:38<09:51,  8.96s/it]Model Responding:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 810/875 [1:56:47<09:44,  9.00s/it]Model Responding:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 811/875 [1:56:57<09:43,  9.11s/it]Model Responding:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 812/875 [1:57:07<09:56,  9.46s/it]Model Responding:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 813/875 [1:57:17<09:52,  9.56s/it]Model Responding:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 814/875 [1:57:26<09:33,  9.41s/it]Model Responding:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 815/875 [1:57:34<08:57,  8.96s/it]Model Responding:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 816/875 [1:57:42<08:36,  8.76s/it]Model Responding:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 817/875 [1:57:51<08:25,  8.71s/it]Model Responding:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 818/875 [1:57:59<08:04,  8.49s/it]Model Responding:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 819/875 [1:58:07<07:48,  8.36s/it]Model Responding:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 820/875 [1:58:15<07:42,  8.41s/it]Model Responding:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 821/875 [1:58:23<07:31,  8.36s/it]Model Responding:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 822/875 [1:58:32<07:27,  8.43s/it]Model Responding:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 823/875 [1:58:40<07:19,  8.45s/it]Model Responding:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 824/875 [1:58:49<07:16,  8.55s/it]Model Responding:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 825/875 [1:58:58<07:13,  8.67s/it]Model Responding:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 826/875 [1:59:06<06:58,  8.54s/it]Model Responding:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 827/875 [1:59:15<06:49,  8.53s/it]Model Responding:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 828/875 [1:59:23<06:32,  8.35s/it]Model Responding:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 829/875 [1:59:31<06:25,  8.39s/it]Model Responding:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 830/875 [1:59:40<06:18,  8.41s/it]Model Responding:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 831/875 [1:59:48<06:06,  8.32s/it]Model Responding:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 832/875 [1:59:56<05:58,  8.33s/it]Model Responding:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 833/875 [2:00:05<05:55,  8.47s/it]Model Responding:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 834/875 [2:00:13<05:37,  8.24s/it]Model Responding:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 835/875 [2:00:21<05:30,  8.26s/it]Model Responding:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 836/875 [2:00:29<05:23,  8.29s/it]Model Responding:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 837/875 [2:00:38<05:18,  8.37s/it]Model Responding:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 838/875 [2:00:47<05:12,  8.46s/it]Model Responding:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 839/875 [2:00:56<05:12,  8.68s/it]Model Responding:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 840/875 [2:01:04<04:58,  8.54s/it]Model Responding:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 841/875 [2:01:12<04:44,  8.38s/it]Model Responding:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 842/875 [2:01:21<04:44,  8.61s/it]Model Responding:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 843/875 [2:01:31<04:42,  8.82s/it]Model Responding:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 844/875 [2:01:40<04:34,  8.86s/it]Model Responding:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 845/875 [2:01:49<04:30,  9.02s/it]Model Responding:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 846/875 [2:01:58<04:20,  9.00s/it]Model Responding:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 847/875 [2:02:06<04:07,  8.83s/it]Model Responding:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 848/875 [2:02:14<03:53,  8.65s/it]Model Responding:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 849/875 [2:02:23<03:44,  8.62s/it]Model Responding:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 850/875 [2:02:32<03:36,  8.65s/it]Model Responding:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 851/875 [2:02:41<03:28,  8.70s/it]Model Responding:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 852/875 [2:02:49<03:16,  8.56s/it]Model Responding:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 853/875 [2:02:58<03:11,  8.70s/it]Model Responding:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 854/875 [2:03:06<02:59,  8.56s/it]Model Responding:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 855/875 [2:03:15<02:51,  8.57s/it]Model Responding:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 856/875 [2:03:23<02:42,  8.53s/it]Model Responding:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 857/875 [2:03:31<02:32,  8.47s/it]Model Responding:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 858/875 [2:03:40<02:24,  8.48s/it]Model Responding:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 859/875 [2:03:48<02:14,  8.39s/it]Model Responding:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 860/875 [2:03:57<02:06,  8.43s/it]Model Responding:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 861/875 [2:04:05<01:59,  8.50s/it]Model Responding:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 862/875 [2:04:13<01:49,  8.40s/it]Model Responding:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 863/875 [2:04:21<01:38,  8.23s/it]Model Responding:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 864/875 [2:04:30<01:31,  8.30s/it]Model Responding:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 865/875 [2:04:38<01:23,  8.33s/it]Model Responding:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 866/875 [2:04:47<01:15,  8.38s/it]Model Responding:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 867/875 [2:04:56<01:08,  8.57s/it]Model Responding:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 868/875 [2:05:04<00:58,  8.35s/it]Model Responding:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 869/875 [2:05:12<00:50,  8.39s/it]Model Responding:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 870/875 [2:05:21<00:42,  8.54s/it]Model Responding: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 871/875 [2:05:29<00:34,  8.52s/it]Model Responding: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 872/875 [2:05:39<00:26,  8.77s/it]Model Responding: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 873/875 [2:05:48<00:17,  8.79s/it]Model Responding: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 874/875 [2:05:57<00:08,  8.92s/it]Model Responding: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 875/875 [2:06:05<00:00,  8.82s/it]Model Responding: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 875/875 [2:06:05<00:00,  8.65s/it]
Postprocessing:   0%|          | 0/125 [00:00<?, ?it/s]Postprocessing:   8%|‚ñä         | 10/125 [00:00<00:01, 97.29it/s]Postprocessing:  16%|‚ñà‚ñå        | 20/125 [00:00<00:01, 93.79it/s]Postprocessing:  25%|‚ñà‚ñà‚ñç       | 31/125 [00:00<00:00, 98.09it/s]Postprocessing:  34%|‚ñà‚ñà‚ñà‚ñç      | 43/125 [00:00<00:00, 102.21it/s]Postprocessing:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 54/125 [00:00<00:00, 102.31it/s]Postprocessing:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 65/125 [00:00<00:00, 99.45it/s] Postprocessing:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 76/125 [00:00<00:00, 101.48it/s]Postprocessing:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 87/125 [00:00<00:00, 102.97it/s]Postprocessing:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 98/125 [00:00<00:00, 102.01it/s]Postprocessing:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 109/125 [00:01<00:00, 103.22it/s]Postprocessing:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 120/125 [00:01<00:00, 99.87it/s] Postprocessing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [00:01<00:00, 100.20it/s]
Postprocessing:   0%|          | 0/750 [00:00<?, ?it/s]Postprocessing:   2%|‚ñè         | 14/750 [00:00<00:05, 127.33it/s]Postprocessing:   4%|‚ñé         | 27/750 [00:00<00:06, 115.31it/s]Postprocessing:   5%|‚ñå         | 40/750 [00:00<00:05, 118.34it/s]Postprocessing:   7%|‚ñã         | 52/750 [00:00<00:06, 115.83it/s]Postprocessing:   9%|‚ñä         | 64/750 [00:00<00:05, 116.56it/s]Postprocessing:  10%|‚ñà         | 76/750 [00:00<00:05, 115.35it/s]Postprocessing:  12%|‚ñà‚ñè        | 88/750 [00:00<00:06, 104.85it/s]Postprocessing:  13%|‚ñà‚ñé        | 99/750 [00:00<00:06, 98.79it/s] Postprocessing:  15%|‚ñà‚ñç        | 112/750 [00:01<00:06, 106.11it/s]Postprocessing:  16%|‚ñà‚ñã        | 123/750 [00:01<00:06, 104.43it/s]Postprocessing:  18%|‚ñà‚ñä        | 134/750 [00:01<00:06, 99.83it/s] Postprocessing:  19%|‚ñà‚ñâ        | 146/750 [00:01<00:05, 104.85it/s]Postprocessing:  21%|‚ñà‚ñà        | 159/750 [00:01<00:05, 110.61it/s]Postprocessing:  23%|‚ñà‚ñà‚ñé       | 171/750 [00:01<00:05, 109.33it/s]Postprocessing:  24%|‚ñà‚ñà‚ñç       | 183/750 [00:01<00:05, 106.90it/s]Postprocessing:  26%|‚ñà‚ñà‚ñå       | 194/750 [00:01<00:05, 107.39it/s]Postprocessing:  27%|‚ñà‚ñà‚ñã       | 205/750 [00:01<00:05, 102.24it/s]Postprocessing:  29%|‚ñà‚ñà‚ñâ       | 216/750 [00:02<00:05, 102.55it/s]Postprocessing:  31%|‚ñà‚ñà‚ñà       | 230/750 [00:02<00:04, 112.34it/s]Postprocessing:  32%|‚ñà‚ñà‚ñà‚ñè      | 242/750 [00:02<00:04, 112.74it/s]Postprocessing:  34%|‚ñà‚ñà‚ñà‚ñç      | 254/750 [00:02<00:04, 114.64it/s]Postprocessing:  35%|‚ñà‚ñà‚ñà‚ñå      | 266/750 [00:02<00:04, 112.89it/s]Postprocessing:  37%|‚ñà‚ñà‚ñà‚ñã      | 278/750 [00:02<00:04, 110.42it/s]Postprocessing:  39%|‚ñà‚ñà‚ñà‚ñä      | 290/750 [00:02<00:04, 107.91it/s]Postprocessing:  40%|‚ñà‚ñà‚ñà‚ñà      | 301/750 [00:02<00:04, 105.98it/s]Postprocessing:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 313/750 [00:02<00:03, 109.84it/s]Postprocessing:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 325/750 [00:02<00:03, 107.46it/s]Postprocessing:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 336/750 [00:03<00:03, 104.11it/s]Postprocessing:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 347/750 [00:03<00:04, 100.15it/s]Postprocessing:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 358/750 [00:03<00:03, 98.86it/s] Postprocessing:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 368/750 [00:03<00:03, 96.80it/s]Postprocessing:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 379/750 [00:03<00:03, 99.34it/s]Postprocessing:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 389/750 [00:03<00:03, 94.61it/s]Postprocessing:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 400/750 [00:03<00:03, 95.72it/s]Postprocessing:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 410/750 [00:03<00:03, 95.87it/s]Postprocessing:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 421/750 [00:03<00:03, 98.41it/s]Postprocessing:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 434/750 [00:04<00:03, 104.77it/s]Postprocessing:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 446/750 [00:04<00:02, 108.54it/s]Postprocessing:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 457/750 [00:04<00:02, 103.17it/s]Postprocessing:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 469/750 [00:04<00:02, 107.29it/s]Postprocessing:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 480/750 [00:04<00:02, 105.67it/s]Postprocessing:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 492/750 [00:04<00:02, 107.02it/s]Postprocessing:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 505/750 [00:04<00:02, 111.82it/s]Postprocessing:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 517/750 [00:04<00:02, 110.81it/s]Postprocessing:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 529/750 [00:04<00:02, 107.30it/s]Postprocessing:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 541/750 [00:05<00:01, 110.78it/s]Postprocessing:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 554/750 [00:05<00:01, 115.81it/s]Postprocessing:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 567/750 [00:05<00:01, 116.68it/s]Postprocessing:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 579/750 [00:05<00:01, 109.83it/s]Postprocessing:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 592/750 [00:05<00:01, 112.90it/s]Postprocessing:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 604/750 [00:05<00:01, 104.86it/s]Postprocessing:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 615/750 [00:05<00:01, 104.95it/s]Postprocessing:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 626/750 [00:05<00:01, 99.13it/s] Postprocessing:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 638/750 [00:05<00:01, 103.65it/s]Postprocessing:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 652/750 [00:06<00:00, 110.53it/s]Postprocessing:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 664/750 [00:06<00:00, 109.29it/s]Postprocessing:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 677/750 [00:06<00:00, 114.81it/s]Postprocessing:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 689/750 [00:06<00:00, 115.26it/s]Postprocessing:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 701/750 [00:06<00:00, 112.94it/s]Postprocessing:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 713/750 [00:06<00:00, 109.65it/s]Postprocessing:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 725/750 [00:06<00:00, 110.40it/s]Postprocessing:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 737/750 [00:06<00:00, 113.09it/s]Postprocessing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 749/750 [00:06<00:00, 114.67it/s]Postprocessing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 750/750 [00:06<00:00, 107.57it/s]
[32m2024-12-14 20:19:13.903[0m | [1mINFO    [0m | [36mlmms_eval.loggers.evaluation_tracker[0m:[36msave_results_aggregated[0m:[36m188[0m - [1mSaving results aggregated[0m
[32m2024-12-14 20:19:13.908[0m | [1mINFO    [0m | [36mlmms_eval.loggers.evaluation_tracker[0m:[36msave_results_samples[0m:[36m255[0m - [1mSaving per-sample results for: pope_pop[0m
[32m2024-12-14 20:19:17.419[0m | [1mINFO    [0m | [36mlmms_eval.loggers.evaluation_tracker[0m:[36msave_results_samples[0m:[36m255[0m - [1mSaving per-sample results for: vqav2_val_lite[0m
llava (pretrained=liuhaotian/llava-v1.6-vicuna-7b), gen_kwargs: (), limit: None, num_fewshot: None, batch_size: 1
|    Tasks     |Version|Filter|n-shot|    Metric    |   |Value |   |Stderr|
|--------------|-------|------|-----:|--------------|---|-----:|---|------|
|pope_pop      |Yaml   |none  |     0|pope_accuracy |‚Üë  |0.8767|¬±  |   N/A|
|pope_pop      |Yaml   |none  |     0|pope_f1_score |‚Üë  |0.8642|¬±  |   N/A|
|pope_pop      |Yaml   |none  |     0|pope_precision|‚Üë  |0.9616|¬±  |   N/A|
|pope_pop      |Yaml   |none  |     0|pope_recall   |‚Üë  |0.7847|¬±  |   N/A|
|pope_pop      |Yaml   |none  |     0|pope_yes_ratio|‚Üë  |0.5000|¬±  |   N/A|
|vqav2_val_lite|Yaml   |none  |     0|exact_match   |‚Üë  |0.7464|¬±  |0.0180|

wandb: - 0.025 MB of 0.025 MB uploadedwandb: - 0.025 MB of 0.025 MB uploadedwandb: - 0.025 MB of 0.025 MB uploadedwandb: \ 0.025 MB of 0.025 MB uploadedwandb: \ 0.025 MB of 0.038 MB uploadedwandb: \ 0.025 MB of 0.025 MB uploadedwandb: | 0.025 MB of 0.025 MB uploadedwandb: / 0.038 MB of 0.038 MB uploadedwandb:                                                                                
wandb: | 0.025 MB of 0.025 MB uploadedwandb: / 0.038 MB of 0.038 MB uploadedwandb:                                                                                
wandb: - 0.032 MB of 0.032 MB uploadedwandb: | 0.038 MB of 0.038 MB uploadedwandb: / 0.038 MB of 0.038 MB uploadedwandb: - 0.038 MB of 0.038 MB uploadedwandb:                                                                                
wandb: \ 0.032 MB of 0.032 MB uploadedwandb: üöÄ View run reverse2 at: https://wandb.ai/VLM_Hallucination_Woohyeon/llava1.6_recursive_eval_1126/runs/v101oiat/workspace
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241214_175110-v101oiat/logs
wandb: üöÄ View run reverse2 at: https://wandb.ai/VLM_Hallucination_Woohyeon/llava1.6_recursive_eval_1126/runs/ki9kglb2/workspace
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241214_175110-ki9kglb2/logs
wandb: üöÄ View run reverse2 at: https://wandb.ai/VLM_Hallucination_Woohyeon/llava1.6_recursive_eval_1126/runs/8qtv767e/workspace
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241214_175110-8qtv767e/logs
wandb: | 0.032 MB of 0.032 MB uploadedwandb: / 0.032 MB of 0.032 MB uploadedwandb: - 0.032 MB of 0.052 MB uploadedwandb: \ 0.032 MB of 0.052 MB uploadedwandb: | 0.052 MB of 0.052 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:            pope_pop/pope_accuracy ‚ñÅ
wandb:            pope_pop/pope_f1_score ‚ñÅ
wandb:           pope_pop/pope_precision ‚ñÅ
wandb:              pope_pop/pope_recall ‚ñÅ
wandb:           pope_pop/pope_yes_ratio ‚ñÅ
wandb:        vqav2_val_lite/exact_match ‚ñÅ
wandb: vqav2_val_lite/exact_match_stderr ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    pope_pop/alias pope_pop
wandb:            pope_pop/pope_accuracy 0.87667
wandb:     pope_pop/pope_accuracy_stderr N/A
wandb:            pope_pop/pope_f1_score 0.86417
wandb:     pope_pop/pope_f1_score_stderr N/A
wandb:           pope_pop/pope_precision 0.9616
wandb:    pope_pop/pope_precision_stderr N/A
wandb:              pope_pop/pope_recall 0.78467
wandb:       pope_pop/pope_recall_stderr N/A
wandb:           pope_pop/pope_yes_ratio 0.5
wandb:    pope_pop/pope_yes_ratio_stderr N/A
wandb:              vqav2_val_lite/alias vqav2_val_lite
wandb:        vqav2_val_lite/exact_match 0.7464
wandb: vqav2_val_lite/exact_match_stderr 0.01797
wandb: 
wandb: üöÄ View run reverse2 at: https://wandb.ai/VLM_Hallucination_Woohyeon/llava1.6_recursive_eval_1126/runs/e9mmayzd/workspace
wandb: Synced 6 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241214_175110-e9mmayzd/logs
[rank0]:[W1214 20:19:32.187467945 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
The following values were not passed to `accelerate launch` and had defaults used instead:
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--num_machines` was set to a value of `1`
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
wandb: Currently logged in as: wjk9904 (VLM_Hallucination_Woohyeon). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: wjk9904 (VLM_Hallucination_Woohyeon). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: wjk9904 (VLM_Hallucination_Woohyeon). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: wjk9904 (VLM_Hallucination_Woohyeon). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.19.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.5
wandb: Run data is saved locally in /workspace/vlm/lmms-reverse/wandb/run-20241214_201942-umyoqxuk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run reverse3
wandb: ‚≠êÔ∏è View project at https://wandb.ai/VLM_Hallucination_Woohyeon/llava1.6_recursive_eval_1126
wandb: üöÄ View run at https://wandb.ai/VLM_Hallucination_Woohyeon/llava1.6_recursive_eval_1126/runs/umyoqxuk/workspace
[32m2024-12-14 20:19:44.912[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate[0m:[36m420[0m - [1mVerbosity set to DEBUG[0m
wandb: wandb version 0.19.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.5
wandb: Run data is saved locally in /workspace/vlm/lmms-reverse/wandb/run-20241214_201942-mlqvfpvl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run reverse3
wandb: ‚≠êÔ∏è View project at https://wandb.ai/VLM_Hallucination_Woohyeon/llava1.6_recursive_eval_1126
wandb: üöÄ View run at https://wandb.ai/VLM_Hallucination_Woohyeon/llava1.6_recursive_eval_1126/runs/mlqvfpvl/workspace
wandb: wandb version 0.19.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.5
wandb: Run data is saved locally in /workspace/vlm/lmms-reverse/wandb/run-20241214_201942-i9bidqan
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run reverse3
wandb: ‚≠êÔ∏è View project at https://wandb.ai/VLM_Hallucination_Woohyeon/llava1.6_recursive_eval_1126
wandb: üöÄ View run at https://wandb.ai/VLM_Hallucination_Woohyeon/llava1.6_recursive_eval_1126/runs/i9bidqan/workspace
[32m2024-12-14 20:19:45.136[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate[0m:[36m420[0m - [1mVerbosity set to DEBUG[0m
[32m2024-12-14 20:19:45.206[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate[0m:[36m420[0m - [1mVerbosity set to DEBUG[0m
wandb: wandb version 0.19.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.5
wandb: Run data is saved locally in /workspace/vlm/lmms-reverse/wandb/run-20241214_201942-k3p3dzhk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run reverse3
wandb: ‚≠êÔ∏è View project at https://wandb.ai/VLM_Hallucination_Woohyeon/llava1.6_recursive_eval_1126
wandb: üöÄ View run at https://wandb.ai/VLM_Hallucination_Woohyeon/llava1.6_recursive_eval_1126/runs/k3p3dzhk/workspace
[32m2024-12-14 20:19:45.334[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate[0m:[36m420[0m - [1mVerbosity set to DEBUG[0m
[32m2024-12-14 20:19:51.613[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.tasks[0m:[36m_get_task_and_group[0m:[36m452[0m - [34m[1m`group` and `group_alias` keys in tasks' configs will no longer be used in the next release of lmms-eval. `tag` will be used to allow to call a collection of tasks just like `group`. `group` will be removed in order to not cause confusion with the new ConfigurableGroup which will be the offical way to create groups with addition of group-wide configuations.[0m
[32m2024-12-14 20:19:52.192[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.tasks[0m:[36m_get_task_and_group[0m:[36m452[0m - [34m[1m`group` and `group_alias` keys in tasks' configs will no longer be used in the next release of lmms-eval. `tag` will be used to allow to call a collection of tasks just like `group`. `group` will be removed in order to not cause confusion with the new ConfigurableGroup which will be the offical way to create groups with addition of group-wide configuations.[0m
[32m2024-12-14 20:19:52.289[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.tasks[0m:[36m_get_task_and_group[0m:[36m452[0m - [34m[1m`group` and `group_alias` keys in tasks' configs will no longer be used in the next release of lmms-eval. `tag` will be used to allow to call a collection of tasks just like `group`. `group` will be removed in order to not cause confusion with the new ConfigurableGroup which will be the offical way to create groups with addition of group-wide configuations.[0m
[32m2024-12-14 20:19:52.360[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.tasks[0m:[36m_get_task_and_group[0m:[36m452[0m - [34m[1m`group` and `group_alias` keys in tasks' configs will no longer be used in the next release of lmms-eval. `tag` will be used to allow to call a collection of tasks just like `group`. `group` will be removed in order to not cause confusion with the new ConfigurableGroup which will be the offical way to create groups with addition of group-wide configuations.[0m
[32m2024-12-14 20:19:52.371[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m503[0m - [1mEvaluation tracker args: {'output_path': './logs/'}[0m
[32m2024-12-14 20:19:52.372[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m592[0m - [1mSelected Tasks: ['pope_pop', 'vqav2_val_lite'][0m
[32m2024-12-14 20:19:52.375[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36msimple_evaluate[0m:[36m155[0m - [1mSetting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234[0m
[32m2024-12-14 20:19:52.939[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m503[0m - [1mEvaluation tracker args: {'output_path': './logs/'}[0m
[32m2024-12-14 20:19:52.940[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m592[0m - [1mSelected Tasks: ['pope_pop', 'vqav2_val_lite'][0m
[32m2024-12-14 20:19:52.944[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36msimple_evaluate[0m:[36m155[0m - [1mSetting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234[0m
[32m2024-12-14 20:19:53.050[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m503[0m - [1mEvaluation tracker args: {'output_path': './logs/'}[0m
[32m2024-12-14 20:19:53.051[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m592[0m - [1mSelected Tasks: ['pope_pop', 'vqav2_val_lite'][0m
[32m2024-12-14 20:19:53.055[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36msimple_evaluate[0m:[36m155[0m - [1mSetting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234[0m
[32m2024-12-14 20:19:53.129[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m503[0m - [1mEvaluation tracker args: {'output_path': './logs/'}[0m
[32m2024-12-14 20:19:53.129[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m592[0m - [1mSelected Tasks: ['pope_pop', 'vqav2_val_lite'][0m
[32m2024-12-14 20:19:53.132[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36msimple_evaluate[0m:[36m155[0m - [1mSetting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234[0m
initialize llava model with modification
initialize llava model with modification
initialize llava model with modification
initialize llava model with modification
OpenCLIP not installed
OpenCLIP not installed
OpenCLIP not installed
OpenCLIP not installed
self.merging= None
model_name: llava-v1.6-vicuna-7b
Rank 0:  Loaded LLaVA model: liuhaotian/llava-v1.6-vicuna-7b
loding from here
self.merging= None
model_name: llava-v1.6-vicuna-7b
loding from here
self.merging= None
model_name: llava-v1.6-vicuna-7b
loding from here
self.merging= None
model_name: llava-v1.6-vicuna-7b
loding from here
You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
Rank 0:  Loading vision tower: openai/clip-vit-large-patch14-336
You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:05<00:10,  5.48s/it]Loading checkpoint shards:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:05<00:11,  5.74s/it]Loading checkpoint shards:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:06<00:12,  6.00s/it]Loading checkpoint shards:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:06<00:13,  6.64s/it]Loading checkpoint shards:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:11<00:05,  5.57s/it]Loading checkpoint shards:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:11<00:05,  5.61s/it]Loading checkpoint shards:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:11<00:05,  5.86s/it]Loading checkpoint shards:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:12<00:06,  6.06s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:16<00:00,  5.28s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:16<00:00,  5.35s/it]
Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:16<00:00,  5.30s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:16<00:00,  5.40s/it]
device: cuda:0
generation_type: recursion
fix_grid: 2x2
attention_thresholding_type: layer_mean_topk
attention_norm: None
attention_threshold: 0.7
detection_strategy: None
detection_threshold: 0.8
save_output: False
save_output_csv_path: generation_output.csv
target_token_selection_strategy: first
stages: [1, 0, -1, -2]
positional_embedding_type: bilinear_interpolation
visualize_heatmap: False
square: 1
remove unpadding=True, change to 'spatial'
change positional embedding to bilinear_interpolation
device: cuda:0
generation_type: recursion
fix_grid: 2x2
attention_thresholding_type: layer_mean_topk
attention_norm: None
attention_threshold: 0.7
detection_strategy: None
detection_threshold: 0.8
save_output: False
save_output_csv_path: generation_output.csv
target_token_selection_strategy: first
stages: [1, 0, -1, -2]
positional_embedding_type: bilinear_interpolation
visualize_heatmap: False
square: 1
remove unpadding=True, change to 'spatial'
change positional embedding to bilinear_interpolation
Bilienar interpolation embedding type.
Bilienar interpolation embedding type.
Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:17<00:00,  5.65s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:17<00:00,  5.72s/it]
device: cuda:0
generation_type: recursion
fix_grid: 2x2
attention_thresholding_type: layer_mean_topk
attention_norm: None
attention_threshold: 0.7
detection_strategy: None
detection_threshold: 0.8
save_output: False
save_output_csv_path: generation_output.csv
target_token_selection_strategy: first
stages: [1, 0, -1, -2]
positional_embedding_type: bilinear_interpolation
visualize_heatmap: False
square: 1
remove unpadding=True, change to 'spatial'
change positional embedding to bilinear_interpolation
Bilienar interpolation embedding type.
Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:17<00:00,  5.76s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:17<00:00,  5.90s/it]
Bilienar interpolation embedding type.
Rank 0:  Model Class: LlavaLlamaForCausalLM
device: cuda:0
generation_type: recursion
fix_grid: 2x2
attention_thresholding_type: layer_mean_topk
attention_norm: None
attention_threshold: 0.7
detection_strategy: None
detection_threshold: 0.8
save_output: False
save_output_csv_path: generation_output.csv
target_token_selection_strategy: first
stages: [1, 0, -1, -2]
positional_embedding_type: bilinear_interpolation
visualize_heatmap: False
square: 1
remove unpadding=True, change to 'spatial'
change positional embedding to bilinear_interpolation
Bilienar interpolation embedding type.
Bilienar interpolation embedding type.
Bilienar interpolation embedding type.
[32m2024-12-14 20:20:23.036[0m | [1mINFO    [0m | [36mlmms_eval.models.llava[0m:[36m__init__[0m:[36m306[0m - [1mUsing 4 devices with data parallelism[0m
[32m2024-12-14 20:20:23.037[0m | [1mINFO    [0m | [36mlmms_eval.evaluator_utils[0m:[36mfrom_taskdict[0m:[36m91[0m - [1mNo metadata found in task config for vqav2_val_lite, using default n_shot=0[0m
[32m2024-12-14 20:20:23.037[0m | [1mINFO    [0m | [36mlmms_eval.evaluator_utils[0m:[36mfrom_taskdict[0m:[36m91[0m - [1mNo metadata found in task config for pope_pop, using default n_shot=0[0m
[32m2024-12-14 20:20:23.038[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.caching.cache[0m:[36mload_from_cache[0m:[36m33[0m - [34m[1mrequests-vqav2_val_lite-0shot-rank0-world_size4-tokenizer is not cached, generating...[0m
[32m2024-12-14 20:20:23.038[0m | [1mINFO    [0m | [36mlmms_eval.api.task[0m:[36mbuild_all_requests[0m:[36m425[0m - [1mBuilding contexts for vqav2_val_lite on rank 0...[0m
[32m2024-12-14 20:20:23.713[0m | [1mINFO    [0m | [36mlmms_eval.evaluator_utils[0m:[36mfrom_taskdict[0m:[36m91[0m - [1mNo metadata found in task config for vqav2_val_lite, using default n_shot=0[0m
[32m2024-12-14 20:20:23.714[0m | [1mINFO    [0m | [36mlmms_eval.evaluator_utils[0m:[36mfrom_taskdict[0m:[36m91[0m - [1mNo metadata found in task config for pope_pop, using default n_shot=0[0m
[32m2024-12-14 20:20:23.714[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.caching.cache[0m:[36mload_from_cache[0m:[36m33[0m - [34m[1mrequests-vqav2_val_lite-0shot-rank2-world_size4-tokenizer is not cached, generating...[0m
[32m2024-12-14 20:20:23.715[0m | [1mINFO    [0m | [36mlmms_eval.api.task[0m:[36mbuild_all_requests[0m:[36m425[0m - [1mBuilding contexts for vqav2_val_lite on rank 2...[0m
[32m2024-12-14 20:20:23.842[0m | [1mINFO    [0m | [36mlmms_eval.evaluator_utils[0m:[36mfrom_taskdict[0m:[36m91[0m - [1mNo metadata found in task config for vqav2_val_lite, using default n_shot=0[0m
[32m2024-12-14 20:20:23.843[0m | [1mINFO    [0m | [36mlmms_eval.evaluator_utils[0m:[36mfrom_taskdict[0m:[36m91[0m - [1mNo metadata found in task config for pope_pop, using default n_shot=0[0m
[32m2024-12-14 20:20:23.843[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.caching.cache[0m:[36mload_from_cache[0m:[36m33[0m - [34m[1mrequests-vqav2_val_lite-0shot-rank3-world_size4-tokenizer is not cached, generating...[0m
[32m2024-12-14 20:20:23.844[0m | [1mINFO    [0m | [36mlmms_eval.api.task[0m:[36mbuild_all_requests[0m:[36m425[0m - [1mBuilding contexts for vqav2_val_lite on rank 3...[0m
Bilienar interpolation embedding type.
  0%|          | 0/125 [00:00<?, ?it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [00:00<00:00, 101233.44it/s]
[32m2024-12-14 20:20:24.215[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m455[0m - [34m[1mTask: vqav2_val_lite; number of requests on this rank: 125[0m
  0%|          | 0/125 [00:00<?, ?it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [00:00<00:00, 99485.39it/s]
[32m2024-12-14 20:20:24.853[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m455[0m - [34m[1mTask: vqav2_val_lite; number of requests on this rank: 125[0m
  0%|          | 0/125 [00:00<?, ?it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [00:00<00:00, 110983.91it/s]
[32m2024-12-14 20:20:24.981[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m455[0m - [34m[1mTask: vqav2_val_lite; number of requests on this rank: 125[0m
[32m2024-12-14 20:20:25.186[0m | [1mINFO    [0m | [36mlmms_eval.evaluator_utils[0m:[36mfrom_taskdict[0m:[36m91[0m - [1mNo metadata found in task config for vqav2_val_lite, using default n_shot=0[0m
[32m2024-12-14 20:20:25.187[0m | [1mINFO    [0m | [36mlmms_eval.evaluator_utils[0m:[36mfrom_taskdict[0m:[36m91[0m - [1mNo metadata found in task config for pope_pop, using default n_shot=0[0m
[32m2024-12-14 20:20:25.187[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.caching.cache[0m:[36mload_from_cache[0m:[36m33[0m - [34m[1mrequests-vqav2_val_lite-0shot-rank1-world_size4-tokenizer is not cached, generating...[0m
[32m2024-12-14 20:20:25.187[0m | [1mINFO    [0m | [36mlmms_eval.api.task[0m:[36mbuild_all_requests[0m:[36m425[0m - [1mBuilding contexts for vqav2_val_lite on rank 1...[0m
  0%|          | 0/125 [00:00<?, ?it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [00:00<00:00, 99259.37it/s]
[32m2024-12-14 20:20:26.349[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m455[0m - [34m[1mTask: vqav2_val_lite; number of requests on this rank: 125[0m
[32m2024-12-14 20:20:34.129[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.caching.cache[0m:[36mload_from_cache[0m:[36m33[0m - [34m[1mrequests-pope_pop-0shot-rank1-world_size4-tokenizer is not cached, generating...[0m
[32m2024-12-14 20:20:34.129[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.caching.cache[0m:[36mload_from_cache[0m:[36m33[0m - [34m[1mrequests-pope_pop-0shot-rank2-world_size4-tokenizer is not cached, generating...[0m
[32m2024-12-14 20:20:34.129[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.caching.cache[0m:[36mload_from_cache[0m:[36m33[0m - [34m[1mrequests-pope_pop-0shot-rank3-world_size4-tokenizer is not cached, generating...[0m
[32m2024-12-14 20:20:34.129[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.caching.cache[0m:[36mload_from_cache[0m:[36m33[0m - [34m[1mrequests-pope_pop-0shot-rank0-world_size4-tokenizer is not cached, generating...[0m
[32m2024-12-14 20:20:34.130[0m | [1mINFO    [0m | [36mlmms_eval.api.task[0m:[36mbuild_all_requests[0m:[36m425[0m - [1mBuilding contexts for pope_pop on rank 1...[0m
[32m2024-12-14 20:20:34.130[0m | [1mINFO    [0m | [36mlmms_eval.api.task[0m:[36mbuild_all_requests[0m:[36m425[0m - [1mBuilding contexts for pope_pop on rank 2...[0m
[32m2024-12-14 20:20:34.130[0m | [1mINFO    [0m | [36mlmms_eval.api.task[0m:[36mbuild_all_requests[0m:[36m425[0m - [1mBuilding contexts for pope_pop on rank 3...[0m
[32m2024-12-14 20:20:34.130[0m | [1mINFO    [0m | [36mlmms_eval.api.task[0m:[36mbuild_all_requests[0m:[36m425[0m - [1mBuilding contexts for pope_pop on rank 0...[0m
  0%|          | 0/750 [00:00<?, ?it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 750/750 [00:00<00:00, 109836.87it/s]
[32m2024-12-14 20:20:41.169[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m455[0m - [34m[1mTask: pope_pop; number of requests on this rank: 750[0m
  0%|          | 0/750 [00:00<?, ?it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 750/750 [00:00<00:00, 102140.66it/s]
[32m2024-12-14 20:20:41.260[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m455[0m - [34m[1mTask: pope_pop; number of requests on this rank: 750[0m
  0%|          | 0/750 [00:00<?, ?it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 750/750 [00:00<00:00, 110310.62it/s]
[32m2024-12-14 20:20:41.490[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m455[0m - [34m[1mTask: pope_pop; number of requests on this rank: 750[0m
  0%|          | 0/750 [00:00<?, ?it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 750/750 [00:00<00:00, 111368.97it/s]
[32m2024-12-14 20:20:41.619[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m455[0m - [34m[1mTask: pope_pop; number of requests on this rank: 750[0m
[32m2024-12-14 20:20:41.620[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m476[0m - [1mRunning generate_until requests[0m
[32m2024-12-14 20:20:41.620[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m476[0m - [1mRunning generate_until requests[0m
[32m2024-12-14 20:20:41.620[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m476[0m - [1mRunning generate_until requests[0m
[32m2024-12-14 20:20:41.620[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m476[0m - [1mRunning generate_until requests[0m
Model Responding:   0%|          | 0/875 [00:00<?, ?it/s]CLIPModel is using CLIPSdpaAttention, but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation="eager"` when loading the model.
CLIPModel is using CLIPSdpaAttention, but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation="eager"` when loading the model.
CLIPModel is using CLIPSdpaAttention, but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation="eager"` when loading the model.
CLIPModel is using CLIPSdpaAttention, but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation="eager"` when loading the model.
LlamaModel is using LlamaSdpaAttention, but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation="eager"` when loading the model.
LlamaModel is using LlamaSdpaAttention, but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation="eager"` when loading the model.
LlamaModel is using LlamaSdpaAttention, but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation="eager"` when loading the model.
LlamaModel is using LlamaSdpaAttention, but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation="eager"` when loading the model.
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
Model Responding:   0%|          | 1/875 [00:10<2:25:41, 10.00s/it]Model Responding:   0%|          | 2/875 [00:18<2:14:43,  9.26s/it]Model Responding:   0%|          | 3/875 [00:28<2:16:03,  9.36s/it]Model Responding:   0%|          | 4/875 [00:36<2:09:43,  8.94s/it]Model Responding:   1%|          | 5/875 [00:44<2:05:17,  8.64s/it]Model Responding:   1%|          | 6/875 [00:53<2:06:49,  8.76s/it]Model Responding:   1%|          | 7/875 [01:02<2:07:50,  8.84s/it]Model Responding:   1%|          | 8/875 [01:11<2:07:10,  8.80s/it]Model Responding:   1%|          | 9/875 [01:20<2:07:35,  8.84s/it]Model Responding:   1%|          | 10/875 [01:29<2:09:06,  8.96s/it]Model Responding:   1%|‚ñè         | 11/875 [01:38<2:07:09,  8.83s/it]Model Responding:   1%|‚ñè         | 12/875 [01:46<2:05:27,  8.72s/it]Model Responding:   1%|‚ñè         | 13/875 [01:53<1:59:52,  8.34s/it]Model Responding:   2%|‚ñè         | 14/875 [02:02<2:01:30,  8.47s/it]Model Responding:   2%|‚ñè         | 15/875 [02:12<2:06:42,  8.84s/it]Model Responding:   2%|‚ñè         | 16/875 [02:21<2:07:03,  8.88s/it]Model Responding:   2%|‚ñè         | 17/875 [02:30<2:06:19,  8.83s/it]Model Responding:   2%|‚ñè         | 18/875 [02:39<2:06:24,  8.85s/it]Model Responding:   2%|‚ñè         | 19/875 [02:47<2:05:21,  8.79s/it]Model Responding:   2%|‚ñè         | 20/875 [02:55<2:01:07,  8.50s/it]Model Responding:   2%|‚ñè         | 21/875 [03:03<1:59:26,  8.39s/it]Model Responding:   3%|‚ñé         | 22/875 [03:12<2:01:05,  8.52s/it]Model Responding:   3%|‚ñé         | 23/875 [03:21<2:01:44,  8.57s/it]Model Responding:   3%|‚ñé         | 24/875 [03:30<2:03:29,  8.71s/it]Model Responding:   3%|‚ñé         | 25/875 [03:39<2:04:14,  8.77s/it]Model Responding:   3%|‚ñé         | 26/875 [03:47<2:03:29,  8.73s/it]Model Responding:   3%|‚ñé         | 27/875 [03:55<2:01:24,  8.59s/it]Model Responding:   3%|‚ñé         | 28/875 [04:04<2:02:16,  8.66s/it]Model Responding:   3%|‚ñé         | 29/875 [04:13<2:01:25,  8.61s/it]Model Responding:   3%|‚ñé         | 30/875 [04:21<2:00:23,  8.55s/it]Model Responding:   4%|‚ñé         | 31/875 [04:30<2:00:24,  8.56s/it]Model Responding:   4%|‚ñé         | 32/875 [04:38<1:59:58,  8.54s/it]Model Responding:   4%|‚ñç         | 33/875 [04:47<1:59:24,  8.51s/it]Model Responding:   4%|‚ñç         | 34/875 [04:55<1:57:12,  8.36s/it]Model Responding:   4%|‚ñç         | 35/875 [05:03<1:55:27,  8.25s/it]Model Responding:   4%|‚ñç         | 36/875 [05:11<1:55:27,  8.26s/it]Model Responding:   4%|‚ñç         | 37/875 [05:20<1:56:24,  8.33s/it]Model Responding:   4%|‚ñç         | 38/875 [05:29<2:00:44,  8.66s/it]Model Responding:   4%|‚ñç         | 39/875 [05:38<2:00:55,  8.68s/it]Model Responding:   5%|‚ñç         | 40/875 [05:46<1:59:10,  8.56s/it]Model Responding:   5%|‚ñç         | 41/875 [05:54<1:57:27,  8.45s/it]Model Responding:   5%|‚ñç         | 42/875 [06:03<1:58:24,  8.53s/it]Model Responding:   5%|‚ñç         | 43/875 [06:12<2:01:47,  8.78s/it]Model Responding:   5%|‚ñå         | 44/875 [06:21<2:03:29,  8.92s/it]Model Responding:   5%|‚ñå         | 45/875 [06:31<2:06:09,  9.12s/it]Model Responding:   5%|‚ñå         | 46/875 [06:40<2:04:06,  8.98s/it]Model Responding:   5%|‚ñå         | 47/875 [06:48<2:00:50,  8.76s/it]Model Responding:   5%|‚ñå         | 48/875 [06:56<1:58:34,  8.60s/it]Model Responding:   6%|‚ñå         | 49/875 [07:05<1:58:48,  8.63s/it]Model Responding:   6%|‚ñå         | 50/875 [07:14<1:59:21,  8.68s/it]Model Responding:   6%|‚ñå         | 51/875 [07:23<2:02:06,  8.89s/it]Model Responding:   6%|‚ñå         | 52/875 [07:33<2:04:54,  9.11s/it]Model Responding:   6%|‚ñå         | 53/875 [07:41<2:01:08,  8.84s/it]Model Responding:   6%|‚ñå         | 54/875 [07:49<1:59:03,  8.70s/it]Model Responding:   6%|‚ñã         | 55/875 [07:58<1:58:00,  8.63s/it]Model Responding:   6%|‚ñã         | 56/875 [08:06<1:57:27,  8.61s/it]Model Responding:   7%|‚ñã         | 57/875 [08:15<1:57:10,  8.60s/it]Model Responding:   7%|‚ñã         | 58/875 [08:23<1:56:56,  8.59s/it]Model Responding:   7%|‚ñã         | 59/875 [08:32<1:55:52,  8.52s/it]Model Responding:   7%|‚ñã         | 60/875 [08:41<1:56:34,  8.58s/it]Model Responding:   7%|‚ñã         | 61/875 [08:49<1:55:15,  8.50s/it]Model Responding:   7%|‚ñã         | 62/875 [08:58<1:56:01,  8.56s/it]Model Responding:   7%|‚ñã         | 63/875 [09:06<1:56:36,  8.62s/it]Model Responding:   7%|‚ñã         | 64/875 [09:15<1:56:08,  8.59s/it]Model Responding:   7%|‚ñã         | 65/875 [09:24<1:59:46,  8.87s/it]Model Responding:   8%|‚ñä         | 66/875 [09:33<1:58:43,  8.81s/it]Model Responding:   8%|‚ñä         | 67/875 [09:42<1:58:44,  8.82s/it]Model Responding:   8%|‚ñä         | 68/875 [09:51<2:00:06,  8.93s/it]Model Responding:   8%|‚ñä         | 69/875 [10:00<1:59:48,  8.92s/it]Model Responding:   8%|‚ñä         | 70/875 [10:09<1:59:05,  8.88s/it]Model Responding:   8%|‚ñä         | 71/875 [10:17<1:56:31,  8.70s/it]Model Responding:   8%|‚ñä         | 72/875 [10:26<1:57:17,  8.76s/it]Model Responding:   8%|‚ñä         | 73/875 [10:34<1:54:52,  8.59s/it]Model Responding:   8%|‚ñä         | 74/875 [10:43<1:55:43,  8.67s/it]Model Responding:   9%|‚ñä         | 75/875 [10:51<1:53:34,  8.52s/it]Model Responding:   9%|‚ñä         | 76/875 [11:01<1:58:21,  8.89s/it]Model Responding:   9%|‚ñâ         | 77/875 [11:10<1:58:59,  8.95s/it]Model Responding:   9%|‚ñâ         | 78/875 [11:19<1:59:31,  9.00s/it]Model Responding:   9%|‚ñâ         | 79/875 [11:28<1:57:47,  8.88s/it]Model Responding:   9%|‚ñâ         | 80/875 [11:37<1:58:46,  8.96s/it]Model Responding:   9%|‚ñâ         | 81/875 [11:46<1:58:08,  8.93s/it]Model Responding:   9%|‚ñâ         | 82/875 [11:54<1:55:08,  8.71s/it]Model Responding:   9%|‚ñâ         | 83/875 [12:03<1:55:43,  8.77s/it]Model Responding:  10%|‚ñâ         | 84/875 [12:12<1:58:28,  8.99s/it]Model Responding:  10%|‚ñâ         | 85/875 [12:20<1:54:39,  8.71s/it]Model Responding:  10%|‚ñâ         | 86/875 [12:29<1:53:54,  8.66s/it]Model Responding:  10%|‚ñâ         | 87/875 [12:37<1:52:50,  8.59s/it]Model Responding:  10%|‚ñà         | 88/875 [12:45<1:51:09,  8.47s/it]Model Responding:  10%|‚ñà         | 89/875 [12:53<1:49:12,  8.34s/it]Model Responding:  10%|‚ñà         | 90/875 [13:02<1:49:54,  8.40s/it]Model Responding:  10%|‚ñà         | 91/875 [13:11<1:50:14,  8.44s/it]Model Responding:  11%|‚ñà         | 92/875 [13:19<1:51:09,  8.52s/it]Model Responding:  11%|‚ñà         | 93/875 [13:29<1:55:29,  8.86s/it]Model Responding:  11%|‚ñà         | 94/875 [13:38<1:57:00,  8.99s/it]Model Responding:  11%|‚ñà         | 95/875 [13:47<1:54:20,  8.80s/it]Model Responding:  11%|‚ñà         | 96/875 [13:55<1:51:58,  8.63s/it]Model Responding:  11%|‚ñà         | 97/875 [14:03<1:51:25,  8.59s/it]Model Responding:  11%|‚ñà         | 98/875 [14:12<1:51:08,  8.58s/it]Model Responding:  11%|‚ñà‚ñè        | 99/875 [14:20<1:50:14,  8.52s/it]Model Responding:  11%|‚ñà‚ñè        | 100/875 [14:28<1:48:45,  8.42s/it]Model Responding:  12%|‚ñà‚ñè        | 101/875 [14:37<1:49:55,  8.52s/it]Model Responding:  12%|‚ñà‚ñè        | 102/875 [14:46<1:52:29,  8.73s/it]Model Responding:  12%|‚ñà‚ñè        | 103/875 [14:56<1:54:00,  8.86s/it]Model Responding:  12%|‚ñà‚ñè        | 104/875 [15:05<1:54:43,  8.93s/it]Model Responding:  12%|‚ñà‚ñè        | 105/875 [15:13<1:52:14,  8.75s/it]Model Responding:  12%|‚ñà‚ñè        | 106/875 [15:22<1:52:02,  8.74s/it]Model Responding:  12%|‚ñà‚ñè        | 107/875 [15:30<1:50:43,  8.65s/it]Model Responding:  12%|‚ñà‚ñè        | 108/875 [15:38<1:49:23,  8.56s/it]Model Responding:  12%|‚ñà‚ñè        | 109/875 [15:47<1:49:34,  8.58s/it]Model Responding:  13%|‚ñà‚ñé        | 110/875 [15:57<1:53:07,  8.87s/it]Model Responding:  13%|‚ñà‚ñé        | 111/875 [16:05<1:51:57,  8.79s/it]Model Responding:  13%|‚ñà‚ñé        | 112/875 [16:14<1:49:42,  8.63s/it]Model Responding:  13%|‚ñà‚ñé        | 113/875 [16:22<1:49:55,  8.66s/it]Model Responding:  13%|‚ñà‚ñé        | 114/875 [16:32<1:52:45,  8.89s/it]Model Responding:  13%|‚ñà‚ñé        | 115/875 [16:40<1:49:05,  8.61s/it]Model Responding:  13%|‚ñà‚ñé        | 116/875 [16:49<1:50:13,  8.71s/it]Model Responding:  13%|‚ñà‚ñé        | 117/875 [16:57<1:47:09,  8.48s/it]Model Responding:  13%|‚ñà‚ñé        | 118/875 [17:04<1:44:58,  8.32s/it]Model Responding:  14%|‚ñà‚ñé        | 119/875 [17:13<1:46:17,  8.44s/it]Model Responding:  14%|‚ñà‚ñé        | 120/875 [17:22<1:47:29,  8.54s/it]Model Responding:  14%|‚ñà‚ñç        | 121/875 [17:30<1:46:17,  8.46s/it]Model Responding:  14%|‚ñà‚ñç        | 122/875 [17:39<1:48:09,  8.62s/it]Model Responding:  14%|‚ñà‚ñç        | 123/875 [17:48<1:48:36,  8.67s/it]Model Responding:  14%|‚ñà‚ñç        | 124/875 [17:57<1:49:15,  8.73s/it]Model Responding:  14%|‚ñà‚ñç        | 125/875 [18:05<1:47:46,  8.62s/it]Model Responding:  14%|‚ñà‚ñç        | 126/875 [18:14<1:46:18,  8.52s/it]Model Responding:  15%|‚ñà‚ñç        | 127/875 [18:22<1:45:31,  8.46s/it]Model Responding:  15%|‚ñà‚ñç        | 128/875 [18:30<1:44:32,  8.40s/it]Model Responding:  15%|‚ñà‚ñç        | 129/875 [18:38<1:42:54,  8.28s/it]Model Responding:  15%|‚ñà‚ñç        | 130/875 [18:46<1:42:47,  8.28s/it]Model Responding:  15%|‚ñà‚ñç        | 131/875 [18:55<1:43:52,  8.38s/it]Model Responding:  15%|‚ñà‚ñå        | 132/875 [19:03<1:43:56,  8.39s/it]Model Responding:  15%|‚ñà‚ñå        | 133/875 [19:12<1:43:00,  8.33s/it]Model Responding:  15%|‚ñà‚ñå        | 134/875 [19:19<1:41:03,  8.18s/it]Model Responding:  15%|‚ñà‚ñå        | 135/875 [19:28<1:43:54,  8.43s/it]Model Responding:  16%|‚ñà‚ñå        | 136/875 [19:37<1:44:35,  8.49s/it]Model Responding:  16%|‚ñà‚ñå        | 137/875 [19:45<1:43:03,  8.38s/it]Model Responding:  16%|‚ñà‚ñå        | 138/875 [19:54<1:44:49,  8.53s/it]Model Responding:  16%|‚ñà‚ñå        | 139/875 [20:03<1:46:14,  8.66s/it]Model Responding:  16%|‚ñà‚ñå        | 140/875 [20:12<1:47:01,  8.74s/it]Model Responding:  16%|‚ñà‚ñå        | 141/875 [20:21<1:47:29,  8.79s/it]Model Responding:  16%|‚ñà‚ñå        | 142/875 [20:30<1:47:58,  8.84s/it]Model Responding:  16%|‚ñà‚ñã        | 143/875 [20:38<1:44:26,  8.56s/it]Model Responding:  16%|‚ñà‚ñã        | 144/875 [20:46<1:42:35,  8.42s/it]Model Responding:  17%|‚ñà‚ñã        | 145/875 [20:54<1:40:04,  8.23s/it]Model Responding:  17%|‚ñà‚ñã        | 146/875 [21:03<1:42:36,  8.45s/it]Model Responding:  17%|‚ñà‚ñã        | 147/875 [21:11<1:42:25,  8.44s/it]Model Responding:  17%|‚ñà‚ñã        | 148/875 [21:20<1:44:58,  8.66s/it]Model Responding:  17%|‚ñà‚ñã        | 149/875 [21:29<1:45:51,  8.75s/it]Model Responding:  17%|‚ñà‚ñã        | 150/875 [21:38<1:47:21,  8.89s/it]Model Responding:  17%|‚ñà‚ñã        | 151/875 [21:47<1:44:47,  8.68s/it]Model Responding:  17%|‚ñà‚ñã        | 152/875 [21:55<1:44:52,  8.70s/it]Model Responding:  17%|‚ñà‚ñã        | 153/875 [22:04<1:45:33,  8.77s/it]Model Responding:  18%|‚ñà‚ñä        | 154/875 [22:13<1:44:51,  8.73s/it]Model Responding:  18%|‚ñà‚ñä        | 155/875 [22:22<1:44:41,  8.72s/it]Model Responding:  18%|‚ñà‚ñä        | 156/875 [22:30<1:45:10,  8.78s/it]Model Responding:  18%|‚ñà‚ñä        | 157/875 [22:39<1:44:47,  8.76s/it]Model Responding:  18%|‚ñà‚ñä        | 158/875 [22:47<1:42:33,  8.58s/it]Model Responding:  18%|‚ñà‚ñä        | 159/875 [22:56<1:43:35,  8.68s/it]Model Responding:  18%|‚ñà‚ñä        | 160/875 [23:05<1:42:28,  8.60s/it]Model Responding:  18%|‚ñà‚ñä        | 161/875 [23:13<1:40:39,  8.46s/it]Model Responding:  19%|‚ñà‚ñä        | 162/875 [23:21<1:40:08,  8.43s/it]Model Responding:  19%|‚ñà‚ñä        | 163/875 [23:30<1:40:03,  8.43s/it]Model Responding:  19%|‚ñà‚ñä        | 164/875 [23:38<1:40:21,  8.47s/it]Model Responding:  19%|‚ñà‚ñâ        | 165/875 [23:47<1:39:44,  8.43s/it]Model Responding:  19%|‚ñà‚ñâ        | 166/875 [23:54<1:37:38,  8.26s/it]Model Responding:  19%|‚ñà‚ñâ        | 167/875 [24:03<1:38:10,  8.32s/it]Model Responding:  19%|‚ñà‚ñâ        | 168/875 [24:12<1:40:09,  8.50s/it]Model Responding:  19%|‚ñà‚ñâ        | 169/875 [24:21<1:41:30,  8.63s/it]Model Responding:  19%|‚ñà‚ñâ        | 170/875 [24:29<1:41:17,  8.62s/it]Model Responding:  20%|‚ñà‚ñâ        | 171/875 [24:38<1:41:46,  8.67s/it]Model Responding:  20%|‚ñà‚ñâ        | 172/875 [24:47<1:42:13,  8.72s/it]Model Responding:  20%|‚ñà‚ñâ        | 173/875 [24:56<1:42:48,  8.79s/it]Model Responding:  20%|‚ñà‚ñâ        | 174/875 [25:04<1:41:25,  8.68s/it]Model Responding:  20%|‚ñà‚ñà        | 175/875 [25:13<1:40:47,  8.64s/it]Model Responding:  20%|‚ñà‚ñà        | 176/875 [25:21<1:40:17,  8.61s/it]Model Responding:  20%|‚ñà‚ñà        | 177/875 [25:30<1:41:18,  8.71s/it]Model Responding:  20%|‚ñà‚ñà        | 178/875 [25:39<1:39:33,  8.57s/it]Model Responding:  20%|‚ñà‚ñà        | 179/875 [25:48<1:41:41,  8.77s/it]Model Responding:  21%|‚ñà‚ñà        | 180/875 [25:57<1:42:15,  8.83s/it]Model Responding:  21%|‚ñà‚ñà        | 181/875 [26:06<1:42:23,  8.85s/it]Model Responding:  21%|‚ñà‚ñà        | 182/875 [26:14<1:40:09,  8.67s/it]Model Responding:  21%|‚ñà‚ñà        | 183/875 [26:23<1:40:12,  8.69s/it]Model Responding:  21%|‚ñà‚ñà        | 184/875 [26:31<1:38:39,  8.57s/it]Model Responding:  21%|‚ñà‚ñà        | 185/875 [26:39<1:36:36,  8.40s/it]Model Responding:  21%|‚ñà‚ñà‚ñè       | 186/875 [26:48<1:38:11,  8.55s/it]Model Responding:  21%|‚ñà‚ñà‚ñè       | 187/875 [26:56<1:35:31,  8.33s/it]Model Responding:  21%|‚ñà‚ñà‚ñè       | 188/875 [27:04<1:36:32,  8.43s/it]Model Responding:  22%|‚ñà‚ñà‚ñè       | 189/875 [27:12<1:35:01,  8.31s/it]Model Responding:  22%|‚ñà‚ñà‚ñè       | 190/875 [27:21<1:35:19,  8.35s/it]Model Responding:  22%|‚ñà‚ñà‚ñè       | 191/875 [27:29<1:35:33,  8.38s/it]Model Responding:  22%|‚ñà‚ñà‚ñè       | 192/875 [27:38<1:35:50,  8.42s/it]Model Responding:  22%|‚ñà‚ñà‚ñè       | 193/875 [27:46<1:36:41,  8.51s/it]Model Responding:  22%|‚ñà‚ñà‚ñè       | 194/875 [27:55<1:37:22,  8.58s/it]Model Responding:  22%|‚ñà‚ñà‚ñè       | 195/875 [28:03<1:34:40,  8.35s/it]Model Responding:  22%|‚ñà‚ñà‚ñè       | 196/875 [28:12<1:37:16,  8.60s/it]Model Responding:  23%|‚ñà‚ñà‚ñé       | 197/875 [28:21<1:36:47,  8.57s/it]Model Responding:  23%|‚ñà‚ñà‚ñé       | 198/875 [28:29<1:37:11,  8.61s/it]Model Responding:  23%|‚ñà‚ñà‚ñé       | 199/875 [28:38<1:36:15,  8.54s/it]Model Responding:  23%|‚ñà‚ñà‚ñé       | 200/875 [28:48<1:40:19,  8.92s/it]Model Responding:  23%|‚ñà‚ñà‚ñé       | 201/875 [28:56<1:39:01,  8.81s/it]Model Responding:  23%|‚ñà‚ñà‚ñé       | 202/875 [29:05<1:39:00,  8.83s/it]Model Responding:  23%|‚ñà‚ñà‚ñé       | 203/875 [29:13<1:36:04,  8.58s/it]Model Responding:  23%|‚ñà‚ñà‚ñé       | 204/875 [29:22<1:35:46,  8.56s/it]Model Responding:  23%|‚ñà‚ñà‚ñé       | 205/875 [29:30<1:34:27,  8.46s/it]Model Responding:  24%|‚ñà‚ñà‚ñé       | 206/875 [29:38<1:34:19,  8.46s/it]Model Responding:  24%|‚ñà‚ñà‚ñé       | 207/875 [29:47<1:34:18,  8.47s/it]Model Responding:  24%|‚ñà‚ñà‚ñç       | 208/875 [29:55<1:32:44,  8.34s/it]Model Responding:  24%|‚ñà‚ñà‚ñç       | 209/875 [30:04<1:34:03,  8.47s/it]Model Responding:  24%|‚ñà‚ñà‚ñç       | 210/875 [30:12<1:33:38,  8.45s/it]Model Responding:  24%|‚ñà‚ñà‚ñç       | 211/875 [30:20<1:33:27,  8.45s/it]Model Responding:  24%|‚ñà‚ñà‚ñç       | 212/875 [30:29<1:33:55,  8.50s/it]Model Responding:  24%|‚ñà‚ñà‚ñç       | 213/875 [30:37<1:32:19,  8.37s/it]Model Responding:  24%|‚ñà‚ñà‚ñç       | 214/875 [30:46<1:33:39,  8.50s/it]Model Responding:  25%|‚ñà‚ñà‚ñç       | 215/875 [30:55<1:34:12,  8.57s/it]Model Responding:  25%|‚ñà‚ñà‚ñç       | 216/875 [31:03<1:34:50,  8.63s/it]Model Responding:  25%|‚ñà‚ñà‚ñç       | 217/875 [31:12<1:34:18,  8.60s/it]Model Responding:  25%|‚ñà‚ñà‚ñç       | 218/875 [31:21<1:35:03,  8.68s/it]Model Responding:  25%|‚ñà‚ñà‚ñå       | 219/875 [31:29<1:34:34,  8.65s/it]Model Responding:  25%|‚ñà‚ñà‚ñå       | 220/875 [31:38<1:34:21,  8.64s/it]Model Responding:  25%|‚ñà‚ñà‚ñå       | 221/875 [31:46<1:31:29,  8.39s/it]Model Responding:  25%|‚ñà‚ñà‚ñå       | 222/875 [31:54<1:30:56,  8.36s/it]Model Responding:  25%|‚ñà‚ñà‚ñå       | 223/875 [32:03<1:31:21,  8.41s/it]Model Responding:  26%|‚ñà‚ñà‚ñå       | 224/875 [32:11<1:32:04,  8.49s/it]Model Responding:  26%|‚ñà‚ñà‚ñå       | 225/875 [32:20<1:31:26,  8.44s/it]Model Responding:  26%|‚ñà‚ñà‚ñå       | 226/875 [32:29<1:33:22,  8.63s/it]Model Responding:  26%|‚ñà‚ñà‚ñå       | 227/875 [32:38<1:35:32,  8.85s/it]Model Responding:  26%|‚ñà‚ñà‚ñå       | 228/875 [32:47<1:35:13,  8.83s/it]Model Responding:  26%|‚ñà‚ñà‚ñå       | 229/875 [32:55<1:33:09,  8.65s/it]Model Responding:  26%|‚ñà‚ñà‚ñã       | 230/875 [33:04<1:34:40,  8.81s/it]Model Responding:  26%|‚ñà‚ñà‚ñã       | 231/875 [33:12<1:31:14,  8.50s/it]Model Responding:  27%|‚ñà‚ñà‚ñã       | 232/875 [33:20<1:31:01,  8.49s/it]Model Responding:  27%|‚ñà‚ñà‚ñã       | 233/875 [33:29<1:30:23,  8.45s/it]Model Responding:  27%|‚ñà‚ñà‚ñã       | 234/875 [33:38<1:31:51,  8.60s/it]Model Responding:  27%|‚ñà‚ñà‚ñã       | 235/875 [33:47<1:32:38,  8.69s/it]Model Responding:  27%|‚ñà‚ñà‚ñã       | 236/875 [33:55<1:31:31,  8.59s/it]Model Responding:  27%|‚ñà‚ñà‚ñã       | 237/875 [34:03<1:30:46,  8.54s/it]Model Responding:  27%|‚ñà‚ñà‚ñã       | 238/875 [34:12<1:32:15,  8.69s/it]Model Responding:  27%|‚ñà‚ñà‚ñã       | 239/875 [34:21<1:31:59,  8.68s/it]Model Responding:  27%|‚ñà‚ñà‚ñã       | 240/875 [34:29<1:30:43,  8.57s/it]Model Responding:  28%|‚ñà‚ñà‚ñä       | 241/875 [34:39<1:32:29,  8.75s/it]Model Responding:  28%|‚ñà‚ñà‚ñä       | 242/875 [34:47<1:31:00,  8.63s/it]Model Responding:  28%|‚ñà‚ñà‚ñä       | 243/875 [34:56<1:32:19,  8.76s/it]Model Responding:  28%|‚ñà‚ñà‚ñä       | 244/875 [35:05<1:33:07,  8.85s/it]Model Responding:  28%|‚ñà‚ñà‚ñä       | 245/875 [35:14<1:33:21,  8.89s/it]Model Responding:  28%|‚ñà‚ñà‚ñä       | 246/875 [35:23<1:33:10,  8.89s/it]Model Responding:  28%|‚ñà‚ñà‚ñä       | 247/875 [35:32<1:32:18,  8.82s/it]Model Responding:  28%|‚ñà‚ñà‚ñä       | 248/875 [35:40<1:30:32,  8.66s/it]Model Responding:  28%|‚ñà‚ñà‚ñä       | 249/875 [35:48<1:29:23,  8.57s/it]Model Responding:  29%|‚ñà‚ñà‚ñä       | 250/875 [35:57<1:28:35,  8.50s/it]Model Responding:  29%|‚ñà‚ñà‚ñä       | 251/875 [36:05<1:27:55,  8.45s/it]Model Responding:  29%|‚ñà‚ñà‚ñâ       | 252/875 [36:13<1:27:17,  8.41s/it]Model Responding:  29%|‚ñà‚ñà‚ñâ       | 253/875 [36:22<1:26:46,  8.37s/it]Model Responding:  29%|‚ñà‚ñà‚ñâ       | 254/875 [36:30<1:27:37,  8.47s/it]Model Responding:  29%|‚ñà‚ñà‚ñâ       | 255/875 [36:39<1:29:28,  8.66s/it]Model Responding:  29%|‚ñà‚ñà‚ñâ       | 256/875 [36:48<1:28:15,  8.55s/it]Model Responding:  29%|‚ñà‚ñà‚ñâ       | 257/875 [36:56<1:27:54,  8.53s/it]Model Responding:  29%|‚ñà‚ñà‚ñâ       | 258/875 [37:05<1:29:28,  8.70s/it]Model Responding:  30%|‚ñà‚ñà‚ñâ       | 259/875 [37:13<1:27:14,  8.50s/it]Model Responding:  30%|‚ñà‚ñà‚ñâ       | 260/875 [37:22<1:28:16,  8.61s/it]Model Responding:  30%|‚ñà‚ñà‚ñâ       | 261/875 [37:30<1:26:12,  8.42s/it]Model Responding:  30%|‚ñà‚ñà‚ñâ       | 262/875 [37:38<1:25:37,  8.38s/it]Model Responding:  30%|‚ñà‚ñà‚ñà       | 263/875 [37:47<1:25:17,  8.36s/it]Model Responding:  30%|‚ñà‚ñà‚ñà       | 264/875 [37:55<1:25:23,  8.39s/it]Model Responding:  30%|‚ñà‚ñà‚ñà       | 265/875 [38:04<1:25:58,  8.46s/it]Model Responding:  30%|‚ñà‚ñà‚ñà       | 266/875 [38:12<1:25:07,  8.39s/it]Model Responding:  31%|‚ñà‚ñà‚ñà       | 267/875 [38:20<1:24:44,  8.36s/it]Model Responding:  31%|‚ñà‚ñà‚ñà       | 268/875 [38:29<1:24:15,  8.33s/it]Model Responding:  31%|‚ñà‚ñà‚ñà       | 269/875 [38:37<1:23:27,  8.26s/it]Model Responding:  31%|‚ñà‚ñà‚ñà       | 270/875 [38:45<1:23:37,  8.29s/it]Model Responding:  31%|‚ñà‚ñà‚ñà       | 271/875 [38:54<1:25:35,  8.50s/it]Model Responding:  31%|‚ñà‚ñà‚ñà       | 272/875 [39:03<1:25:48,  8.54s/it]Model Responding:  31%|‚ñà‚ñà‚ñà       | 273/875 [39:11<1:26:25,  8.61s/it]Model Responding:  31%|‚ñà‚ñà‚ñà‚ñè      | 274/875 [39:20<1:26:18,  8.62s/it]Model Responding:  31%|‚ñà‚ñà‚ñà‚ñè      | 275/875 [39:29<1:25:57,  8.60s/it]Model Responding:  32%|‚ñà‚ñà‚ñà‚ñè      | 276/875 [39:38<1:28:21,  8.85s/it]Model Responding:  32%|‚ñà‚ñà‚ñà‚ñè      | 277/875 [39:47<1:28:37,  8.89s/it]Model Responding:  32%|‚ñà‚ñà‚ñà‚ñè      | 278/875 [39:56<1:27:12,  8.77s/it]Model Responding:  32%|‚ñà‚ñà‚ñà‚ñè      | 279/875 [40:04<1:25:26,  8.60s/it]Model Responding:  32%|‚ñà‚ñà‚ñà‚ñè      | 280/875 [40:13<1:27:07,  8.79s/it]Model Responding:  32%|‚ñà‚ñà‚ñà‚ñè      | 281/875 [40:21<1:25:29,  8.64s/it]Model Responding:  32%|‚ñà‚ñà‚ñà‚ñè      | 282/875 [40:29<1:23:56,  8.49s/it]Model Responding:  32%|‚ñà‚ñà‚ñà‚ñè      | 283/875 [40:38<1:23:45,  8.49s/it]Model Responding:  32%|‚ñà‚ñà‚ñà‚ñè      | 284/875 [40:47<1:24:11,  8.55s/it]Model Responding:  33%|‚ñà‚ñà‚ñà‚ñé      | 285/875 [40:55<1:24:13,  8.57s/it]Model Responding:  33%|‚ñà‚ñà‚ñà‚ñé      | 286/875 [41:04<1:24:26,  8.60s/it]Model Responding:  33%|‚ñà‚ñà‚ñà‚ñé      | 287/875 [41:13<1:24:43,  8.64s/it]Model Responding:  33%|‚ñà‚ñà‚ñà‚ñé      | 288/875 [41:21<1:24:09,  8.60s/it]Model Responding:  33%|‚ñà‚ñà‚ñà‚ñé      | 289/875 [41:29<1:23:14,  8.52s/it]Model Responding:  33%|‚ñà‚ñà‚ñà‚ñé      | 290/875 [41:38<1:22:58,  8.51s/it]Model Responding:  33%|‚ñà‚ñà‚ñà‚ñé      | 291/875 [41:46<1:22:28,  8.47s/it]Model Responding:  33%|‚ñà‚ñà‚ñà‚ñé      | 292/875 [41:55<1:21:47,  8.42s/it]Model Responding:  33%|‚ñà‚ñà‚ñà‚ñé      | 293/875 [42:03<1:22:53,  8.55s/it]Model Responding:  34%|‚ñà‚ñà‚ñà‚ñé      | 294/875 [42:12<1:23:03,  8.58s/it]Model Responding:  34%|‚ñà‚ñà‚ñà‚ñé      | 295/875 [42:21<1:23:03,  8.59s/it]Model Responding:  34%|‚ñà‚ñà‚ñà‚ñç      | 296/875 [42:29<1:22:32,  8.55s/it]Model Responding:  34%|‚ñà‚ñà‚ñà‚ñç      | 297/875 [42:38<1:23:24,  8.66s/it]Model Responding:  34%|‚ñà‚ñà‚ñà‚ñç      | 298/875 [42:47<1:23:33,  8.69s/it]Model Responding:  34%|‚ñà‚ñà‚ñà‚ñç      | 299/875 [42:56<1:23:47,  8.73s/it]Model Responding:  34%|‚ñà‚ñà‚ñà‚ñç      | 300/875 [43:04<1:22:52,  8.65s/it]Model Responding:  34%|‚ñà‚ñà‚ñà‚ñç      | 301/875 [43:12<1:21:42,  8.54s/it]Model Responding:  35%|‚ñà‚ñà‚ñà‚ñç      | 302/875 [43:21<1:22:24,  8.63s/it]Model Responding:  35%|‚ñà‚ñà‚ñà‚ñç      | 303/875 [43:30<1:21:16,  8.53s/it]Model Responding:  35%|‚ñà‚ñà‚ñà‚ñç      | 304/875 [43:39<1:22:38,  8.68s/it]Model Responding:  35%|‚ñà‚ñà‚ñà‚ñç      | 305/875 [43:47<1:22:27,  8.68s/it]Model Responding:  35%|‚ñà‚ñà‚ñà‚ñç      | 306/875 [43:56<1:22:48,  8.73s/it]Model Responding:  35%|‚ñà‚ñà‚ñà‚ñå      | 307/875 [44:05<1:23:52,  8.86s/it]Model Responding:  35%|‚ñà‚ñà‚ñà‚ñå      | 308/875 [44:14<1:22:48,  8.76s/it]Model Responding:  35%|‚ñà‚ñà‚ñà‚ñå      | 309/875 [44:22<1:22:21,  8.73s/it]Model Responding:  35%|‚ñà‚ñà‚ñà‚ñå      | 310/875 [44:31<1:22:38,  8.78s/it]Model Responding:  36%|‚ñà‚ñà‚ñà‚ñå      | 311/875 [44:40<1:21:18,  8.65s/it]Model Responding:  36%|‚ñà‚ñà‚ñà‚ñå      | 312/875 [44:48<1:20:37,  8.59s/it]Model Responding:  36%|‚ñà‚ñà‚ñà‚ñå      | 313/875 [44:57<1:21:28,  8.70s/it]Model Responding:  36%|‚ñà‚ñà‚ñà‚ñå      | 314/875 [45:07<1:24:16,  9.01s/it]Model Responding:  36%|‚ñà‚ñà‚ñà‚ñå      | 315/875 [45:15<1:22:55,  8.89s/it]Model Responding:  36%|‚ñà‚ñà‚ñà‚ñå      | 316/875 [45:24<1:21:18,  8.73s/it]Model Responding:  36%|‚ñà‚ñà‚ñà‚ñå      | 317/875 [45:33<1:22:03,  8.82s/it]Model Responding:  36%|‚ñà‚ñà‚ñà‚ñã      | 318/875 [45:42<1:23:04,  8.95s/it]Model Responding:  36%|‚ñà‚ñà‚ñà‚ñã      | 319/875 [45:51<1:22:40,  8.92s/it]Model Responding:  37%|‚ñà‚ñà‚ñà‚ñã      | 320/875 [45:59<1:21:10,  8.78s/it]Model Responding:  37%|‚ñà‚ñà‚ñà‚ñã      | 321/875 [46:08<1:20:07,  8.68s/it]Model Responding:  37%|‚ñà‚ñà‚ñà‚ñã      | 322/875 [46:16<1:18:40,  8.54s/it]Model Responding:  37%|‚ñà‚ñà‚ñà‚ñã      | 323/875 [46:25<1:19:03,  8.59s/it]Model Responding:  37%|‚ñà‚ñà‚ñà‚ñã      | 324/875 [46:33<1:19:11,  8.62s/it]Model Responding:  37%|‚ñà‚ñà‚ñà‚ñã      | 325/875 [46:42<1:19:38,  8.69s/it]Model Responding:  37%|‚ñà‚ñà‚ñà‚ñã      | 326/875 [46:51<1:19:26,  8.68s/it]Model Responding:  37%|‚ñà‚ñà‚ñà‚ñã      | 327/875 [47:00<1:20:16,  8.79s/it]Model Responding:  37%|‚ñà‚ñà‚ñà‚ñã      | 328/875 [47:09<1:21:06,  8.90s/it]Model Responding:  38%|‚ñà‚ñà‚ñà‚ñä      | 329/875 [47:18<1:19:50,  8.77s/it]Model Responding:  38%|‚ñà‚ñà‚ñà‚ñä      | 330/875 [47:27<1:20:06,  8.82s/it]Model Responding:  38%|‚ñà‚ñà‚ñà‚ñä      | 331/875 [47:35<1:19:10,  8.73s/it]Model Responding:  38%|‚ñà‚ñà‚ñà‚ñä      | 332/875 [47:43<1:18:01,  8.62s/it]Model Responding:  38%|‚ñà‚ñà‚ñà‚ñä      | 333/875 [47:52<1:17:28,  8.58s/it]Model Responding:  38%|‚ñà‚ñà‚ñà‚ñä      | 334/875 [48:00<1:16:40,  8.50s/it]Model Responding:  38%|‚ñà‚ñà‚ñà‚ñä      | 335/875 [48:08<1:14:54,  8.32s/it]Model Responding:  38%|‚ñà‚ñà‚ñà‚ñä      | 336/875 [48:17<1:16:13,  8.48s/it]Model Responding:  39%|‚ñà‚ñà‚ñà‚ñä      | 337/875 [48:26<1:18:11,  8.72s/it]Model Responding:  39%|‚ñà‚ñà‚ñà‚ñä      | 338/875 [48:36<1:19:25,  8.87s/it]Model Responding:  39%|‚ñà‚ñà‚ñà‚ñä      | 339/875 [48:43<1:16:29,  8.56s/it]Model Responding:  39%|‚ñà‚ñà‚ñà‚ñâ      | 340/875 [48:52<1:16:51,  8.62s/it]Model Responding:  39%|‚ñà‚ñà‚ñà‚ñâ      | 341/875 [49:00<1:15:24,  8.47s/it]Model Responding:  39%|‚ñà‚ñà‚ñà‚ñâ      | 342/875 [49:09<1:14:43,  8.41s/it]Model Responding:  39%|‚ñà‚ñà‚ñà‚ñâ      | 343/875 [49:17<1:15:18,  8.49s/it]Model Responding:  39%|‚ñà‚ñà‚ñà‚ñâ      | 344/875 [49:26<1:16:36,  8.66s/it]Model Responding:  39%|‚ñà‚ñà‚ñà‚ñâ      | 345/875 [49:35<1:15:50,  8.59s/it]Model Responding:  40%|‚ñà‚ñà‚ñà‚ñâ      | 346/875 [49:43<1:14:30,  8.45s/it]Model Responding:  40%|‚ñà‚ñà‚ñà‚ñâ      | 347/875 [49:51<1:14:47,  8.50s/it]Model Responding:  40%|‚ñà‚ñà‚ñà‚ñâ      | 348/875 [50:00<1:14:26,  8.47s/it]Model Responding:  40%|‚ñà‚ñà‚ñà‚ñâ      | 349/875 [50:08<1:13:36,  8.40s/it]Model Responding:  40%|‚ñà‚ñà‚ñà‚ñà      | 350/875 [50:16<1:11:49,  8.21s/it]Model Responding:  40%|‚ñà‚ñà‚ñà‚ñà      | 351/875 [50:25<1:13:22,  8.40s/it]Model Responding:  40%|‚ñà‚ñà‚ñà‚ñà      | 352/875 [50:33<1:14:04,  8.50s/it]Model Responding:  40%|‚ñà‚ñà‚ñà‚ñà      | 353/875 [50:42<1:14:40,  8.58s/it]Model Responding:  40%|‚ñà‚ñà‚ñà‚ñà      | 354/875 [50:50<1:13:21,  8.45s/it]Model Responding:  41%|‚ñà‚ñà‚ñà‚ñà      | 355/875 [50:59<1:12:37,  8.38s/it]Model Responding:  41%|‚ñà‚ñà‚ñà‚ñà      | 356/875 [51:07<1:11:52,  8.31s/it]Model Responding:  41%|‚ñà‚ñà‚ñà‚ñà      | 357/875 [51:15<1:11:18,  8.26s/it]Model Responding:  41%|‚ñà‚ñà‚ñà‚ñà      | 358/875 [51:23<1:12:04,  8.36s/it]Model Responding:  41%|‚ñà‚ñà‚ñà‚ñà      | 359/875 [51:31<1:11:10,  8.28s/it]Model Responding:  41%|‚ñà‚ñà‚ñà‚ñà      | 360/875 [51:40<1:11:13,  8.30s/it]Model Responding:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 361/875 [51:48<1:09:52,  8.16s/it]Model Responding:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 362/875 [51:56<1:10:30,  8.25s/it]Model Responding:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 363/875 [52:04<1:10:23,  8.25s/it]Model Responding:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 364/875 [52:13<1:10:59,  8.34s/it]Model Responding:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 365/875 [52:21<1:11:00,  8.35s/it]Model Responding:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 366/875 [52:30<1:10:47,  8.35s/it]Model Responding:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 367/875 [52:38<1:10:28,  8.32s/it]Model Responding:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 368/875 [52:46<1:09:50,  8.27s/it]Model Responding:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 369/875 [52:55<1:10:42,  8.38s/it]Model Responding:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 370/875 [53:03<1:11:10,  8.46s/it]Model Responding:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 371/875 [53:12<1:12:33,  8.64s/it]Model Responding:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 372/875 [53:21<1:12:09,  8.61s/it]Model Responding:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 373/875 [53:29<1:11:12,  8.51s/it]Model Responding:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 374/875 [53:38<1:10:32,  8.45s/it]Model Responding:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 375/875 [53:46<1:10:51,  8.50s/it]Model Responding:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 376/875 [53:55<1:10:35,  8.49s/it]Model Responding:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 377/875 [54:03<1:09:46,  8.41s/it]Model Responding:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 378/875 [54:11<1:10:07,  8.47s/it]Model Responding:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 379/875 [54:20<1:09:48,  8.44s/it]Model Responding:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 380/875 [54:28<1:09:31,  8.43s/it]Model Responding:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 381/875 [54:37<1:10:25,  8.55s/it]Model Responding:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 382/875 [54:45<1:07:57,  8.27s/it]Model Responding:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 383/875 [54:53<1:08:44,  8.38s/it]Model Responding:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 384/875 [55:01<1:06:38,  8.14s/it]Model Responding:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 385/875 [55:09<1:07:03,  8.21s/it]Model Responding:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 386/875 [55:18<1:07:16,  8.25s/it]Model Responding:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 387/875 [55:26<1:07:55,  8.35s/it]Model Responding:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 388/875 [55:35<1:07:44,  8.35s/it]Model Responding:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 389/875 [55:43<1:08:50,  8.50s/it]Model Responding:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 390/875 [55:52<1:08:59,  8.54s/it]Model Responding:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 391/875 [56:01<1:09:05,  8.57s/it]Model Responding:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 392/875 [56:09<1:08:05,  8.46s/it]Model Responding:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 393/875 [56:17<1:07:43,  8.43s/it]Model Responding:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 394/875 [56:26<1:07:54,  8.47s/it]Model Responding:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 395/875 [56:34<1:06:45,  8.35s/it]Model Responding:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 396/875 [56:43<1:07:26,  8.45s/it]Model Responding:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 397/875 [56:51<1:06:33,  8.36s/it]Model Responding:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 398/875 [57:00<1:07:47,  8.53s/it]Model Responding:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 399/875 [57:08<1:08:04,  8.58s/it]Model Responding:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 400/875 [57:17<1:07:32,  8.53s/it]Model Responding:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 401/875 [57:26<1:08:27,  8.67s/it]Model Responding:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 402/875 [57:34<1:07:12,  8.53s/it]Model Responding:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 403/875 [57:43<1:08:30,  8.71s/it]Model Responding:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 404/875 [57:52<1:08:29,  8.73s/it]Model Responding:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 405/875 [58:00<1:07:31,  8.62s/it]Model Responding:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 406/875 [58:08<1:05:50,  8.42s/it]Model Responding:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 407/875 [58:16<1:05:08,  8.35s/it]Model Responding:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 408/875 [58:25<1:05:32,  8.42s/it]Model Responding:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 409/875 [58:33<1:04:35,  8.32s/it]Model Responding:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 410/875 [58:41<1:04:34,  8.33s/it]Model Responding:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 411/875 [58:50<1:04:15,  8.31s/it]Model Responding:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 412/875 [58:59<1:06:19,  8.59s/it]Model Responding:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 413/875 [59:08<1:07:06,  8.72s/it]Model Responding:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 414/875 [59:17<1:07:17,  8.76s/it]Model Responding:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 415/875 [59:26<1:08:41,  8.96s/it]Model Responding:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 416/875 [59:34<1:06:53,  8.74s/it]Model Responding:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 417/875 [59:43<1:07:01,  8.78s/it]Model Responding:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 418/875 [59:52<1:06:57,  8.79s/it]Model Responding:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 419/875 [1:00:01<1:07:45,  8.91s/it]Model Responding:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 420/875 [1:00:10<1:06:23,  8.75s/it]Model Responding:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 421/875 [1:00:17<1:04:01,  8.46s/it]Model Responding:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 422/875 [1:00:26<1:05:00,  8.61s/it]Model Responding:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 423/875 [1:00:35<1:04:38,  8.58s/it]Model Responding:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 424/875 [1:00:43<1:03:47,  8.49s/it]Model Responding:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 425/875 [1:00:51<1:02:41,  8.36s/it]Model Responding:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 426/875 [1:00:59<1:01:15,  8.19s/it]Model Responding:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 427/875 [1:01:07<1:01:37,  8.25s/it]Model Responding:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 428/875 [1:01:16<1:01:22,  8.24s/it]Model Responding:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 429/875 [1:01:24<1:01:59,  8.34s/it]Model Responding:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 430/875 [1:01:32<1:01:31,  8.30s/it]Model Responding:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 431/875 [1:01:41<1:02:47,  8.49s/it]Model Responding:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 432/875 [1:01:50<1:03:23,  8.58s/it]Model Responding:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 433/875 [1:01:59<1:03:47,  8.66s/it]Model Responding:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 434/875 [1:02:07<1:01:33,  8.37s/it]Model Responding:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 435/875 [1:02:15<1:01:27,  8.38s/it]Model Responding:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 436/875 [1:02:24<1:01:48,  8.45s/it]Model Responding:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 437/875 [1:02:32<1:00:49,  8.33s/it]Model Responding:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 438/875 [1:02:41<1:01:53,  8.50s/it]Model Responding:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 439/875 [1:02:50<1:03:03,  8.68s/it]Model Responding:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 440/875 [1:02:59<1:03:57,  8.82s/it]Model Responding:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 441/875 [1:03:08<1:05:29,  9.05s/it]Model Responding:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 442/875 [1:03:17<1:03:53,  8.85s/it]Model Responding:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 443/875 [1:03:26<1:04:07,  8.91s/it]Model Responding:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 444/875 [1:03:34<1:02:14,  8.66s/it]Model Responding:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 445/875 [1:03:42<1:01:33,  8.59s/it]Model Responding:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 446/875 [1:03:51<1:01:14,  8.56s/it]Model Responding:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 447/875 [1:04:00<1:01:15,  8.59s/it]Model Responding:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 448/875 [1:04:09<1:02:20,  8.76s/it]Model Responding:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 449/875 [1:04:18<1:03:03,  8.88s/it]Model Responding:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 450/875 [1:04:27<1:02:59,  8.89s/it]Model Responding:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 451/875 [1:04:35<1:01:04,  8.64s/it]Model Responding:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 452/875 [1:04:44<1:01:32,  8.73s/it]Model Responding:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 453/875 [1:04:52<1:00:43,  8.63s/it]Model Responding:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 454/875 [1:05:00<59:47,  8.52s/it]  Model Responding:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 455/875 [1:05:09<1:00:04,  8.58s/it]Model Responding:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 456/875 [1:05:18<1:00:38,  8.68s/it]Model Responding:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 457/875 [1:05:27<1:01:13,  8.79s/it]Model Responding:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 458/875 [1:05:36<1:00:52,  8.76s/it]Model Responding:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 459/875 [1:05:45<1:00:35,  8.74s/it]Model Responding:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 460/875 [1:05:53<59:46,  8.64s/it]  Model Responding:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 461/875 [1:06:02<1:00:16,  8.74s/it]Model Responding:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 462/875 [1:06:11<1:00:11,  8.74s/it]Model Responding:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 463/875 [1:06:19<1:00:03,  8.75s/it]Model Responding:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 464/875 [1:06:28<1:00:02,  8.76s/it]Model Responding:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 465/875 [1:06:37<59:28,  8.70s/it]  Model Responding:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 466/875 [1:06:45<58:52,  8.64s/it]Model Responding:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 467/875 [1:06:53<57:55,  8.52s/it]Model Responding:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 468/875 [1:07:02<57:06,  8.42s/it]Model Responding:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 469/875 [1:07:11<58:27,  8.64s/it]Model Responding:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 470/875 [1:07:19<57:55,  8.58s/it]Model Responding:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 471/875 [1:07:28<58:49,  8.74s/it]Model Responding:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 472/875 [1:07:37<58:38,  8.73s/it]Model Responding:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 473/875 [1:07:46<58:25,  8.72s/it]Model Responding:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 474/875 [1:07:55<58:49,  8.80s/it]Model Responding:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 475/875 [1:08:04<59:12,  8.88s/it]Model Responding:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 476/875 [1:08:12<58:12,  8.75s/it]Model Responding:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 477/875 [1:08:21<58:02,  8.75s/it]Model Responding:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 478/875 [1:08:30<57:30,  8.69s/it]Model Responding:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 479/875 [1:08:38<56:13,  8.52s/it]Model Responding:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 480/875 [1:08:46<55:26,  8.42s/it]Model Responding:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 481/875 [1:08:54<55:13,  8.41s/it]Model Responding:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 482/875 [1:09:02<54:24,  8.31s/it]Model Responding:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 483/875 [1:09:11<54:36,  8.36s/it]Model Responding:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 484/875 [1:09:19<54:27,  8.36s/it]Model Responding:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 485/875 [1:09:28<55:12,  8.49s/it]Model Responding:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 486/875 [1:09:36<53:46,  8.29s/it]Model Responding:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 487/875 [1:09:45<55:05,  8.52s/it]Model Responding:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 488/875 [1:09:53<55:00,  8.53s/it]Model Responding:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 489/875 [1:10:02<54:22,  8.45s/it]Model Responding:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 490/875 [1:10:10<54:09,  8.44s/it]Model Responding:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 491/875 [1:10:19<54:07,  8.46s/it]Model Responding:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 492/875 [1:10:27<54:23,  8.52s/it]Model Responding:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 493/875 [1:10:35<53:35,  8.42s/it]Model Responding:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 494/875 [1:10:44<53:58,  8.50s/it]Model Responding:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 495/875 [1:10:52<53:21,  8.42s/it]Model Responding:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 496/875 [1:11:01<53:14,  8.43s/it]Model Responding:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 497/875 [1:11:09<53:24,  8.48s/it]Model Responding:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 498/875 [1:11:18<53:41,  8.54s/it]Model Responding:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 499/875 [1:11:27<54:43,  8.73s/it]Model Responding:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 500/875 [1:11:36<53:59,  8.64s/it]Model Responding:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 501/875 [1:11:44<54:04,  8.68s/it]Model Responding:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 502/875 [1:11:53<53:14,  8.56s/it]Model Responding:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 503/875 [1:12:02<53:32,  8.63s/it]Model Responding:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 504/875 [1:12:11<54:50,  8.87s/it]Model Responding:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 505/875 [1:12:19<53:05,  8.61s/it]Model Responding:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 506/875 [1:12:28<53:46,  8.74s/it]Model Responding:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 507/875 [1:12:37<54:12,  8.84s/it]Model Responding:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 508/875 [1:12:46<54:13,  8.87s/it]Model Responding:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 509/875 [1:12:55<54:24,  8.92s/it]Model Responding:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 510/875 [1:13:04<54:00,  8.88s/it]Model Responding:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 511/875 [1:13:12<53:21,  8.79s/it]Model Responding:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 512/875 [1:13:21<53:03,  8.77s/it]Model Responding:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 513/875 [1:13:30<52:27,  8.69s/it]Model Responding:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 514/875 [1:13:38<51:52,  8.62s/it]Model Responding:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 515/875 [1:13:48<53:04,  8.84s/it]Model Responding:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 516/875 [1:13:56<51:34,  8.62s/it]Model Responding:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 517/875 [1:14:05<52:23,  8.78s/it]Model Responding:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 518/875 [1:14:13<51:47,  8.70s/it]Model Responding:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 519/875 [1:14:22<51:29,  8.68s/it]Model Responding:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 520/875 [1:14:31<51:29,  8.70s/it]Model Responding:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 521/875 [1:14:40<51:48,  8.78s/it]Model Responding:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 522/875 [1:14:49<51:57,  8.83s/it]Model Responding:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 523/875 [1:14:57<50:39,  8.63s/it]Model Responding:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 524/875 [1:15:05<50:24,  8.62s/it]Model Responding:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 525/875 [1:15:14<50:20,  8.63s/it]Model Responding:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 526/875 [1:15:23<51:04,  8.78s/it]Model Responding:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 527/875 [1:15:32<51:42,  8.92s/it]Model Responding:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 528/875 [1:15:41<50:54,  8.80s/it]Model Responding:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 529/875 [1:15:49<50:09,  8.70s/it]Model Responding:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 530/875 [1:15:58<50:47,  8.83s/it]Model Responding:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 531/875 [1:16:07<50:51,  8.87s/it]Model Responding:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 532/875 [1:16:16<50:35,  8.85s/it]Model Responding:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 533/875 [1:16:25<50:01,  8.78s/it]Model Responding:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 534/875 [1:16:33<48:47,  8.58s/it]Model Responding:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 535/875 [1:16:41<47:52,  8.45s/it]Model Responding:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 536/875 [1:16:49<47:20,  8.38s/it]Model Responding:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 537/875 [1:16:58<47:20,  8.40s/it]Model Responding:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 538/875 [1:17:06<47:19,  8.43s/it]Model Responding:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 539/875 [1:17:14<46:44,  8.35s/it]Model Responding:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 540/875 [1:17:23<46:53,  8.40s/it]Model Responding:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 541/875 [1:17:31<46:55,  8.43s/it]Model Responding:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 542/875 [1:17:40<47:04,  8.48s/it]Model Responding:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 543/875 [1:17:49<47:11,  8.53s/it]Model Responding:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 544/875 [1:17:57<47:21,  8.59s/it]Model Responding:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 545/875 [1:18:06<47:21,  8.61s/it]Model Responding:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 546/875 [1:18:15<46:52,  8.55s/it]Model Responding:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 547/875 [1:18:23<46:51,  8.57s/it]Model Responding:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 548/875 [1:18:31<46:15,  8.49s/it]Model Responding:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 549/875 [1:18:39<45:06,  8.30s/it]Model Responding:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 550/875 [1:18:48<45:46,  8.45s/it]Model Responding:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 551/875 [1:18:57<46:17,  8.57s/it]Model Responding:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 552/875 [1:19:05<46:06,  8.56s/it]Model Responding:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 553/875 [1:19:14<46:36,  8.68s/it]Model Responding:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 554/875 [1:19:24<47:05,  8.80s/it]Model Responding:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 555/875 [1:19:32<46:19,  8.69s/it]Model Responding:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 556/875 [1:19:40<45:53,  8.63s/it]Model Responding:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 557/875 [1:19:49<45:12,  8.53s/it]Model Responding:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 558/875 [1:19:57<44:32,  8.43s/it]Model Responding:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 559/875 [1:20:06<45:06,  8.57s/it]Model Responding:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 560/875 [1:20:15<46:00,  8.76s/it]Model Responding:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 561/875 [1:20:24<45:48,  8.75s/it]Model Responding:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 562/875 [1:20:32<44:50,  8.59s/it]Model Responding:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 563/875 [1:20:40<44:20,  8.53s/it]Model Responding:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 564/875 [1:20:49<44:37,  8.61s/it]Model Responding:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 565/875 [1:20:57<43:37,  8.44s/it]Model Responding:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 566/875 [1:21:05<43:12,  8.39s/it]Model Responding:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 567/875 [1:21:14<42:59,  8.38s/it]Model Responding:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 568/875 [1:21:23<43:30,  8.50s/it]Model Responding:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 569/875 [1:21:31<42:46,  8.39s/it]Model Responding:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 570/875 [1:21:39<43:04,  8.47s/it]Model Responding:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 571/875 [1:21:47<42:14,  8.34s/it]Model Responding:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 572/875 [1:21:56<42:37,  8.44s/it]Model Responding:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 573/875 [1:22:04<42:11,  8.38s/it]Model Responding:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 574/875 [1:22:13<42:29,  8.47s/it]Model Responding:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 575/875 [1:22:22<42:35,  8.52s/it]Model Responding:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 576/875 [1:22:30<42:13,  8.47s/it]Model Responding:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 577/875 [1:22:38<41:37,  8.38s/it]Model Responding:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 578/875 [1:22:47<42:13,  8.53s/it]Model Responding:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 579/875 [1:22:56<42:23,  8.59s/it]Model Responding:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 580/875 [1:23:04<42:01,  8.55s/it]Model Responding:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 581/875 [1:23:12<41:22,  8.45s/it]Model Responding:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 582/875 [1:23:21<41:58,  8.60s/it]Model Responding:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 583/875 [1:23:29<41:01,  8.43s/it]Model Responding:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 584/875 [1:23:38<40:57,  8.45s/it]Model Responding:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 585/875 [1:23:47<41:17,  8.54s/it]Model Responding:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 586/875 [1:23:55<40:27,  8.40s/it]Model Responding:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 587/875 [1:24:03<40:00,  8.33s/it]Model Responding:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 588/875 [1:24:12<40:35,  8.49s/it]Model Responding:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 589/875 [1:24:20<40:42,  8.54s/it]Model Responding:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 590/875 [1:24:29<40:17,  8.48s/it]Model Responding:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 591/875 [1:24:37<40:03,  8.46s/it]Model Responding:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 592/875 [1:24:46<40:16,  8.54s/it]Model Responding:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 593/875 [1:24:55<40:15,  8.57s/it]Model Responding:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 594/875 [1:25:03<39:27,  8.43s/it]Model Responding:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 595/875 [1:25:11<38:56,  8.35s/it]Model Responding:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 596/875 [1:25:19<38:38,  8.31s/it]Model Responding:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 597/875 [1:25:28<39:02,  8.43s/it]Model Responding:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 598/875 [1:25:36<39:10,  8.49s/it]Model Responding:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 599/875 [1:25:45<39:37,  8.61s/it]Model Responding:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 600/875 [1:25:53<38:48,  8.47s/it]Model Responding:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 601/875 [1:26:02<38:46,  8.49s/it]Model Responding:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 602/875 [1:26:11<38:45,  8.52s/it]Model Responding:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 603/875 [1:26:19<38:36,  8.52s/it]Model Responding:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 604/875 [1:26:28<39:29,  8.74s/it]Model Responding:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 605/875 [1:26:37<39:33,  8.79s/it]Model Responding:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 606/875 [1:26:45<38:34,  8.60s/it]Model Responding:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 607/875 [1:26:54<38:04,  8.53s/it]Model Responding:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 608/875 [1:27:03<38:22,  8.63s/it]Model Responding:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 609/875 [1:27:11<38:12,  8.62s/it]Model Responding:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 610/875 [1:27:21<39:07,  8.86s/it]Model Responding:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 611/875 [1:27:30<39:02,  8.87s/it]Model Responding:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 612/875 [1:27:39<39:26,  9.00s/it]Model Responding:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 613/875 [1:27:47<38:34,  8.83s/it]Model Responding:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 614/875 [1:27:56<38:16,  8.80s/it]Model Responding:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 615/875 [1:28:05<38:35,  8.91s/it]Model Responding:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 616/875 [1:28:15<39:04,  9.05s/it]Model Responding:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 617/875 [1:28:24<39:02,  9.08s/it]Model Responding:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 618/875 [1:28:32<37:52,  8.84s/it]Model Responding:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 619/875 [1:28:41<37:20,  8.75s/it]Model Responding:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 620/875 [1:28:50<37:33,  8.84s/it]Model Responding:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 621/875 [1:28:58<36:49,  8.70s/it]Model Responding:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 622/875 [1:29:07<37:17,  8.85s/it]Model Responding:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 623/875 [1:29:17<38:04,  9.06s/it]Model Responding:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 624/875 [1:29:26<38:12,  9.13s/it]Model Responding:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 625/875 [1:29:35<37:17,  8.95s/it]Model Responding:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 626/875 [1:29:43<36:57,  8.91s/it]Model Responding:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 627/875 [1:29:51<35:50,  8.67s/it]Model Responding:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 628/875 [1:30:00<35:46,  8.69s/it]Model Responding:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 629/875 [1:30:09<35:31,  8.67s/it]Model Responding:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 630/875 [1:30:17<35:05,  8.60s/it]Model Responding:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 631/875 [1:30:26<34:54,  8.58s/it]Model Responding:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 632/875 [1:30:34<34:08,  8.43s/it]Model Responding:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 633/875 [1:30:42<33:49,  8.39s/it]Model Responding:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 634/875 [1:30:51<33:54,  8.44s/it]Model Responding:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 635/875 [1:30:59<33:09,  8.29s/it]Model Responding:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 636/875 [1:31:07<32:48,  8.24s/it]Model Responding:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 637/875 [1:31:16<33:16,  8.39s/it]Model Responding:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 638/875 [1:31:24<33:45,  8.55s/it]Model Responding:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 639/875 [1:31:33<33:33,  8.53s/it]Model Responding:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 640/875 [1:31:42<33:38,  8.59s/it]Model Responding:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 641/875 [1:31:50<33:29,  8.59s/it]Model Responding:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 642/875 [1:31:59<33:28,  8.62s/it]Model Responding:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 643/875 [1:32:07<32:29,  8.40s/it]Model Responding:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 644/875 [1:32:15<32:15,  8.38s/it]Model Responding:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 645/875 [1:32:24<32:52,  8.58s/it]Model Responding:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 646/875 [1:32:33<32:28,  8.51s/it]Model Responding:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 647/875 [1:32:41<32:30,  8.55s/it]Model Responding:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 648/875 [1:32:50<32:22,  8.56s/it]Model Responding:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 649/875 [1:32:58<31:49,  8.45s/it]Model Responding:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 650/875 [1:33:06<30:52,  8.23s/it]Model Responding:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 651/875 [1:33:14<31:00,  8.31s/it]Model Responding:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 652/875 [1:33:23<31:33,  8.49s/it]Model Responding:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 653/875 [1:33:31<30:46,  8.32s/it]Model Responding:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 654/875 [1:33:39<30:44,  8.35s/it]Model Responding:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 655/875 [1:33:47<30:16,  8.26s/it]Model Responding:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 656/875 [1:33:56<30:44,  8.42s/it]Model Responding:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 657/875 [1:34:04<30:05,  8.28s/it]Model Responding:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 658/875 [1:34:12<29:55,  8.27s/it]Model Responding:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 659/875 [1:34:22<30:39,  8.52s/it]Model Responding:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 660/875 [1:34:30<30:33,  8.53s/it]Model Responding:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 661/875 [1:34:39<30:24,  8.52s/it]Model Responding:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 662/875 [1:34:47<30:08,  8.49s/it]Model Responding:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 663/875 [1:34:56<30:14,  8.56s/it]Model Responding:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 664/875 [1:35:04<29:57,  8.52s/it]Model Responding:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 665/875 [1:35:12<29:24,  8.40s/it]Model Responding:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 666/875 [1:35:20<29:00,  8.33s/it]Model Responding:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 667/875 [1:35:30<29:58,  8.65s/it]Model Responding:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 668/875 [1:35:39<30:03,  8.71s/it]Model Responding:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 669/875 [1:35:47<29:24,  8.56s/it]Model Responding:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 670/875 [1:35:56<29:59,  8.78s/it]Model Responding:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 671/875 [1:36:05<29:29,  8.68s/it]Model Responding:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 672/875 [1:36:14<29:58,  8.86s/it]Model Responding:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 673/875 [1:36:23<29:42,  8.82s/it]Model Responding:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 674/875 [1:36:31<29:27,  8.79s/it]Model Responding:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 675/875 [1:36:40<28:56,  8.68s/it]Model Responding:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 676/875 [1:36:49<28:50,  8.70s/it]Model Responding:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 677/875 [1:36:57<28:22,  8.60s/it]Model Responding:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 678/875 [1:37:05<27:58,  8.52s/it]Model Responding:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 679/875 [1:37:14<27:51,  8.53s/it]Model Responding:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 680/875 [1:37:22<27:29,  8.46s/it]Model Responding:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 681/875 [1:37:30<27:10,  8.40s/it]Model Responding:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 682/875 [1:37:38<26:45,  8.32s/it]Model Responding:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 683/875 [1:37:48<27:33,  8.61s/it]Model Responding:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 684/875 [1:37:57<28:18,  8.89s/it]Model Responding:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 685/875 [1:38:06<28:10,  8.90s/it]Model Responding:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 686/875 [1:38:14<27:13,  8.64s/it]Model Responding:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 687/875 [1:38:24<28:04,  8.96s/it]Model Responding:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 688/875 [1:38:33<28:02,  9.00s/it]Model Responding:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 689/875 [1:38:42<27:23,  8.83s/it]Model Responding:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 690/875 [1:38:50<26:56,  8.74s/it]Model Responding:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 691/875 [1:38:59<26:52,  8.77s/it]Model Responding:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 692/875 [1:39:08<27:00,  8.86s/it]Model Responding:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 693/875 [1:39:16<26:28,  8.73s/it]Model Responding:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 694/875 [1:39:26<26:56,  8.93s/it]Model Responding:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 695/875 [1:39:35<26:36,  8.87s/it]Model Responding:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 696/875 [1:39:43<26:05,  8.75s/it]Model Responding:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 697/875 [1:39:51<25:38,  8.64s/it]Model Responding:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 698/875 [1:40:00<25:23,  8.61s/it]Model Responding:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 699/875 [1:40:08<24:46,  8.44s/it]Model Responding:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 700/875 [1:40:16<23:53,  8.19s/it]Model Responding:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 701/875 [1:40:24<24:21,  8.40s/it]Model Responding:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 702/875 [1:40:33<24:27,  8.48s/it]Model Responding:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 703/875 [1:40:42<24:34,  8.57s/it]Model Responding:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 704/875 [1:40:51<24:36,  8.64s/it]Model Responding:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 705/875 [1:40:59<24:22,  8.60s/it]Model Responding:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 706/875 [1:41:08<24:07,  8.57s/it]Model Responding:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 707/875 [1:41:15<23:18,  8.32s/it]Model Responding:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 708/875 [1:41:24<23:14,  8.35s/it]Model Responding:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 709/875 [1:41:33<23:26,  8.47s/it]Model Responding:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 710/875 [1:41:40<22:35,  8.21s/it]Model Responding:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 711/875 [1:41:48<22:21,  8.18s/it]Model Responding:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 712/875 [1:41:57<22:35,  8.32s/it]Model Responding:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 713/875 [1:42:06<23:00,  8.52s/it]Model Responding:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 714/875 [1:42:14<22:32,  8.40s/it]Model Responding:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 715/875 [1:42:23<22:52,  8.58s/it]Model Responding:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 716/875 [1:42:32<22:47,  8.60s/it]Model Responding:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 717/875 [1:42:41<22:50,  8.67s/it]Model Responding:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 718/875 [1:42:49<22:46,  8.70s/it]Model Responding:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 719/875 [1:42:58<22:34,  8.68s/it]Model Responding:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 720/875 [1:43:07<22:19,  8.64s/it]Model Responding:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 721/875 [1:43:15<21:51,  8.52s/it]Model Responding:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 722/875 [1:43:23<21:41,  8.51s/it]Model Responding:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 723/875 [1:43:32<21:40,  8.56s/it]Model Responding:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 724/875 [1:43:40<20:52,  8.29s/it]Model Responding:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 725/875 [1:43:48<20:28,  8.19s/it]Model Responding:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 726/875 [1:43:56<20:45,  8.36s/it]Model Responding:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 727/875 [1:44:05<20:49,  8.44s/it]Model Responding:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 728/875 [1:44:13<20:27,  8.35s/it]Model Responding:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 729/875 [1:44:23<21:13,  8.72s/it]Model Responding:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 730/875 [1:44:31<20:55,  8.66s/it]Model Responding:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 731/875 [1:44:40<20:40,  8.61s/it]Model Responding:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 732/875 [1:44:48<20:11,  8.47s/it]Model Responding:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 733/875 [1:44:56<19:43,  8.33s/it]Model Responding:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 734/875 [1:45:05<20:04,  8.54s/it]Model Responding:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 735/875 [1:45:14<20:02,  8.59s/it]Model Responding:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 736/875 [1:45:22<19:43,  8.51s/it]Model Responding:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 737/875 [1:45:30<19:22,  8.42s/it]Model Responding:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 738/875 [1:45:38<19:02,  8.34s/it]Model Responding:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 739/875 [1:45:46<18:43,  8.26s/it]Model Responding:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 740/875 [1:45:55<18:40,  8.30s/it]Model Responding:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 741/875 [1:46:04<18:54,  8.47s/it]Model Responding:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 742/875 [1:46:12<18:55,  8.53s/it]Model Responding:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 743/875 [1:46:21<18:42,  8.51s/it]Model Responding:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 744/875 [1:46:29<18:39,  8.55s/it]Model Responding:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 745/875 [1:46:37<18:12,  8.41s/it]Model Responding:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 746/875 [1:46:46<17:53,  8.33s/it]Model Responding:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 747/875 [1:46:54<17:40,  8.29s/it]Model Responding:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 748/875 [1:47:02<17:42,  8.36s/it]Model Responding:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 749/875 [1:47:11<17:41,  8.42s/it]Model Responding:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 750/875 [1:47:19<17:34,  8.43s/it]Model Responding:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 751/875 [1:47:28<17:40,  8.55s/it]Model Responding:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 752/875 [1:47:36<17:18,  8.45s/it]Model Responding:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 753/875 [1:47:45<17:17,  8.51s/it]Model Responding:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 754/875 [1:47:53<16:59,  8.42s/it]Model Responding:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 755/875 [1:48:02<16:53,  8.45s/it]Model Responding:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 756/875 [1:48:10<16:47,  8.47s/it]Model Responding:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 757/875 [1:48:18<16:19,  8.30s/it]Model Responding:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 758/875 [1:48:27<16:24,  8.41s/it]Model Responding:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 759/875 [1:48:35<16:12,  8.38s/it]Model Responding:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 760/875 [1:48:43<15:59,  8.35s/it]Model Responding:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 761/875 [1:48:52<15:54,  8.37s/it]Model Responding:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 762/875 [1:49:00<15:53,  8.44s/it]Model Responding:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 763/875 [1:49:09<15:43,  8.43s/it]Model Responding:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 764/875 [1:49:17<15:32,  8.40s/it]Model Responding:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 765/875 [1:49:26<15:52,  8.66s/it]Model Responding:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 766/875 [1:49:34<15:17,  8.42s/it]Model Responding:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 767/875 [1:49:43<15:18,  8.51s/it]Model Responding:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 768/875 [1:49:51<15:03,  8.44s/it]Model Responding:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 769/875 [1:50:00<14:51,  8.41s/it]Model Responding:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 770/875 [1:50:08<14:44,  8.43s/it]Model Responding:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 771/875 [1:50:16<14:35,  8.42s/it]Model Responding:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 772/875 [1:50:25<14:18,  8.34s/it]Model Responding:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 773/875 [1:50:33<14:01,  8.25s/it]Model Responding:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 774/875 [1:50:41<13:56,  8.28s/it]Model Responding:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 775/875 [1:50:49<13:51,  8.32s/it]Model Responding:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 776/875 [1:50:58<13:54,  8.43s/it]Model Responding:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 777/875 [1:51:07<13:47,  8.45s/it]Model Responding:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 778/875 [1:51:15<13:43,  8.49s/it]Model Responding:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 779/875 [1:51:25<14:04,  8.80s/it]Model Responding:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 780/875 [1:51:33<13:37,  8.61s/it]Model Responding:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 781/875 [1:51:41<13:20,  8.51s/it]Model Responding:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 782/875 [1:51:50<13:11,  8.51s/it]Model Responding:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 783/875 [1:51:58<12:49,  8.36s/it]Model Responding:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 784/875 [1:52:06<12:46,  8.42s/it]Model Responding:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 785/875 [1:52:15<12:41,  8.46s/it]Model Responding:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 786/875 [1:52:24<12:41,  8.56s/it]Model Responding:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 787/875 [1:52:32<12:37,  8.60s/it]Model Responding:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 788/875 [1:52:41<12:23,  8.54s/it]Model Responding:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 789/875 [1:52:50<12:22,  8.64s/it]Model Responding:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 790/875 [1:52:57<11:56,  8.42s/it]Model Responding:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 791/875 [1:53:06<11:54,  8.51s/it]Model Responding:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 792/875 [1:53:14<11:35,  8.38s/it]Model Responding:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 793/875 [1:53:23<11:34,  8.47s/it]Model Responding:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 794/875 [1:53:32<11:33,  8.56s/it]Model Responding:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 795/875 [1:53:40<11:20,  8.50s/it]Model Responding:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 796/875 [1:53:48<10:59,  8.35s/it]Model Responding:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 797/875 [1:53:56<10:45,  8.28s/it]Model Responding:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 798/875 [1:54:05<10:45,  8.38s/it]Model Responding:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 799/875 [1:54:13<10:43,  8.46s/it]Model Responding:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 800/875 [1:54:22<10:39,  8.52s/it]Model Responding:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 801/875 [1:54:31<10:41,  8.67s/it]Model Responding:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 802/875 [1:54:40<10:28,  8.60s/it]Model Responding:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 803/875 [1:54:48<10:18,  8.59s/it]Model Responding:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 804/875 [1:54:57<10:05,  8.53s/it]Model Responding:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 805/875 [1:55:05<09:58,  8.55s/it]Model Responding:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 806/875 [1:55:14<09:52,  8.59s/it]Model Responding:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 807/875 [1:55:23<09:46,  8.62s/it]Model Responding:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 808/875 [1:55:31<09:33,  8.56s/it]Model Responding:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 809/875 [1:55:39<09:20,  8.49s/it]Model Responding:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 810/875 [1:55:47<09:06,  8.41s/it]Model Responding:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 811/875 [1:55:56<09:03,  8.50s/it]Model Responding:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 812/875 [1:56:05<08:55,  8.50s/it]Model Responding:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 813/875 [1:56:14<08:55,  8.64s/it]Model Responding:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 814/875 [1:56:22<08:48,  8.66s/it]Model Responding:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 815/875 [1:56:31<08:42,  8.70s/it]Model Responding:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 816/875 [1:56:40<08:38,  8.79s/it]Model Responding:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 817/875 [1:56:49<08:26,  8.74s/it]Model Responding:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 818/875 [1:56:57<08:09,  8.59s/it]Model Responding:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 819/875 [1:57:06<08:08,  8.73s/it]Model Responding:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 820/875 [1:57:15<07:58,  8.70s/it]Model Responding:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 821/875 [1:57:23<07:48,  8.67s/it]Model Responding:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 822/875 [1:57:32<07:34,  8.58s/it]Model Responding:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 823/875 [1:57:40<07:28,  8.63s/it]Model Responding:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 824/875 [1:57:48<07:07,  8.39s/it]Model Responding:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 825/875 [1:57:57<07:05,  8.51s/it]Model Responding:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 826/875 [1:58:05<06:50,  8.37s/it]Model Responding:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 827/875 [1:58:14<06:46,  8.47s/it]Model Responding:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 828/875 [1:58:22<06:35,  8.42s/it]Model Responding:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 829/875 [1:58:31<06:40,  8.71s/it]Model Responding:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 830/875 [1:58:40<06:35,  8.80s/it]Model Responding:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 831/875 [1:58:49<06:17,  8.58s/it]Model Responding:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 832/875 [1:58:57<06:07,  8.54s/it]Model Responding:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 833/875 [1:59:06<06:00,  8.57s/it]Model Responding:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 834/875 [1:59:13<05:37,  8.24s/it]Model Responding:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 835/875 [1:59:22<05:37,  8.44s/it]Model Responding:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 836/875 [1:59:31<05:33,  8.55s/it]Model Responding:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 837/875 [1:59:40<05:30,  8.69s/it]Model Responding:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 838/875 [1:59:50<05:34,  9.03s/it]Model Responding:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 839/875 [1:59:58<05:21,  8.93s/it]Model Responding:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 840/875 [2:00:07<05:08,  8.81s/it]Model Responding:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 841/875 [2:00:15<04:55,  8.70s/it]Model Responding:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 842/875 [2:00:24<04:44,  8.64s/it]Model Responding:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 843/875 [2:00:32<04:36,  8.64s/it]Model Responding:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 844/875 [2:00:41<04:26,  8.61s/it]Model Responding:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 845/875 [2:00:50<04:18,  8.62s/it]Model Responding:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 846/875 [2:00:58<04:06,  8.51s/it]Model Responding:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 847/875 [2:01:06<03:54,  8.38s/it]Model Responding:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 848/875 [2:01:14<03:44,  8.33s/it]Model Responding:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 849/875 [2:01:23<03:37,  8.37s/it]Model Responding:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 850/875 [2:01:31<03:32,  8.50s/it]Model Responding:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 851/875 [2:01:40<03:22,  8.43s/it]Model Responding:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 852/875 [2:01:49<03:16,  8.54s/it]Model Responding:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 853/875 [2:01:56<03:03,  8.36s/it]Model Responding:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 854/875 [2:02:05<02:58,  8.50s/it]Model Responding:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 855/875 [2:02:14<02:50,  8.51s/it]Model Responding:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 856/875 [2:02:22<02:38,  8.33s/it]Model Responding:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 857/875 [2:02:29<02:25,  8.10s/it]Model Responding:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 858/875 [2:02:38<02:20,  8.26s/it]Model Responding:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 859/875 [2:02:46<02:12,  8.27s/it]Model Responding:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 860/875 [2:02:54<02:03,  8.21s/it]Model Responding:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 861/875 [2:03:03<01:57,  8.41s/it]Model Responding:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 862/875 [2:03:11<01:48,  8.33s/it]Model Responding:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 863/875 [2:03:19<01:39,  8.29s/it]Model Responding:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 864/875 [2:03:28<01:31,  8.32s/it]Model Responding:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 865/875 [2:03:36<01:23,  8.35s/it]Model Responding:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 866/875 [2:03:45<01:15,  8.42s/it]Model Responding:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 867/875 [2:03:53<01:07,  8.44s/it]Model Responding:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 868/875 [2:04:01<00:57,  8.22s/it]Model Responding:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 869/875 [2:04:10<00:49,  8.33s/it]Model Responding:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 870/875 [2:04:18<00:41,  8.34s/it]Model Responding: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 871/875 [2:04:27<00:34,  8.58s/it]Model Responding: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 872/875 [2:04:36<00:26,  8.68s/it]Model Responding: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 873/875 [2:04:45<00:17,  8.70s/it]Model Responding: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 874/875 [2:04:53<00:08,  8.51s/it]Model Responding: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 875/875 [2:05:01<00:00,  8.31s/it]Model Responding: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 875/875 [2:05:01<00:00,  8.57s/it]
Postprocessing:   0%|          | 0/125 [00:00<?, ?it/s]Postprocessing:   8%|‚ñä         | 10/125 [00:00<00:01, 97.97it/s]Postprocessing:  16%|‚ñà‚ñå        | 20/125 [00:00<00:01, 98.85it/s]Postprocessing:  25%|‚ñà‚ñà‚ñç       | 31/125 [00:00<00:00, 101.43it/s]Postprocessing:  34%|‚ñà‚ñà‚ñà‚ñç      | 43/125 [00:00<00:00, 105.09it/s]Postprocessing:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 54/125 [00:00<00:00, 100.38it/s]Postprocessing:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 65/125 [00:00<00:00, 99.50it/s] Postprocessing:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 76/125 [00:00<00:00, 102.32it/s]Postprocessing:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 87/125 [00:00<00:00, 104.14it/s]Postprocessing:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 98/125 [00:00<00:00, 105.49it/s]Postprocessing:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 109/125 [00:01<00:00, 105.72it/s]Postprocessing:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 120/125 [00:01<00:00, 102.72it/s]Postprocessing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [00:01<00:00, 102.28it/s]
Postprocessing:   0%|          | 0/750 [00:00<?, ?it/s]Postprocessing:   2%|‚ñè         | 13/750 [00:00<00:05, 129.24it/s]Postprocessing:   3%|‚ñé         | 26/750 [00:00<00:06, 117.14it/s]Postprocessing:   5%|‚ñå         | 38/750 [00:00<00:06, 116.59it/s]Postprocessing:   7%|‚ñã         | 51/750 [00:00<00:05, 118.98it/s]Postprocessing:   9%|‚ñä         | 64/750 [00:00<00:05, 119.96it/s]Postprocessing:  10%|‚ñà         | 77/750 [00:00<00:05, 115.37it/s]Postprocessing:  12%|‚ñà‚ñè        | 89/750 [00:00<00:06, 102.27it/s]Postprocessing:  13%|‚ñà‚ñé        | 100/750 [00:00<00:06, 99.96it/s]Postprocessing:  15%|‚ñà‚ñå        | 114/750 [00:01<00:05, 108.31it/s]Postprocessing:  17%|‚ñà‚ñã        | 126/750 [00:01<00:06, 103.60it/s]Postprocessing:  18%|‚ñà‚ñä        | 137/750 [00:01<00:05, 103.34it/s]Postprocessing:  20%|‚ñà‚ñà        | 150/750 [00:01<00:05, 108.68it/s]Postprocessing:  22%|‚ñà‚ñà‚ñè       | 162/750 [00:01<00:05, 109.09it/s]Postprocessing:  23%|‚ñà‚ñà‚ñé       | 173/750 [00:01<00:05, 103.86it/s]Postprocessing:  25%|‚ñà‚ñà‚ñç       | 184/750 [00:01<00:05, 103.18it/s]Postprocessing:  26%|‚ñà‚ñà‚ñå       | 196/750 [00:01<00:05, 105.45it/s]Postprocessing:  28%|‚ñà‚ñà‚ñä       | 207/750 [00:01<00:05, 105.77it/s]Postprocessing:  29%|‚ñà‚ñà‚ñâ       | 218/750 [00:02<00:05, 105.19it/s]Postprocessing:  31%|‚ñà‚ñà‚ñà       | 231/750 [00:02<00:04, 111.46it/s]Postprocessing:  32%|‚ñà‚ñà‚ñà‚ñè      | 243/750 [00:02<00:04, 109.53it/s]Postprocessing:  34%|‚ñà‚ñà‚ñà‚ñç      | 255/750 [00:02<00:04, 111.16it/s]Postprocessing:  36%|‚ñà‚ñà‚ñà‚ñå      | 267/750 [00:02<00:04, 112.38it/s]Postprocessing:  37%|‚ñà‚ñà‚ñà‚ñã      | 279/750 [00:02<00:04, 105.43it/s]Postprocessing:  39%|‚ñà‚ñà‚ñà‚ñä      | 290/750 [00:02<00:04, 102.32it/s]Postprocessing:  40%|‚ñà‚ñà‚ñà‚ñà      | 301/750 [00:02<00:04, 101.36it/s]Postprocessing:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 314/750 [00:02<00:04, 108.97it/s]Postprocessing:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 325/750 [00:03<00:04, 99.98it/s] Postprocessing:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 336/750 [00:03<00:04, 101.12it/s]Postprocessing:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 347/750 [00:03<00:04, 98.90it/s] Postprocessing:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 357/750 [00:03<00:04, 97.23it/s]Postprocessing:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 367/750 [00:03<00:03, 97.54it/s]Postprocessing:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 378/750 [00:03<00:03, 99.85it/s]Postprocessing:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 389/750 [00:03<00:03, 100.69it/s]Postprocessing:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 400/750 [00:03<00:03, 102.49it/s]Postprocessing:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 411/750 [00:03<00:03, 101.24it/s]Postprocessing:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 423/750 [00:03<00:03, 105.70it/s]Postprocessing:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 435/750 [00:04<00:02, 107.94it/s]Postprocessing:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 447/750 [00:04<00:02, 111.36it/s]Postprocessing:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 459/750 [00:04<00:02, 105.91it/s]Postprocessing:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 471/750 [00:04<00:02, 108.45it/s]Postprocessing:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 482/750 [00:04<00:02, 105.82it/s]Postprocessing:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 494/750 [00:04<00:02, 108.93it/s]Postprocessing:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 505/750 [00:04<00:02, 109.17it/s]Postprocessing:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 516/750 [00:04<00:02, 107.06it/s]Postprocessing:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 527/750 [00:04<00:02, 102.50it/s]Postprocessing:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 540/750 [00:05<00:01, 107.77it/s]Postprocessing:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 552/750 [00:05<00:01, 110.44it/s]Postprocessing:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 565/750 [00:05<00:01, 114.46it/s]Postprocessing:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 577/750 [00:05<00:01, 110.87it/s]Postprocessing:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 590/750 [00:05<00:01, 114.18it/s]Postprocessing:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 602/750 [00:05<00:01, 113.49it/s]Postprocessing:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 614/750 [00:05<00:01, 112.35it/s]Postprocessing:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 626/750 [00:05<00:01, 106.02it/s]Postprocessing:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 638/750 [00:05<00:01, 108.04it/s]Postprocessing:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 651/750 [00:06<00:00, 111.52it/s]Postprocessing:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 663/750 [00:06<00:00, 108.34it/s]Postprocessing:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 676/750 [00:06<00:00, 112.13it/s]Postprocessing:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 688/750 [00:06<00:00, 109.65it/s]Postprocessing:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 700/750 [00:06<00:00, 106.07it/s]Postprocessing:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 711/750 [00:06<00:00, 101.61it/s]Postprocessing:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 722/750 [00:06<00:00, 98.47it/s] Postprocessing:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 733/750 [00:06<00:00, 99.86it/s]Postprocessing:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 744/750 [00:07<00:00, 97.70it/s]Postprocessing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 750/750 [00:07<00:00, 106.20it/s]
[32m2024-12-14 22:43:48.610[0m | [1mINFO    [0m | [36mlmms_eval.loggers.evaluation_tracker[0m:[36msave_results_aggregated[0m:[36m188[0m - [1mSaving results aggregated[0m
[32m2024-12-14 22:43:48.615[0m | [1mINFO    [0m | [36mlmms_eval.loggers.evaluation_tracker[0m:[36msave_results_samples[0m:[36m255[0m - [1mSaving per-sample results for: pope_pop[0m
[32m2024-12-14 22:43:51.657[0m | [1mINFO    [0m | [36mlmms_eval.loggers.evaluation_tracker[0m:[36msave_results_samples[0m:[36m255[0m - [1mSaving per-sample results for: vqav2_val_lite[0m
llava (pretrained=liuhaotian/llava-v1.6-vicuna-7b), gen_kwargs: (), limit: None, num_fewshot: None, batch_size: 1
|    Tasks     |Version|Filter|n-shot|    Metric    |   |Value |   |Stderr|
|--------------|-------|------|-----:|--------------|---|-----:|---|------|
|pope_pop      |Yaml   |none  |     0|pope_accuracy |‚Üë  |0.8777|¬±  |   N/A|
|pope_pop      |Yaml   |none  |     0|pope_f1_score |‚Üë  |0.8654|¬±  |   N/A|
|pope_pop      |Yaml   |none  |     0|pope_precision|‚Üë  |0.9617|¬±  |   N/A|
|pope_pop      |Yaml   |none  |     0|pope_recall   |‚Üë  |0.7867|¬±  |   N/A|
|pope_pop      |Yaml   |none  |     0|pope_yes_ratio|‚Üë  |0.5000|¬±  |   N/A|
|vqav2_val_lite|Yaml   |none  |     0|exact_match   |‚Üë  |0.7520|¬±  |0.0178|

wandb: - 0.025 MB of 0.025 MB uploadedwandb: - 0.025 MB of 0.025 MB uploadedwandb: - 0.025 MB of 0.025 MB uploadedwandb: \ 0.025 MB of 0.025 MB uploadedwandb: \ 0.025 MB of 0.030 MB uploadedwandb: \ 0.025 MB of 0.025 MB uploadedwandb: | 0.025 MB of 0.025 MB uploadedwandb: | 0.025 MB of 0.030 MB uploadedwandb: / 0.038 MB of 0.038 MB uploadedwandb:                                                                                
wandb: | 0.025 MB of 0.038 MB uploadedwandb: / 0.025 MB of 0.038 MB uploadedwandb: / 0.025 MB of 0.038 MB uploadedwandb: - 0.038 MB of 0.038 MB uploadedwandb:                                                                                
wandb: - 0.025 MB of 0.038 MB uploadedwandb: \ 0.038 MB of 0.038 MB uploadedwandb:                                                                                
wandb: üöÄ View run reverse3 at: https://wandb.ai/VLM_Hallucination_Woohyeon/llava1.6_recursive_eval_1126/runs/umyoqxuk/workspace
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241214_201942-umyoqxuk/logs
wandb: - 0.032 MB of 0.032 MB uploadedwandb: üöÄ View run reverse3 at: https://wandb.ai/VLM_Hallucination_Woohyeon/llava1.6_recursive_eval_1126/runs/k3p3dzhk/workspace
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241214_201942-k3p3dzhk/logs
wandb: üöÄ View run reverse3 at: https://wandb.ai/VLM_Hallucination_Woohyeon/llava1.6_recursive_eval_1126/runs/mlqvfpvl/workspace
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241214_201942-mlqvfpvl/logs
wandb: \ 0.032 MB of 0.032 MB uploadedwandb: | 0.032 MB of 0.032 MB uploadedwandb: / 0.032 MB of 0.032 MB uploadedwandb: - 0.032 MB of 0.052 MB uploadedwandb: \ 0.032 MB of 0.052 MB uploadedwandb: | 0.052 MB of 0.052 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:            pope_pop/pope_accuracy ‚ñÅ
wandb:            pope_pop/pope_f1_score ‚ñÅ
wandb:           pope_pop/pope_precision ‚ñÅ
wandb:              pope_pop/pope_recall ‚ñÅ
wandb:           pope_pop/pope_yes_ratio ‚ñÅ
wandb:        vqav2_val_lite/exact_match ‚ñÅ
wandb: vqav2_val_lite/exact_match_stderr ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    pope_pop/alias pope_pop
wandb:            pope_pop/pope_accuracy 0.87767
wandb:     pope_pop/pope_accuracy_stderr N/A
wandb:            pope_pop/pope_f1_score 0.86542
wandb:     pope_pop/pope_f1_score_stderr N/A
wandb:           pope_pop/pope_precision 0.9617
wandb:    pope_pop/pope_precision_stderr N/A
wandb:              pope_pop/pope_recall 0.78667
wandb:       pope_pop/pope_recall_stderr N/A
wandb:           pope_pop/pope_yes_ratio 0.5
wandb:    pope_pop/pope_yes_ratio_stderr N/A
wandb:              vqav2_val_lite/alias vqav2_val_lite
wandb:        vqav2_val_lite/exact_match 0.752
wandb: vqav2_val_lite/exact_match_stderr 0.0178
wandb: 
wandb: üöÄ View run reverse3 at: https://wandb.ai/VLM_Hallucination_Woohyeon/llava1.6_recursive_eval_1126/runs/i9bidqan/workspace
wandb: Synced 6 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241214_201942-i9bidqan/logs
[rank0]:[W1214 22:44:06.043137712 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
The following values were not passed to `accelerate launch` and had defaults used instead:
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--num_machines` was set to a value of `1`
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
wandb: Currently logged in as: wjk9904 (VLM_Hallucination_Woohyeon). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: wjk9904 (VLM_Hallucination_Woohyeon). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: wjk9904 (VLM_Hallucination_Woohyeon). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: wjk9904 (VLM_Hallucination_Woohyeon). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.19.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.5
wandb: Run data is saved locally in /workspace/vlm/lmms-reverse/wandb/run-20241214_224416-wwrne0gc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run reverse4
wandb: ‚≠êÔ∏è View project at https://wandb.ai/VLM_Hallucination_Woohyeon/llava1.6_recursive_eval_1126
wandb: üöÄ View run at https://wandb.ai/VLM_Hallucination_Woohyeon/llava1.6_recursive_eval_1126/runs/wwrne0gc/workspace
wandb: wandb version 0.19.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.5
wandb: Run data is saved locally in /workspace/vlm/lmms-reverse/wandb/run-20241214_224416-hh2kqkg5
wandb: Run `wandb offline` to turn off syncing.
wandb: wandb version 0.19.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.5
wandb: Run data is saved locally in /workspace/vlm/lmms-reverse/wandb/run-20241214_224416-mo1yyvo3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run reverse4
wandb: ‚≠êÔ∏è View project at https://wandb.ai/VLM_Hallucination_Woohyeon/llava1.6_recursive_eval_1126
wandb: üöÄ View run at https://wandb.ai/VLM_Hallucination_Woohyeon/llava1.6_recursive_eval_1126/runs/hh2kqkg5/workspace
wandb: Syncing run reverse4
wandb: ‚≠êÔ∏è View project at https://wandb.ai/VLM_Hallucination_Woohyeon/llava1.6_recursive_eval_1126
wandb: üöÄ View run at https://wandb.ai/VLM_Hallucination_Woohyeon/llava1.6_recursive_eval_1126/runs/mo1yyvo3/workspace
wandb: wandb version 0.19.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.5
wandb: Run data is saved locally in /workspace/vlm/lmms-reverse/wandb/run-20241214_224416-0jkokywl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run reverse4
wandb: ‚≠êÔ∏è View project at https://wandb.ai/VLM_Hallucination_Woohyeon/llava1.6_recursive_eval_1126
wandb: üöÄ View run at https://wandb.ai/VLM_Hallucination_Woohyeon/llava1.6_recursive_eval_1126/runs/0jkokywl/workspace
[32m2024-12-14 22:44:19.174[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate[0m:[36m420[0m - [1mVerbosity set to DEBUG[0m
[32m2024-12-14 22:44:19.225[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate[0m:[36m420[0m - [1mVerbosity set to DEBUG[0m
[32m2024-12-14 22:44:19.226[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate[0m:[36m420[0m - [1mVerbosity set to DEBUG[0m
[32m2024-12-14 22:44:19.281[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate[0m:[36m420[0m - [1mVerbosity set to DEBUG[0m
[32m2024-12-14 22:44:25.379[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.tasks[0m:[36m_get_task_and_group[0m:[36m452[0m - [34m[1m`group` and `group_alias` keys in tasks' configs will no longer be used in the next release of lmms-eval. `tag` will be used to allow to call a collection of tasks just like `group`. `group` will be removed in order to not cause confusion with the new ConfigurableGroup which will be the offical way to create groups with addition of group-wide configuations.[0m
[32m2024-12-14 22:44:26.059[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.tasks[0m:[36m_get_task_and_group[0m:[36m452[0m - [34m[1m`group` and `group_alias` keys in tasks' configs will no longer be used in the next release of lmms-eval. `tag` will be used to allow to call a collection of tasks just like `group`. `group` will be removed in order to not cause confusion with the new ConfigurableGroup which will be the offical way to create groups with addition of group-wide configuations.[0m
[32m2024-12-14 22:44:26.132[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m503[0m - [1mEvaluation tracker args: {'output_path': './logs/'}[0m
[32m2024-12-14 22:44:26.133[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m592[0m - [1mSelected Tasks: ['pope_pop', 'vqav2_val_lite'][0m
[32m2024-12-14 22:44:26.137[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36msimple_evaluate[0m:[36m155[0m - [1mSetting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234[0m
[32m2024-12-14 22:44:26.221[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.tasks[0m:[36m_get_task_and_group[0m:[36m452[0m - [34m[1m`group` and `group_alias` keys in tasks' configs will no longer be used in the next release of lmms-eval. `tag` will be used to allow to call a collection of tasks just like `group`. `group` will be removed in order to not cause confusion with the new ConfigurableGroup which will be the offical way to create groups with addition of group-wide configuations.[0m
[32m2024-12-14 22:44:26.331[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.tasks[0m:[36m_get_task_and_group[0m:[36m452[0m - [34m[1m`group` and `group_alias` keys in tasks' configs will no longer be used in the next release of lmms-eval. `tag` will be used to allow to call a collection of tasks just like `group`. `group` will be removed in order to not cause confusion with the new ConfigurableGroup which will be the offical way to create groups with addition of group-wide configuations.[0m
[32m2024-12-14 22:44:26.804[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m503[0m - [1mEvaluation tracker args: {'output_path': './logs/'}[0m
[32m2024-12-14 22:44:26.805[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m592[0m - [1mSelected Tasks: ['pope_pop', 'vqav2_val_lite'][0m
[32m2024-12-14 22:44:26.807[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36msimple_evaluate[0m:[36m155[0m - [1mSetting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234[0m
[32m2024-12-14 22:44:26.992[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m503[0m - [1mEvaluation tracker args: {'output_path': './logs/'}[0m
[32m2024-12-14 22:44:26.993[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m592[0m - [1mSelected Tasks: ['pope_pop', 'vqav2_val_lite'][0m
[32m2024-12-14 22:44:26.996[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36msimple_evaluate[0m:[36m155[0m - [1mSetting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234[0m
[32m2024-12-14 22:44:27.111[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m503[0m - [1mEvaluation tracker args: {'output_path': './logs/'}[0m
[32m2024-12-14 22:44:27.113[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m592[0m - [1mSelected Tasks: ['pope_pop', 'vqav2_val_lite'][0m
[32m2024-12-14 22:44:27.116[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36msimple_evaluate[0m:[36m155[0m - [1mSetting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234[0m
initialize llava model with modification
initialize llava model with modification
initialize llava model with modification
initialize llava model with modification
OpenCLIP not installed
OpenCLIP not installed
OpenCLIP not installed
OpenCLIP not installed
self.merging= None
model_name: llava-v1.6-vicuna-7b
loding from here
self.merging= None
model_name: llava-v1.6-vicuna-7b
loding from here
self.merging= None
model_name: llava-v1.6-vicuna-7b
Rank 0:  Loaded LLaVA model: liuhaotian/llava-v1.6-vicuna-7b
loding from here
self.merging= None
model_name: llava-v1.6-vicuna-7b
loding from here
You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
Rank 0:  Loading vision tower: openai/clip-vit-large-patch14-336
You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:05<00:11,  5.65s/it]Loading checkpoint shards:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:05<00:11,  5.69s/it]Loading checkpoint shards:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:05<00:11,  5.91s/it]Loading checkpoint shards:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:06<00:12,  6.23s/it]Loading checkpoint shards:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:11<00:05,  5.67s/it]Loading checkpoint shards:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:11<00:05,  5.67s/it]Loading checkpoint shards:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:11<00:05,  5.86s/it]Loading checkpoint shards:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:11<00:05,  5.93s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:16<00:00,  5.48s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:16<00:00,  5.53s/it]
Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:16<00:00,  5.49s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:16<00:00,  5.54s/it]
device: cuda:0
generation_type: recursion
fix_grid: 2x2
attention_thresholding_type: layer_mean_topk
attention_norm: None
attention_threshold: [0.9,0.8,0.7]
detection_strategy: None
detection_threshold: 0.8
save_output: False
save_output_csv_path: generation_output.csv
target_token_selection_strategy: first
stages: [1, 0, -1, -2]
positional_embedding_type: bilinear_interpolation
visualize_heatmap: False
square: 1
remove unpadding=True, change to 'spatial'
change positional embedding to bilinear_interpolation
device: cuda:0
generation_type: recursion
fix_grid: 2x2
attention_thresholding_type: layer_mean_topk
attention_norm: None
attention_threshold: [0.9,0.8,0.7]
detection_strategy: None
detection_threshold: 0.8
save_output: False
save_output_csv_path: generation_output.csv
target_token_selection_strategy: first
stages: [1, 0, -1, -2]
positional_embedding_type: bilinear_interpolation
visualize_heatmap: False
square: 1
remove unpadding=True, change to 'spatial'
change positional embedding to bilinear_interpolation
Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:16<00:00,  5.45s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:16<00:00,  5.60s/it]
Bilienar interpolation embedding type.
Bilienar interpolation embedding type.
Rank 0:  Model Class: LlavaLlamaForCausalLM
device: cuda:0
generation_type: recursion
fix_grid: 2x2
attention_thresholding_type: layer_mean_topk
attention_norm: None
attention_threshold: [0.9,0.8,0.7]
detection_strategy: None
detection_threshold: 0.8
save_output: False
save_output_csv_path: generation_output.csv
target_token_selection_strategy: first
stages: [1, 0, -1, -2]
positional_embedding_type: bilinear_interpolation
visualize_heatmap: False
square: 1
remove unpadding=True, change to 'spatial'
change positional embedding to bilinear_interpolation
Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:17<00:00,  5.67s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:17<00:00,  5.74s/it]
device: cuda:0
generation_type: recursion
fix_grid: 2x2
attention_thresholding_type: layer_mean_topk
attention_norm: None
attention_threshold: [0.9,0.8,0.7]
detection_strategy: None
detection_threshold: 0.8
save_output: False
save_output_csv_path: generation_output.csv
target_token_selection_strategy: first
stages: [1, 0, -1, -2]
positional_embedding_type: bilinear_interpolation
visualize_heatmap: False
square: 1
remove unpadding=True, change to 'spatial'
change positional embedding to bilinear_interpolation
Bilienar interpolation embedding type.
Bilienar interpolation embedding type.
[32m2024-12-14 22:44:56.272[0m | [1mINFO    [0m | [36mlmms_eval.models.llava[0m:[36m__init__[0m:[36m306[0m - [1mUsing 4 devices with data parallelism[0m
[32m2024-12-14 22:44:56.272[0m | [1mINFO    [0m | [36mlmms_eval.evaluator_utils[0m:[36mfrom_taskdict[0m:[36m91[0m - [1mNo metadata found in task config for vqav2_val_lite, using default n_shot=0[0m
[32m2024-12-14 22:44:56.273[0m | [1mINFO    [0m | [36mlmms_eval.evaluator_utils[0m:[36mfrom_taskdict[0m:[36m91[0m - [1mNo metadata found in task config for pope_pop, using default n_shot=0[0m
[32m2024-12-14 22:44:56.273[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.caching.cache[0m:[36mload_from_cache[0m:[36m33[0m - [34m[1mrequests-vqav2_val_lite-0shot-rank0-world_size4-tokenizer is not cached, generating...[0m
[32m2024-12-14 22:44:56.273[0m | [1mINFO    [0m | [36mlmms_eval.api.task[0m:[36mbuild_all_requests[0m:[36m425[0m - [1mBuilding contexts for vqav2_val_lite on rank 0...[0m
Bilienar interpolation embedding type.
Bilienar interpolation embedding type.
Bilienar interpolation embedding type.
  0%|          | 0/125 [00:00<?, ?it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [00:00<00:00, 103287.63it/s]
[32m2024-12-14 22:44:57.490[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m455[0m - [34m[1mTask: vqav2_val_lite; number of requests on this rank: 125[0m
[32m2024-12-14 22:44:57.716[0m | [1mINFO    [0m | [36mlmms_eval.evaluator_utils[0m:[36mfrom_taskdict[0m:[36m91[0m - [1mNo metadata found in task config for vqav2_val_lite, using default n_shot=0[0m
[32m2024-12-14 22:44:57.717[0m | [1mINFO    [0m | [36mlmms_eval.evaluator_utils[0m:[36mfrom_taskdict[0m:[36m91[0m - [1mNo metadata found in task config for pope_pop, using default n_shot=0[0m
[32m2024-12-14 22:44:57.717[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.caching.cache[0m:[36mload_from_cache[0m:[36m33[0m - [34m[1mrequests-vqav2_val_lite-0shot-rank3-world_size4-tokenizer is not cached, generating...[0m
[32m2024-12-14 22:44:57.717[0m | [1mINFO    [0m | [36mlmms_eval.api.task[0m:[36mbuild_all_requests[0m:[36m425[0m - [1mBuilding contexts for vqav2_val_lite on rank 3...[0m
[32m2024-12-14 22:44:57.783[0m | [1mINFO    [0m | [36mlmms_eval.evaluator_utils[0m:[36mfrom_taskdict[0m:[36m91[0m - [1mNo metadata found in task config for vqav2_val_lite, using default n_shot=0[0m
[32m2024-12-14 22:44:57.784[0m | [1mINFO    [0m | [36mlmms_eval.evaluator_utils[0m:[36mfrom_taskdict[0m:[36m91[0m - [1mNo metadata found in task config for pope_pop, using default n_shot=0[0m
[32m2024-12-14 22:44:57.785[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.caching.cache[0m:[36mload_from_cache[0m:[36m33[0m - [34m[1mrequests-vqav2_val_lite-0shot-rank2-world_size4-tokenizer is not cached, generating...[0m
[32m2024-12-14 22:44:57.785[0m | [1mINFO    [0m | [36mlmms_eval.api.task[0m:[36mbuild_all_requests[0m:[36m425[0m - [1mBuilding contexts for vqav2_val_lite on rank 2...[0m
Bilienar interpolation embedding type.
  0%|          | 0/125 [00:00<?, ?it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [00:00<00:00, 111979.50it/s]
[32m2024-12-14 22:44:58.824[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m455[0m - [34m[1mTask: vqav2_val_lite; number of requests on this rank: 125[0m
  0%|          | 0/125 [00:00<?, ?it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [00:00<00:00, 106303.33it/s]
[32m2024-12-14 22:44:58.899[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m455[0m - [34m[1mTask: vqav2_val_lite; number of requests on this rank: 125[0m
[32m2024-12-14 22:44:59.384[0m | [1mINFO    [0m | [36mlmms_eval.evaluator_utils[0m:[36mfrom_taskdict[0m:[36m91[0m - [1mNo metadata found in task config for vqav2_val_lite, using default n_shot=0[0m
[32m2024-12-14 22:44:59.384[0m | [1mINFO    [0m | [36mlmms_eval.evaluator_utils[0m:[36mfrom_taskdict[0m:[36m91[0m - [1mNo metadata found in task config for pope_pop, using default n_shot=0[0m
[32m2024-12-14 22:44:59.384[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.caching.cache[0m:[36mload_from_cache[0m:[36m33[0m - [34m[1mrequests-vqav2_val_lite-0shot-rank1-world_size4-tokenizer is not cached, generating...[0m
[32m2024-12-14 22:44:59.384[0m | [1mINFO    [0m | [36mlmms_eval.api.task[0m:[36mbuild_all_requests[0m:[36m425[0m - [1mBuilding contexts for vqav2_val_lite on rank 1...[0m
  0%|          | 0/125 [00:00<?, ?it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [00:00<00:00, 106260.24it/s]
[32m2024-12-14 22:45:00.571[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m455[0m - [34m[1mTask: vqav2_val_lite; number of requests on this rank: 125[0m
[32m2024-12-14 22:45:08.363[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.caching.cache[0m:[36mload_from_cache[0m:[36m33[0m - [34m[1mrequests-pope_pop-0shot-rank0-world_size4-tokenizer is not cached, generating...[0m
[32m2024-12-14 22:45:08.363[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.caching.cache[0m:[36mload_from_cache[0m:[36m33[0m - [34m[1mrequests-pope_pop-0shot-rank3-world_size4-tokenizer is not cached, generating...[0m
[32m2024-12-14 22:45:08.363[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.caching.cache[0m:[36mload_from_cache[0m:[36m33[0m - [34m[1mrequests-pope_pop-0shot-rank2-world_size4-tokenizer is not cached, generating...[0m
[32m2024-12-14 22:45:08.364[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.caching.cache[0m:[36mload_from_cache[0m:[36m33[0m - [34m[1mrequests-pope_pop-0shot-rank1-world_size4-tokenizer is not cached, generating...[0m
[32m2024-12-14 22:45:08.364[0m | [1mINFO    [0m | [36mlmms_eval.api.task[0m:[36mbuild_all_requests[0m:[36m425[0m - [1mBuilding contexts for pope_pop on rank 3...[0m
[32m2024-12-14 22:45:08.364[0m | [1mINFO    [0m | [36mlmms_eval.api.task[0m:[36mbuild_all_requests[0m:[36m425[0m - [1mBuilding contexts for pope_pop on rank 0...[0m
[32m2024-12-14 22:45:08.364[0m | [1mINFO    [0m | [36mlmms_eval.api.task[0m:[36mbuild_all_requests[0m:[36m425[0m - [1mBuilding contexts for pope_pop on rank 2...[0m
[32m2024-12-14 22:45:08.365[0m | [1mINFO    [0m | [36mlmms_eval.api.task[0m:[36mbuild_all_requests[0m:[36m425[0m - [1mBuilding contexts for pope_pop on rank 1...[0m
  0%|          | 0/750 [00:00<?, ?it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 750/750 [00:00<00:00, 92589.49it/s]
[32m2024-12-14 22:45:15.372[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m455[0m - [34m[1mTask: pope_pop; number of requests on this rank: 750[0m
  0%|          | 0/750 [00:00<?, ?it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 750/750 [00:00<00:00, 107285.84it/s]
[32m2024-12-14 22:45:15.765[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m455[0m - [34m[1mTask: pope_pop; number of requests on this rank: 750[0m
  0%|          | 0/750 [00:00<?, ?it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 750/750 [00:00<00:00, 106084.65it/s]
[32m2024-12-14 22:45:15.796[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m455[0m - [34m[1mTask: pope_pop; number of requests on this rank: 750[0m
  0%|          | 0/750 [00:00<?, ?it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 750/750 [00:00<00:00, 93176.39it/s]
[32m2024-12-14 22:45:15.925[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m455[0m - [34m[1mTask: pope_pop; number of requests on this rank: 750[0m
[32m2024-12-14 22:45:15.926[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m476[0m - [1mRunning generate_until requests[0m
[32m2024-12-14 22:45:15.927[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m476[0m - [1mRunning generate_until requests[0m
[32m2024-12-14 22:45:15.927[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m476[0m - [1mRunning generate_until requests[0m
[32m2024-12-14 22:45:15.927[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m476[0m - [1mRunning generate_until requests[0m
Model Responding:   0%|          | 0/875 [00:00<?, ?it/s]CLIPModel is using CLIPSdpaAttention, but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation="eager"` when loading the model.
CLIPModel is using CLIPSdpaAttention, but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation="eager"` when loading the model.
CLIPModel is using CLIPSdpaAttention, but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation="eager"` when loading the model.
CLIPModel is using CLIPSdpaAttention, but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation="eager"` when loading the model.
LlamaModel is using LlamaSdpaAttention, but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation="eager"` when loading the model.
LlamaModel is using LlamaSdpaAttention, but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation="eager"` when loading the model.
LlamaModel is using LlamaSdpaAttention, but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation="eager"` when loading the model.
LlamaModel is using LlamaSdpaAttention, but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation="eager"` when loading the model.
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
Model Responding:   0%|          | 1/875 [00:10<2:27:52, 10.15s/it]Model Responding:   0%|          | 2/875 [00:19<2:22:50,  9.82s/it]Model Responding:   0%|          | 3/875 [00:28<2:14:41,  9.27s/it]Model Responding:   0%|          | 4/875 [00:37<2:12:39,  9.14s/it]Model Responding:   1%|          | 5/875 [00:46<2:12:20,  9.13s/it]Model Responding:   1%|          | 6/875 [00:54<2:08:53,  8.90s/it]Model Responding:   1%|          | 7/875 [01:03<2:06:35,  8.75s/it]Model Responding:   1%|          | 8/875 [01:11<2:03:37,  8.56s/it]Model Responding:   1%|          | 9/875 [01:20<2:07:35,  8.84s/it]Model Responding:   1%|          | 10/875 [01:30<2:08:53,  8.94s/it]Model Responding:   1%|‚ñè         | 11/875 [01:39<2:09:03,  8.96s/it]Model Responding:   1%|‚ñè         | 12/875 [01:48<2:12:22,  9.20s/it]Model Responding:   1%|‚ñè         | 13/875 [01:57<2:10:43,  9.10s/it]Model Responding:   2%|‚ñè         | 14/875 [02:06<2:09:47,  9.04s/it]Model Responding:   2%|‚ñè         | 15/875 [02:15<2:08:38,  8.98s/it]Model Responding:   2%|‚ñè         | 16/875 [02:24<2:08:07,  8.95s/it]Model Responding:   2%|‚ñè         | 17/875 [02:33<2:06:55,  8.88s/it]Model Responding:   2%|‚ñè         | 18/875 [02:42<2:09:48,  9.09s/it]Model Responding:   2%|‚ñè         | 19/875 [02:51<2:08:21,  9.00s/it]Model Responding:   2%|‚ñè         | 20/875 [03:00<2:09:35,  9.09s/it]Model Responding:   2%|‚ñè         | 21/875 [03:09<2:08:42,  9.04s/it]Model Responding:   3%|‚ñé         | 22/875 [03:18<2:07:36,  8.98s/it]Model Responding:   3%|‚ñé         | 23/875 [03:26<2:04:40,  8.78s/it]Model Responding:   3%|‚ñé         | 24/875 [03:35<2:03:38,  8.72s/it]Model Responding:   3%|‚ñé         | 25/875 [03:43<2:01:37,  8.59s/it]Model Responding:   3%|‚ñé         | 26/875 [03:52<2:01:01,  8.55s/it]Model Responding:   3%|‚ñé         | 27/875 [04:00<2:01:50,  8.62s/it]Model Responding:   3%|‚ñé         | 28/875 [04:10<2:04:05,  8.79s/it]Model Responding:   3%|‚ñé         | 29/875 [04:18<2:04:22,  8.82s/it]Model Responding:   3%|‚ñé         | 30/875 [04:28<2:06:06,  8.95s/it]Model Responding:   4%|‚ñé         | 31/875 [04:37<2:06:19,  8.98s/it]Model Responding:   4%|‚ñé         | 32/875 [04:45<2:03:27,  8.79s/it]Model Responding:   4%|‚ñç         | 33/875 [04:55<2:06:29,  9.01s/it]Model Responding:   4%|‚ñç         | 34/875 [05:05<2:11:58,  9.42s/it]Model Responding:   4%|‚ñç         | 35/875 [05:13<2:07:58,  9.14s/it]Model Responding:   4%|‚ñç         | 36/875 [05:22<2:04:53,  8.93s/it]Model Responding:   4%|‚ñç         | 37/875 [05:30<2:01:54,  8.73s/it]Model Responding:   4%|‚ñç         | 38/875 [05:39<2:03:46,  8.87s/it]Model Responding:   4%|‚ñç         | 39/875 [05:49<2:06:21,  9.07s/it]Model Responding:   5%|‚ñç         | 40/875 [05:58<2:05:35,  9.02s/it]Model Responding:   5%|‚ñç         | 41/875 [06:07<2:05:30,  9.03s/it]Model Responding:   5%|‚ñç         | 42/875 [06:16<2:03:49,  8.92s/it]Model Responding:   5%|‚ñç         | 43/875 [06:25<2:05:49,  9.07s/it]Model Responding:   5%|‚ñå         | 44/875 [06:34<2:06:49,  9.16s/it]Model Responding:   5%|‚ñå         | 45/875 [06:44<2:09:40,  9.37s/it]Model Responding:   5%|‚ñå         | 46/875 [06:54<2:09:34,  9.38s/it]Model Responding:   5%|‚ñå         | 47/875 [07:02<2:04:14,  9.00s/it]Model Responding:   5%|‚ñå         | 48/875 [07:10<2:01:22,  8.81s/it]Model Responding:   6%|‚ñå         | 49/875 [07:19<2:00:00,  8.72s/it]Model Responding:   6%|‚ñå         | 50/875 [07:28<2:01:12,  8.81s/it]Model Responding:   6%|‚ñå         | 51/875 [07:37<2:02:52,  8.95s/it]Model Responding:   6%|‚ñå         | 52/875 [07:47<2:06:03,  9.19s/it]Model Responding:   6%|‚ñå         | 53/875 [07:55<2:04:07,  9.06s/it]Model Responding:   6%|‚ñå         | 54/875 [08:05<2:05:58,  9.21s/it]Model Responding:   6%|‚ñã         | 55/875 [08:14<2:04:38,  9.12s/it]Model Responding:   6%|‚ñã         | 56/875 [08:23<2:03:38,  9.06s/it]Model Responding:   7%|‚ñã         | 57/875 [08:31<2:01:47,  8.93s/it]Model Responding:   7%|‚ñã         | 58/875 [08:41<2:03:02,  9.04s/it]Model Responding:   7%|‚ñã         | 59/875 [08:50<2:04:26,  9.15s/it]Model Responding:   7%|‚ñã         | 60/875 [08:59<2:02:43,  9.03s/it]Model Responding:   7%|‚ñã         | 61/875 [09:08<2:03:02,  9.07s/it]Model Responding:   7%|‚ñã         | 62/875 [09:17<2:01:19,  8.95s/it]Model Responding:   7%|‚ñã         | 63/875 [09:26<2:02:18,  9.04s/it]Model Responding:   7%|‚ñã         | 64/875 [09:36<2:04:15,  9.19s/it]Model Responding:   7%|‚ñã         | 65/875 [09:44<2:00:43,  8.94s/it]Model Responding:   8%|‚ñä         | 66/875 [09:53<2:02:59,  9.12s/it]Model Responding:   8%|‚ñä         | 67/875 [10:02<2:01:11,  9.00s/it]Model Responding:   8%|‚ñä         | 68/875 [10:12<2:02:46,  9.13s/it]Model Responding:   8%|‚ñä         | 69/875 [10:20<2:00:21,  8.96s/it]Model Responding:   8%|‚ñä         | 70/875 [10:29<2:00:37,  8.99s/it]Model Responding:   8%|‚ñä         | 71/875 [10:38<1:59:26,  8.91s/it]Model Responding:   8%|‚ñä         | 72/875 [10:47<1:58:36,  8.86s/it]Model Responding:   8%|‚ñä         | 73/875 [10:55<1:56:25,  8.71s/it]Model Responding:   8%|‚ñä         | 74/875 [11:04<1:56:06,  8.70s/it]Model Responding:   9%|‚ñä         | 75/875 [11:12<1:54:11,  8.56s/it]Model Responding:   9%|‚ñä         | 76/875 [11:21<1:54:18,  8.58s/it]Model Responding:   9%|‚ñâ         | 77/875 [11:29<1:53:55,  8.57s/it]Model Responding:   9%|‚ñâ         | 78/875 [11:38<1:53:28,  8.54s/it]Model Responding:   9%|‚ñâ         | 79/875 [11:46<1:54:08,  8.60s/it]Model Responding:   9%|‚ñâ         | 80/875 [11:55<1:56:07,  8.76s/it]Model Responding:   9%|‚ñâ         | 81/875 [12:04<1:54:33,  8.66s/it]Model Responding:   9%|‚ñâ         | 82/875 [12:13<1:55:36,  8.75s/it]Model Responding:   9%|‚ñâ         | 83/875 [12:22<1:58:22,  8.97s/it]Model Responding:  10%|‚ñâ         | 84/875 [12:32<2:00:56,  9.17s/it]Model Responding:  10%|‚ñâ         | 85/875 [12:42<2:04:58,  9.49s/it]Model Responding:  10%|‚ñâ         | 86/875 [12:52<2:04:47,  9.49s/it]Model Responding:  10%|‚ñâ         | 87/875 [13:01<2:02:02,  9.29s/it]Model Responding:  10%|‚ñà         | 88/875 [13:09<1:59:27,  9.11s/it]Model Responding:  10%|‚ñà         | 89/875 [13:18<1:59:05,  9.09s/it]Model Responding:  10%|‚ñà         | 90/875 [13:28<2:00:41,  9.23s/it]Model Responding:  10%|‚ñà         | 91/875 [13:37<1:59:46,  9.17s/it]Model Responding:  11%|‚ñà         | 92/875 [13:46<2:01:40,  9.32s/it]Model Responding:  11%|‚ñà         | 93/875 [13:57<2:05:17,  9.61s/it]Model Responding:  11%|‚ñà         | 94/875 [14:07<2:05:59,  9.68s/it]Model Responding:  11%|‚ñà         | 95/875 [14:16<2:03:29,  9.50s/it]Model Responding:  11%|‚ñà         | 96/875 [14:25<2:02:18,  9.42s/it]Model Responding:  11%|‚ñà         | 97/875 [14:33<1:57:31,  9.06s/it]Model Responding:  11%|‚ñà         | 98/875 [14:41<1:53:53,  8.80s/it]Model Responding:  11%|‚ñà‚ñè        | 99/875 [14:51<1:57:17,  9.07s/it]Model Responding:  11%|‚ñà‚ñè        | 100/875 [15:00<1:55:46,  8.96s/it]Model Responding:  12%|‚ñà‚ñè        | 101/875 [15:08<1:53:59,  8.84s/it]Model Responding:  12%|‚ñà‚ñè        | 102/875 [15:17<1:53:37,  8.82s/it]Model Responding:  12%|‚ñà‚ñè        | 103/875 [15:26<1:54:15,  8.88s/it]Model Responding:  12%|‚ñà‚ñè        | 104/875 [15:35<1:54:13,  8.89s/it]Model Responding:  12%|‚ñà‚ñè        | 105/875 [15:44<1:54:09,  8.90s/it]Model Responding:  12%|‚ñà‚ñè        | 106/875 [15:53<1:53:17,  8.84s/it]Model Responding:  12%|‚ñà‚ñè        | 107/875 [16:01<1:52:35,  8.80s/it]Model Responding:  12%|‚ñà‚ñè        | 108/875 [16:10<1:53:07,  8.85s/it]Model Responding:  12%|‚ñà‚ñè        | 109/875 [16:19<1:53:17,  8.87s/it]Model Responding:  13%|‚ñà‚ñé        | 110/875 [16:28<1:52:23,  8.81s/it]Model Responding:  13%|‚ñà‚ñé        | 111/875 [16:37<1:52:26,  8.83s/it]Model Responding:  13%|‚ñà‚ñé        | 112/875 [16:46<1:53:03,  8.89s/it]Model Responding:  13%|‚ñà‚ñé        | 113/875 [16:54<1:51:17,  8.76s/it]Model Responding:  13%|‚ñà‚ñé        | 114/875 [17:03<1:52:37,  8.88s/it]Model Responding:  13%|‚ñà‚ñé        | 115/875 [17:13<1:53:35,  8.97s/it]Model Responding:  13%|‚ñà‚ñé        | 116/875 [17:22<1:53:30,  8.97s/it]Model Responding:  13%|‚ñà‚ñé        | 117/875 [17:30<1:52:03,  8.87s/it]Model Responding:  13%|‚ñà‚ñé        | 118/875 [17:39<1:51:20,  8.82s/it]Model Responding:  14%|‚ñà‚ñé        | 119/875 [17:48<1:51:33,  8.85s/it]Model Responding:  14%|‚ñà‚ñé        | 120/875 [17:57<1:53:20,  9.01s/it]Model Responding:  14%|‚ñà‚ñç        | 121/875 [18:06<1:53:01,  8.99s/it]Model Responding:  14%|‚ñà‚ñç        | 122/875 [18:15<1:52:42,  8.98s/it]Model Responding:  14%|‚ñà‚ñç        | 123/875 [18:24<1:51:17,  8.88s/it]Model Responding:  14%|‚ñà‚ñç        | 124/875 [18:33<1:52:01,  8.95s/it]Model Responding:  14%|‚ñà‚ñç        | 125/875 [18:42<1:53:01,  9.04s/it]Model Responding:  14%|‚ñà‚ñç        | 126/875 [18:51<1:52:25,  9.01s/it]Model Responding:  15%|‚ñà‚ñç        | 127/875 [19:00<1:50:26,  8.86s/it]Model Responding:  15%|‚ñà‚ñç        | 128/875 [19:09<1:52:18,  9.02s/it]Model Responding:  15%|‚ñà‚ñç        | 129/875 [19:18<1:52:01,  9.01s/it]Model Responding:  15%|‚ñà‚ñç        | 130/875 [19:27<1:51:00,  8.94s/it]Model Responding:  15%|‚ñà‚ñç        | 131/875 [19:35<1:49:27,  8.83s/it]Model Responding:  15%|‚ñà‚ñå        | 132/875 [19:45<1:51:14,  8.98s/it]Model Responding:  15%|‚ñà‚ñå        | 133/875 [19:53<1:50:06,  8.90s/it]Model Responding:  15%|‚ñà‚ñå        | 134/875 [20:02<1:48:15,  8.77s/it]Model Responding:  15%|‚ñà‚ñå        | 135/875 [20:11<1:48:11,  8.77s/it]Model Responding:  16%|‚ñà‚ñå        | 136/875 [20:19<1:47:25,  8.72s/it]Model Responding:  16%|‚ñà‚ñå        | 137/875 [20:29<1:49:36,  8.91s/it]Model Responding:  16%|‚ñà‚ñå        | 138/875 [20:37<1:47:22,  8.74s/it]Model Responding:  16%|‚ñà‚ñå        | 139/875 [20:45<1:46:35,  8.69s/it]Model Responding:  16%|‚ñà‚ñå        | 140/875 [20:54<1:47:32,  8.78s/it]Model Responding:  16%|‚ñà‚ñå        | 141/875 [21:03<1:46:22,  8.69s/it]Model Responding:  16%|‚ñà‚ñå        | 142/875 [21:12<1:47:09,  8.77s/it]Model Responding:  16%|‚ñà‚ñã        | 143/875 [21:20<1:45:39,  8.66s/it]Model Responding:  16%|‚ñà‚ñã        | 144/875 [21:29<1:45:59,  8.70s/it]Model Responding:  17%|‚ñà‚ñã        | 145/875 [21:38<1:45:17,  8.65s/it]Model Responding:  17%|‚ñà‚ñã        | 146/875 [21:46<1:45:28,  8.68s/it]Model Responding:  17%|‚ñà‚ñã        | 147/875 [21:55<1:43:28,  8.53s/it]Model Responding:  17%|‚ñà‚ñã        | 148/875 [22:03<1:43:21,  8.53s/it]Model Responding:  17%|‚ñà‚ñã        | 149/875 [22:12<1:44:32,  8.64s/it]Model Responding:  17%|‚ñà‚ñã        | 150/875 [22:21<1:44:20,  8.64s/it]Model Responding:  17%|‚ñà‚ñã        | 151/875 [22:29<1:43:31,  8.58s/it]Model Responding:  17%|‚ñà‚ñã        | 152/875 [22:38<1:43:34,  8.59s/it]Model Responding:  17%|‚ñà‚ñã        | 153/875 [22:47<1:44:37,  8.70s/it]Model Responding:  18%|‚ñà‚ñä        | 154/875 [22:55<1:44:40,  8.71s/it]Model Responding:  18%|‚ñà‚ñä        | 155/875 [23:05<1:46:21,  8.86s/it]Model Responding:  18%|‚ñà‚ñä        | 156/875 [23:13<1:44:56,  8.76s/it]Model Responding:  18%|‚ñà‚ñä        | 157/875 [23:22<1:44:27,  8.73s/it]Model Responding:  18%|‚ñà‚ñä        | 158/875 [23:31<1:46:22,  8.90s/it]Model Responding:  18%|‚ñà‚ñä        | 159/875 [23:40<1:46:44,  8.94s/it]Model Responding:  18%|‚ñà‚ñä        | 160/875 [23:49<1:47:46,  9.04s/it]Model Responding:  18%|‚ñà‚ñä        | 161/875 [23:58<1:45:14,  8.84s/it]Model Responding:  19%|‚ñà‚ñä        | 162/875 [24:06<1:43:12,  8.68s/it]Model Responding:  19%|‚ñà‚ñä        | 163/875 [24:15<1:43:48,  8.75s/it]Model Responding:  19%|‚ñà‚ñä        | 164/875 [24:24<1:43:55,  8.77s/it]Model Responding:  19%|‚ñà‚ñâ        | 165/875 [24:33<1:46:11,  8.97s/it]Model Responding:  19%|‚ñà‚ñâ        | 166/875 [24:41<1:43:12,  8.73s/it]Model Responding:  19%|‚ñà‚ñâ        | 167/875 [24:50<1:43:09,  8.74s/it]Model Responding:  19%|‚ñà‚ñâ        | 168/875 [24:59<1:43:18,  8.77s/it]Model Responding:  19%|‚ñà‚ñâ        | 169/875 [25:07<1:41:21,  8.61s/it]Model Responding:  19%|‚ñà‚ñâ        | 170/875 [25:16<1:41:35,  8.65s/it]Model Responding:  20%|‚ñà‚ñâ        | 171/875 [25:24<1:40:12,  8.54s/it]Model Responding:  20%|‚ñà‚ñâ        | 172/875 [25:33<1:39:20,  8.48s/it]Model Responding:  20%|‚ñà‚ñâ        | 173/875 [25:41<1:38:24,  8.41s/it]Model Responding:  20%|‚ñà‚ñâ        | 174/875 [25:50<1:41:17,  8.67s/it]Model Responding:  20%|‚ñà‚ñà        | 175/875 [25:59<1:42:28,  8.78s/it]Model Responding:  20%|‚ñà‚ñà        | 176/875 [26:08<1:41:44,  8.73s/it]Model Responding:  20%|‚ñà‚ñà        | 177/875 [26:17<1:42:01,  8.77s/it]Model Responding:  20%|‚ñà‚ñà        | 178/875 [26:25<1:42:00,  8.78s/it]Model Responding:  20%|‚ñà‚ñà        | 179/875 [26:35<1:43:37,  8.93s/it]Model Responding:  21%|‚ñà‚ñà        | 180/875 [26:43<1:42:01,  8.81s/it]Model Responding:  21%|‚ñà‚ñà        | 181/875 [26:52<1:41:15,  8.75s/it]Model Responding:  21%|‚ñà‚ñà        | 182/875 [27:00<1:38:43,  8.55s/it]Model Responding:  21%|‚ñà‚ñà        | 183/875 [27:09<1:38:37,  8.55s/it]Model Responding:  21%|‚ñà‚ñà        | 184/875 [27:17<1:36:54,  8.41s/it]Model Responding:  21%|‚ñà‚ñà        | 185/875 [27:26<1:38:22,  8.55s/it]Model Responding:  21%|‚ñà‚ñà‚ñè       | 186/875 [27:34<1:36:52,  8.44s/it]Model Responding:  21%|‚ñà‚ñà‚ñè       | 187/875 [27:42<1:37:17,  8.48s/it]Model Responding:  21%|‚ñà‚ñà‚ñè       | 188/875 [27:51<1:37:12,  8.49s/it]Model Responding:  22%|‚ñà‚ñà‚ñè       | 189/875 [27:59<1:36:05,  8.40s/it]Model Responding:  22%|‚ñà‚ñà‚ñè       | 190/875 [28:08<1:36:25,  8.45s/it]Model Responding:  22%|‚ñà‚ñà‚ñè       | 191/875 [28:16<1:36:29,  8.46s/it]Model Responding:  22%|‚ñà‚ñà‚ñè       | 192/875 [28:25<1:37:36,  8.57s/it]Model Responding:  22%|‚ñà‚ñà‚ñè       | 193/875 [28:33<1:37:11,  8.55s/it]Model Responding:  22%|‚ñà‚ñà‚ñè       | 194/875 [28:42<1:36:29,  8.50s/it]Model Responding:  22%|‚ñà‚ñà‚ñè       | 195/875 [28:51<1:40:09,  8.84s/it]Model Responding:  22%|‚ñà‚ñà‚ñè       | 196/875 [29:00<1:39:28,  8.79s/it]Model Responding:  23%|‚ñà‚ñà‚ñé       | 197/875 [29:09<1:39:44,  8.83s/it]Model Responding:  23%|‚ñà‚ñà‚ñé       | 198/875 [29:18<1:40:31,  8.91s/it]Model Responding:  23%|‚ñà‚ñà‚ñé       | 199/875 [29:27<1:41:25,  9.00s/it]Model Responding:  23%|‚ñà‚ñà‚ñé       | 200/875 [29:36<1:41:04,  8.98s/it]Model Responding:  23%|‚ñà‚ñà‚ñé       | 201/875 [29:45<1:40:43,  8.97s/it]Model Responding:  23%|‚ñà‚ñà‚ñé       | 202/875 [29:54<1:39:57,  8.91s/it]Model Responding:  23%|‚ñà‚ñà‚ñé       | 203/875 [30:03<1:40:06,  8.94s/it]Model Responding:  23%|‚ñà‚ñà‚ñé       | 204/875 [30:12<1:39:21,  8.89s/it]Model Responding:  23%|‚ñà‚ñà‚ñé       | 205/875 [30:21<1:40:03,  8.96s/it]Model Responding:  24%|‚ñà‚ñà‚ñé       | 206/875 [30:30<1:39:59,  8.97s/it]Model Responding:  24%|‚ñà‚ñà‚ñé       | 207/875 [30:39<1:40:32,  9.03s/it]Model Responding:  24%|‚ñà‚ñà‚ñç       | 208/875 [30:48<1:40:09,  9.01s/it]Model Responding:  24%|‚ñà‚ñà‚ñç       | 209/875 [30:57<1:41:01,  9.10s/it]Model Responding:  24%|‚ñà‚ñà‚ñç       | 210/875 [31:06<1:40:04,  9.03s/it]Model Responding:  24%|‚ñà‚ñà‚ñç       | 211/875 [31:15<1:37:49,  8.84s/it]Model Responding:  24%|‚ñà‚ñà‚ñç       | 212/875 [31:23<1:36:53,  8.77s/it]Model Responding:  24%|‚ñà‚ñà‚ñç       | 213/875 [31:33<1:38:54,  8.96s/it]Model Responding:  24%|‚ñà‚ñà‚ñç       | 214/875 [31:42<1:40:01,  9.08s/it]Model Responding:  25%|‚ñà‚ñà‚ñç       | 215/875 [31:51<1:40:47,  9.16s/it]Model Responding:  25%|‚ñà‚ñà‚ñç       | 216/875 [32:00<1:39:06,  9.02s/it]Model Responding:  25%|‚ñà‚ñà‚ñç       | 217/875 [32:09<1:38:16,  8.96s/it]Model Responding:  25%|‚ñà‚ñà‚ñç       | 218/875 [32:18<1:38:14,  8.97s/it]Model Responding:  25%|‚ñà‚ñà‚ñå       | 219/875 [32:27<1:37:37,  8.93s/it]Model Responding:  25%|‚ñà‚ñà‚ñå       | 220/875 [32:35<1:36:50,  8.87s/it]Model Responding:  25%|‚ñà‚ñà‚ñå       | 221/875 [32:44<1:35:17,  8.74s/it]Model Responding:  25%|‚ñà‚ñà‚ñå       | 222/875 [32:53<1:35:11,  8.75s/it]Model Responding:  25%|‚ñà‚ñà‚ñå       | 223/875 [33:02<1:35:58,  8.83s/it]Model Responding:  26%|‚ñà‚ñà‚ñå       | 224/875 [33:10<1:36:07,  8.86s/it]Model Responding:  26%|‚ñà‚ñà‚ñå       | 225/875 [33:19<1:35:11,  8.79s/it]Model Responding:  26%|‚ñà‚ñà‚ñå       | 226/875 [33:28<1:34:11,  8.71s/it]Model Responding:  26%|‚ñà‚ñà‚ñå       | 227/875 [33:36<1:33:29,  8.66s/it]Model Responding:  26%|‚ñà‚ñà‚ñå       | 228/875 [33:45<1:33:05,  8.63s/it]Model Responding:  26%|‚ñà‚ñà‚ñå       | 229/875 [33:53<1:31:44,  8.52s/it]Model Responding:  26%|‚ñà‚ñà‚ñã       | 230/875 [34:01<1:29:58,  8.37s/it]Model Responding:  26%|‚ñà‚ñà‚ñã       | 231/875 [34:09<1:29:03,  8.30s/it]Model Responding:  27%|‚ñà‚ñà‚ñã       | 232/875 [34:18<1:30:25,  8.44s/it]Model Responding:  27%|‚ñà‚ñà‚ñã       | 233/875 [34:27<1:32:04,  8.60s/it]Model Responding:  27%|‚ñà‚ñà‚ñã       | 234/875 [34:36<1:33:09,  8.72s/it]Model Responding:  27%|‚ñà‚ñà‚ñã       | 235/875 [34:45<1:33:24,  8.76s/it]Model Responding:  27%|‚ñà‚ñà‚ñã       | 236/875 [34:53<1:33:15,  8.76s/it]Model Responding:  27%|‚ñà‚ñà‚ñã       | 237/875 [35:02<1:32:31,  8.70s/it]Model Responding:  27%|‚ñà‚ñà‚ñã       | 238/875 [35:11<1:32:03,  8.67s/it]Model Responding:  27%|‚ñà‚ñà‚ñã       | 239/875 [35:20<1:32:31,  8.73s/it]Model Responding:  27%|‚ñà‚ñà‚ñã       | 240/875 [35:28<1:32:10,  8.71s/it]Model Responding:  28%|‚ñà‚ñà‚ñä       | 241/875 [35:36<1:30:31,  8.57s/it]Model Responding:  28%|‚ñà‚ñà‚ñä       | 242/875 [35:46<1:32:28,  8.77s/it]Model Responding:  28%|‚ñà‚ñà‚ñä       | 243/875 [35:55<1:34:36,  8.98s/it]Model Responding:  28%|‚ñà‚ñà‚ñä       | 244/875 [36:04<1:34:54,  9.03s/it]Model Responding:  28%|‚ñà‚ñà‚ñä       | 245/875 [36:13<1:33:56,  8.95s/it]Model Responding:  28%|‚ñà‚ñà‚ñä       | 246/875 [36:22<1:32:57,  8.87s/it]Model Responding:  28%|‚ñà‚ñà‚ñä       | 247/875 [36:30<1:31:56,  8.78s/it]Model Responding:  28%|‚ñà‚ñà‚ñä       | 248/875 [36:40<1:33:32,  8.95s/it]Model Responding:  28%|‚ñà‚ñà‚ñä       | 249/875 [36:50<1:36:35,  9.26s/it]Model Responding:  29%|‚ñà‚ñà‚ñä       | 250/875 [36:59<1:36:54,  9.30s/it]Model Responding:  29%|‚ñà‚ñà‚ñä       | 251/875 [37:08<1:34:41,  9.10s/it]Model Responding:  29%|‚ñà‚ñà‚ñâ       | 252/875 [37:16<1:32:50,  8.94s/it]Model Responding:  29%|‚ñà‚ñà‚ñâ       | 253/875 [37:24<1:30:17,  8.71s/it]Model Responding:  29%|‚ñà‚ñà‚ñâ       | 254/875 [37:33<1:29:40,  8.66s/it]Model Responding:  29%|‚ñà‚ñà‚ñâ       | 255/875 [37:41<1:28:34,  8.57s/it]Model Responding:  29%|‚ñà‚ñà‚ñâ       | 256/875 [37:50<1:29:15,  8.65s/it]Model Responding:  29%|‚ñà‚ñà‚ñâ       | 257/875 [38:00<1:31:53,  8.92s/it]Model Responding:  29%|‚ñà‚ñà‚ñâ       | 258/875 [38:09<1:32:50,  9.03s/it]Model Responding:  30%|‚ñà‚ñà‚ñâ       | 259/875 [38:18<1:32:19,  8.99s/it]Model Responding:  30%|‚ñà‚ñà‚ñâ       | 260/875 [38:27<1:32:58,  9.07s/it]Model Responding:  30%|‚ñà‚ñà‚ñâ       | 261/875 [38:36<1:32:14,  9.01s/it]Model Responding:  30%|‚ñà‚ñà‚ñâ       | 262/875 [38:45<1:30:38,  8.87s/it]Model Responding:  30%|‚ñà‚ñà‚ñà       | 263/875 [38:54<1:32:07,  9.03s/it]Model Responding:  30%|‚ñà‚ñà‚ñà       | 264/875 [39:03<1:31:42,  9.01s/it]Model Responding:  30%|‚ñà‚ñà‚ñà       | 265/875 [39:12<1:33:10,  9.16s/it]Model Responding:  30%|‚ñà‚ñà‚ñà       | 266/875 [39:21<1:32:26,  9.11s/it]Model Responding:  31%|‚ñà‚ñà‚ñà       | 267/875 [39:31<1:32:33,  9.13s/it]Model Responding:  31%|‚ñà‚ñà‚ñà       | 268/875 [39:40<1:31:56,  9.09s/it]Model Responding:  31%|‚ñà‚ñà‚ñà       | 269/875 [39:48<1:29:46,  8.89s/it]Model Responding:  31%|‚ñà‚ñà‚ñà       | 270/875 [39:57<1:30:20,  8.96s/it]Model Responding:  31%|‚ñà‚ñà‚ñà       | 271/875 [40:06<1:30:12,  8.96s/it]Model Responding:  31%|‚ñà‚ñà‚ñà       | 272/875 [40:15<1:28:26,  8.80s/it]Model Responding:  31%|‚ñà‚ñà‚ñà       | 273/875 [40:23<1:28:20,  8.80s/it]Model Responding:  31%|‚ñà‚ñà‚ñà‚ñè      | 274/875 [40:32<1:28:11,  8.81s/it]Model Responding:  31%|‚ñà‚ñà‚ñà‚ñè      | 275/875 [40:41<1:27:25,  8.74s/it]Model Responding:  32%|‚ñà‚ñà‚ñà‚ñè      | 276/875 [40:50<1:27:54,  8.81s/it]Model Responding:  32%|‚ñà‚ñà‚ñà‚ñè      | 277/875 [40:59<1:28:51,  8.92s/it]Model Responding:  32%|‚ñà‚ñà‚ñà‚ñè      | 278/875 [41:08<1:28:33,  8.90s/it]Model Responding:  32%|‚ñà‚ñà‚ñà‚ñè      | 279/875 [41:17<1:28:32,  8.91s/it]Model Responding:  32%|‚ñà‚ñà‚ñà‚ñè      | 280/875 [41:25<1:27:02,  8.78s/it]Model Responding:  32%|‚ñà‚ñà‚ñà‚ñè      | 281/875 [41:34<1:26:48,  8.77s/it]Model Responding:  32%|‚ñà‚ñà‚ñà‚ñè      | 282/875 [41:43<1:27:49,  8.89s/it]Model Responding:  32%|‚ñà‚ñà‚ñà‚ñè      | 283/875 [41:52<1:28:29,  8.97s/it]Model Responding:  32%|‚ñà‚ñà‚ñà‚ñè      | 284/875 [42:02<1:29:46,  9.11s/it]Model Responding:  33%|‚ñà‚ñà‚ñà‚ñé      | 285/875 [42:10<1:28:38,  9.01s/it]Model Responding:  33%|‚ñà‚ñà‚ñà‚ñé      | 286/875 [42:19<1:26:49,  8.84s/it]Model Responding:  33%|‚ñà‚ñà‚ñà‚ñé      | 287/875 [42:28<1:26:42,  8.85s/it]Model Responding:  33%|‚ñà‚ñà‚ñà‚ñé      | 288/875 [42:37<1:26:43,  8.86s/it]Model Responding:  33%|‚ñà‚ñà‚ñà‚ñé      | 289/875 [42:45<1:25:33,  8.76s/it]Model Responding:  33%|‚ñà‚ñà‚ñà‚ñé      | 290/875 [42:54<1:26:00,  8.82s/it]Model Responding:  33%|‚ñà‚ñà‚ñà‚ñé      | 291/875 [43:03<1:24:39,  8.70s/it]Model Responding:  33%|‚ñà‚ñà‚ñà‚ñé      | 292/875 [43:12<1:25:30,  8.80s/it]Model Responding:  33%|‚ñà‚ñà‚ñà‚ñé      | 293/875 [43:21<1:26:57,  8.96s/it]Model Responding:  34%|‚ñà‚ñà‚ñà‚ñé      | 294/875 [43:31<1:28:59,  9.19s/it]Model Responding:  34%|‚ñà‚ñà‚ñà‚ñé      | 295/875 [43:39<1:27:26,  9.05s/it]Model Responding:  34%|‚ñà‚ñà‚ñà‚ñç      | 296/875 [43:48<1:26:26,  8.96s/it]Model Responding:  34%|‚ñà‚ñà‚ñà‚ñç      | 297/875 [43:57<1:26:42,  9.00s/it]Model Responding:  34%|‚ñà‚ñà‚ñà‚ñç      | 298/875 [44:06<1:24:48,  8.82s/it]Model Responding:  34%|‚ñà‚ñà‚ñà‚ñç      | 299/875 [44:14<1:24:19,  8.78s/it]Model Responding:  34%|‚ñà‚ñà‚ñà‚ñç      | 300/875 [44:23<1:23:48,  8.75s/it]Model Responding:  34%|‚ñà‚ñà‚ñà‚ñç      | 301/875 [44:31<1:21:48,  8.55s/it]Model Responding:  35%|‚ñà‚ñà‚ñà‚ñç      | 302/875 [44:39<1:20:54,  8.47s/it]Model Responding:  35%|‚ñà‚ñà‚ñà‚ñç      | 303/875 [44:48<1:22:34,  8.66s/it]Model Responding:  35%|‚ñà‚ñà‚ñà‚ñç      | 304/875 [44:57<1:21:41,  8.58s/it]Model Responding:  35%|‚ñà‚ñà‚ñà‚ñç      | 305/875 [45:06<1:21:44,  8.60s/it]Model Responding:  35%|‚ñà‚ñà‚ñà‚ñç      | 306/875 [45:14<1:21:23,  8.58s/it]Model Responding:  35%|‚ñà‚ñà‚ñà‚ñå      | 307/875 [45:23<1:22:32,  8.72s/it]Model Responding:  35%|‚ñà‚ñà‚ñà‚ñå      | 308/875 [45:32<1:21:56,  8.67s/it]Model Responding:  35%|‚ñà‚ñà‚ñà‚ñå      | 309/875 [45:40<1:21:49,  8.67s/it]Model Responding:  35%|‚ñà‚ñà‚ñà‚ñå      | 310/875 [45:50<1:24:15,  8.95s/it]Model Responding:  36%|‚ñà‚ñà‚ñà‚ñå      | 311/875 [45:59<1:25:23,  9.08s/it]Model Responding:  36%|‚ñà‚ñà‚ñà‚ñå      | 312/875 [46:08<1:25:06,  9.07s/it]Model Responding:  36%|‚ñà‚ñà‚ñà‚ñå      | 313/875 [46:17<1:24:01,  8.97s/it]Model Responding:  36%|‚ñà‚ñà‚ñà‚ñå      | 314/875 [46:26<1:24:28,  9.03s/it]Model Responding:  36%|‚ñà‚ñà‚ñà‚ñå      | 315/875 [46:35<1:24:17,  9.03s/it]Model Responding:  36%|‚ñà‚ñà‚ñà‚ñå      | 316/875 [46:45<1:25:33,  9.18s/it]Model Responding:  36%|‚ñà‚ñà‚ñà‚ñå      | 317/875 [46:54<1:23:59,  9.03s/it]Model Responding:  36%|‚ñà‚ñà‚ñà‚ñã      | 318/875 [47:02<1:21:45,  8.81s/it]Model Responding:  36%|‚ñà‚ñà‚ñà‚ñã      | 319/875 [47:10<1:20:08,  8.65s/it]Model Responding:  37%|‚ñà‚ñà‚ñà‚ñã      | 320/875 [47:19<1:21:05,  8.77s/it]Model Responding:  37%|‚ñà‚ñà‚ñà‚ñã      | 321/875 [47:28<1:20:14,  8.69s/it]Model Responding:  37%|‚ñà‚ñà‚ñà‚ñã      | 322/875 [47:37<1:22:22,  8.94s/it]Model Responding:  37%|‚ñà‚ñà‚ñà‚ñã      | 323/875 [47:46<1:21:51,  8.90s/it]Model Responding:  37%|‚ñà‚ñà‚ñà‚ñã      | 324/875 [47:55<1:21:06,  8.83s/it]Model Responding:  37%|‚ñà‚ñà‚ñà‚ñã      | 325/875 [48:03<1:20:40,  8.80s/it]Model Responding:  37%|‚ñà‚ñà‚ñà‚ñã      | 326/875 [48:12<1:20:19,  8.78s/it]Model Responding:  37%|‚ñà‚ñà‚ñà‚ñã      | 327/875 [48:20<1:19:00,  8.65s/it]Model Responding:  37%|‚ñà‚ñà‚ñà‚ñã      | 328/875 [48:29<1:19:37,  8.73s/it]Model Responding:  38%|‚ñà‚ñà‚ñà‚ñä      | 329/875 [48:38<1:20:28,  8.84s/it]Model Responding:  38%|‚ñà‚ñà‚ñà‚ñä      | 330/875 [48:47<1:20:44,  8.89s/it]Model Responding:  38%|‚ñà‚ñà‚ñà‚ñä      | 331/875 [48:56<1:20:23,  8.87s/it]Model Responding:  38%|‚ñà‚ñà‚ñà‚ñä      | 332/875 [49:05<1:19:06,  8.74s/it]Model Responding:  38%|‚ñà‚ñà‚ñà‚ñä      | 333/875 [49:14<1:19:15,  8.77s/it]Model Responding:  38%|‚ñà‚ñà‚ñà‚ñä      | 334/875 [49:22<1:17:44,  8.62s/it]Model Responding:  38%|‚ñà‚ñà‚ñà‚ñä      | 335/875 [49:31<1:17:47,  8.64s/it]Model Responding:  38%|‚ñà‚ñà‚ñà‚ñä      | 336/875 [49:39<1:18:19,  8.72s/it]Model Responding:  39%|‚ñà‚ñà‚ñà‚ñä      | 337/875 [49:48<1:18:53,  8.80s/it]Model Responding:  39%|‚ñà‚ñà‚ñà‚ñä      | 338/875 [49:57<1:18:12,  8.74s/it]Model Responding:  39%|‚ñà‚ñà‚ñà‚ñä      | 339/875 [50:05<1:16:56,  8.61s/it]Model Responding:  39%|‚ñà‚ñà‚ñà‚ñâ      | 340/875 [50:14<1:17:21,  8.68s/it]Model Responding:  39%|‚ñà‚ñà‚ñà‚ñâ      | 341/875 [50:23<1:17:37,  8.72s/it]Model Responding:  39%|‚ñà‚ñà‚ñà‚ñâ      | 342/875 [50:32<1:17:35,  8.74s/it]Model Responding:  39%|‚ñà‚ñà‚ñà‚ñâ      | 343/875 [50:40<1:16:47,  8.66s/it]Model Responding:  39%|‚ñà‚ñà‚ñà‚ñâ      | 344/875 [50:49<1:17:51,  8.80s/it]Model Responding:  39%|‚ñà‚ñà‚ñà‚ñâ      | 345/875 [50:59<1:18:54,  8.93s/it]Model Responding:  40%|‚ñà‚ñà‚ñà‚ñâ      | 346/875 [51:08<1:19:18,  9.00s/it]Model Responding:  40%|‚ñà‚ñà‚ñà‚ñâ      | 347/875 [51:17<1:18:47,  8.95s/it]Model Responding:  40%|‚ñà‚ñà‚ñà‚ñâ      | 348/875 [51:26<1:18:33,  8.94s/it]Model Responding:  40%|‚ñà‚ñà‚ñà‚ñâ      | 349/875 [51:34<1:18:14,  8.93s/it]Model Responding:  40%|‚ñà‚ñà‚ñà‚ñà      | 350/875 [51:43<1:17:58,  8.91s/it]Model Responding:  40%|‚ñà‚ñà‚ñà‚ñà      | 351/875 [51:53<1:18:42,  9.01s/it]Model Responding:  40%|‚ñà‚ñà‚ñà‚ñà      | 352/875 [52:01<1:18:08,  8.97s/it]Model Responding:  40%|‚ñà‚ñà‚ñà‚ñà      | 353/875 [52:10<1:16:51,  8.83s/it]Model Responding:  40%|‚ñà‚ñà‚ñà‚ñà      | 354/875 [52:19<1:18:23,  9.03s/it]Model Responding:  41%|‚ñà‚ñà‚ñà‚ñà      | 355/875 [52:28<1:18:09,  9.02s/it]Model Responding:  41%|‚ñà‚ñà‚ñà‚ñà      | 356/875 [52:37<1:16:50,  8.88s/it]Model Responding:  41%|‚ñà‚ñà‚ñà‚ñà      | 357/875 [52:45<1:15:25,  8.74s/it]Model Responding:  41%|‚ñà‚ñà‚ñà‚ñà      | 358/875 [52:54<1:15:25,  8.75s/it]Model Responding:  41%|‚ñà‚ñà‚ñà‚ñà      | 359/875 [53:04<1:17:42,  9.04s/it]Model Responding:  41%|‚ñà‚ñà‚ñà‚ñà      | 360/875 [53:13<1:18:05,  9.10s/it]Model Responding:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 361/875 [53:22<1:17:20,  9.03s/it]Model Responding:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 362/875 [53:31<1:17:42,  9.09s/it]Model Responding:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 363/875 [53:41<1:19:04,  9.27s/it]Model Responding:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 364/875 [53:50<1:19:44,  9.36s/it]Model Responding:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 365/875 [53:59<1:17:02,  9.06s/it]Model Responding:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 366/875 [54:07<1:15:45,  8.93s/it]Model Responding:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 367/875 [54:16<1:14:03,  8.75s/it]Model Responding:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 368/875 [54:24<1:13:54,  8.75s/it]Model Responding:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 369/875 [54:34<1:15:21,  8.94s/it]Model Responding:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 370/875 [54:43<1:14:27,  8.85s/it]Model Responding:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 371/875 [54:53<1:17:25,  9.22s/it]Model Responding:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 372/875 [55:02<1:16:58,  9.18s/it]Model Responding:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 373/875 [55:11<1:17:18,  9.24s/it]Model Responding:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 374/875 [55:20<1:16:17,  9.14s/it]Model Responding:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 375/875 [55:29<1:16:30,  9.18s/it]Model Responding:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 376/875 [55:38<1:15:16,  9.05s/it]Model Responding:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 377/875 [55:47<1:14:14,  8.94s/it]Model Responding:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 378/875 [55:55<1:12:58,  8.81s/it]Model Responding:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 379/875 [56:04<1:12:55,  8.82s/it]Model Responding:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 380/875 [56:13<1:13:29,  8.91s/it]Model Responding:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 381/875 [56:22<1:12:57,  8.86s/it]Model Responding:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 382/875 [56:31<1:12:49,  8.86s/it]Model Responding:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 383/875 [56:40<1:12:57,  8.90s/it]Model Responding:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 384/875 [56:49<1:14:40,  9.13s/it]Model Responding:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 385/875 [56:58<1:14:01,  9.06s/it]Model Responding:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 386/875 [57:08<1:14:18,  9.12s/it]Model Responding:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 387/875 [57:16<1:12:55,  8.97s/it]Model Responding:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 388/875 [57:25<1:13:26,  9.05s/it]Model Responding:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 389/875 [57:34<1:12:48,  8.99s/it]Model Responding:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 390/875 [57:43<1:12:39,  8.99s/it]Model Responding:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 391/875 [57:52<1:12:30,  8.99s/it]Model Responding:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 392/875 [58:01<1:11:34,  8.89s/it]Model Responding:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 393/875 [58:09<1:09:55,  8.70s/it]Model Responding:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 394/875 [58:17<1:08:42,  8.57s/it]Model Responding:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 395/875 [58:26<1:09:13,  8.65s/it]Model Responding:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 396/875 [58:36<1:10:31,  8.83s/it]Model Responding:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 397/875 [58:45<1:11:09,  8.93s/it]Model Responding:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 398/875 [58:55<1:13:40,  9.27s/it]Model Responding:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 399/875 [59:04<1:13:43,  9.29s/it]Model Responding:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 400/875 [59:13<1:12:29,  9.16s/it]Model Responding:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 401/875 [59:22<1:11:06,  9.00s/it]Model Responding:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 402/875 [59:30<1:08:52,  8.74s/it]Model Responding:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 403/875 [59:38<1:08:35,  8.72s/it]Model Responding:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 404/875 [59:48<1:10:55,  9.04s/it]Model Responding:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 405/875 [59:57<1:11:14,  9.09s/it]Model Responding:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 406/875 [1:00:06<1:10:42,  9.05s/it]Model Responding:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 407/875 [1:00:15<1:09:46,  8.95s/it]Model Responding:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 408/875 [1:00:24<1:10:24,  9.05s/it]Model Responding:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 409/875 [1:00:33<1:08:55,  8.87s/it]Model Responding:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 410/875 [1:00:42<1:08:33,  8.85s/it]Model Responding:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 411/875 [1:00:51<1:09:12,  8.95s/it]Model Responding:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 412/875 [1:01:00<1:10:11,  9.10s/it]Model Responding:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 413/875 [1:01:09<1:10:10,  9.11s/it]Model Responding:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 414/875 [1:01:18<1:08:33,  8.92s/it]Model Responding:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 415/875 [1:01:26<1:07:27,  8.80s/it]Model Responding:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 416/875 [1:01:35<1:07:10,  8.78s/it]Model Responding:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 417/875 [1:01:44<1:06:38,  8.73s/it]Model Responding:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 418/875 [1:01:53<1:07:52,  8.91s/it]Model Responding:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 419/875 [1:02:02<1:07:26,  8.87s/it]Model Responding:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 420/875 [1:02:10<1:06:09,  8.72s/it]Model Responding:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 421/875 [1:02:19<1:06:56,  8.85s/it]Model Responding:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 422/875 [1:02:28<1:06:11,  8.77s/it]Model Responding:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 423/875 [1:02:37<1:05:56,  8.75s/it]Model Responding:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 424/875 [1:02:45<1:05:28,  8.71s/it]Model Responding:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 425/875 [1:02:54<1:06:21,  8.85s/it]Model Responding:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 426/875 [1:03:03<1:06:14,  8.85s/it]Model Responding:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 427/875 [1:03:12<1:06:34,  8.92s/it]Model Responding:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 428/875 [1:03:21<1:06:55,  8.98s/it]Model Responding:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 429/875 [1:03:30<1:06:49,  8.99s/it]Model Responding:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 430/875 [1:03:40<1:07:16,  9.07s/it]Model Responding:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 431/875 [1:03:49<1:07:30,  9.12s/it]Model Responding:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 432/875 [1:03:59<1:08:31,  9.28s/it]Model Responding:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 433/875 [1:04:07<1:07:06,  9.11s/it]Model Responding:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 434/875 [1:04:16<1:06:06,  8.99s/it]Model Responding:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 435/875 [1:04:25<1:06:20,  9.05s/it]Model Responding:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 436/875 [1:04:34<1:05:28,  8.95s/it]Model Responding:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 437/875 [1:04:42<1:04:16,  8.80s/it]Model Responding:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 438/875 [1:04:52<1:05:37,  9.01s/it]Model Responding:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 439/875 [1:05:01<1:04:53,  8.93s/it]Model Responding:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 440/875 [1:05:10<1:04:46,  8.93s/it]Model Responding:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 441/875 [1:05:18<1:03:52,  8.83s/it]Model Responding:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 442/875 [1:05:29<1:07:28,  9.35s/it]Model Responding:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 443/875 [1:05:38<1:06:43,  9.27s/it]Model Responding:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 444/875 [1:05:47<1:05:48,  9.16s/it]Model Responding:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 445/875 [1:05:55<1:04:41,  9.03s/it]Model Responding:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 446/875 [1:06:05<1:05:04,  9.10s/it]Model Responding:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 447/875 [1:06:14<1:06:17,  9.29s/it]Model Responding:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 448/875 [1:06:24<1:05:52,  9.26s/it]Model Responding:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 449/875 [1:06:33<1:05:38,  9.25s/it]Model Responding:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 450/875 [1:06:42<1:05:40,  9.27s/it]Model Responding:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 451/875 [1:06:52<1:06:45,  9.45s/it]Model Responding:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 452/875 [1:07:01<1:05:15,  9.26s/it]Model Responding:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 453/875 [1:07:10<1:04:16,  9.14s/it]Model Responding:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 454/875 [1:07:18<1:01:37,  8.78s/it]Model Responding:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 455/875 [1:07:27<1:02:28,  8.93s/it]Model Responding:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 456/875 [1:07:36<1:02:17,  8.92s/it]Model Responding:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 457/875 [1:07:44<1:01:35,  8.84s/it]Model Responding:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 458/875 [1:07:54<1:02:22,  8.97s/it]Model Responding:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 459/875 [1:08:03<1:02:07,  8.96s/it]Model Responding:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 460/875 [1:08:12<1:02:20,  9.01s/it]Model Responding:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 461/875 [1:08:21<1:02:28,  9.05s/it]Model Responding:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 462/875 [1:08:30<1:01:51,  8.99s/it]Model Responding:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 463/875 [1:08:40<1:03:37,  9.27s/it]Model Responding:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 464/875 [1:08:49<1:02:29,  9.12s/it]Model Responding:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 465/875 [1:08:57<1:01:45,  9.04s/it]Model Responding:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 466/875 [1:09:06<1:01:19,  9.00s/it]Model Responding:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 467/875 [1:09:15<1:00:24,  8.88s/it]Model Responding:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 468/875 [1:09:24<1:01:04,  9.00s/it]Model Responding:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 469/875 [1:09:34<1:01:54,  9.15s/it]Model Responding:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 470/875 [1:09:43<1:01:37,  9.13s/it]Model Responding:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 471/875 [1:09:52<1:01:41,  9.16s/it]Model Responding:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 472/875 [1:10:01<1:01:28,  9.15s/it]Model Responding:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 473/875 [1:10:10<1:00:21,  9.01s/it]Model Responding:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 474/875 [1:10:19<59:54,  8.96s/it]  Model Responding:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 475/875 [1:10:28<1:00:01,  9.00s/it]Model Responding:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 476/875 [1:10:36<59:20,  8.92s/it]  Model Responding:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 477/875 [1:10:46<59:46,  9.01s/it]Model Responding:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 478/875 [1:10:55<1:00:23,  9.13s/it]Model Responding:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 479/875 [1:11:04<59:57,  9.08s/it]  Model Responding:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 480/875 [1:11:13<59:14,  9.00s/it]Model Responding:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 481/875 [1:11:22<59:55,  9.13s/it]Model Responding:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 482/875 [1:11:32<1:00:23,  9.22s/it]Model Responding:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 483/875 [1:11:41<59:44,  9.14s/it]  Model Responding:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 484/875 [1:11:50<59:39,  9.15s/it]Model Responding:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 485/875 [1:11:59<59:55,  9.22s/it]Model Responding:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 486/875 [1:12:08<58:52,  9.08s/it]Model Responding:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 487/875 [1:12:17<58:27,  9.04s/it]Model Responding:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 488/875 [1:12:26<58:43,  9.11s/it]Model Responding:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 489/875 [1:12:35<58:25,  9.08s/it]Model Responding:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 490/875 [1:12:45<58:43,  9.15s/it]Model Responding:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 491/875 [1:12:54<58:24,  9.13s/it]Model Responding:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 492/875 [1:13:03<58:00,  9.09s/it]Model Responding:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 493/875 [1:13:11<57:13,  8.99s/it]Model Responding:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 494/875 [1:13:20<56:31,  8.90s/it]Model Responding:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 495/875 [1:13:29<55:54,  8.83s/it]Model Responding:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 496/875 [1:13:37<55:23,  8.77s/it]Model Responding:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 497/875 [1:13:46<55:33,  8.82s/it]Model Responding:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 498/875 [1:13:55<54:36,  8.69s/it]Model Responding:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 499/875 [1:14:04<55:23,  8.84s/it]Model Responding:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 500/875 [1:14:13<56:38,  9.06s/it]Model Responding:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 501/875 [1:14:23<57:19,  9.20s/it]Model Responding:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 502/875 [1:14:31<55:43,  8.96s/it]Model Responding:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 503/875 [1:14:41<56:00,  9.03s/it]Model Responding:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 504/875 [1:14:50<56:26,  9.13s/it]Model Responding:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 505/875 [1:14:59<56:50,  9.22s/it]Model Responding:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 506/875 [1:15:09<56:41,  9.22s/it]Model Responding:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 507/875 [1:15:18<56:38,  9.24s/it]Model Responding:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 508/875 [1:15:28<57:17,  9.37s/it]Model Responding:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 509/875 [1:15:37<57:02,  9.35s/it]Model Responding:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 510/875 [1:15:46<57:23,  9.43s/it]Model Responding:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 511/875 [1:15:55<55:52,  9.21s/it]Model Responding:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 512/875 [1:16:04<55:11,  9.12s/it]Model Responding:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 513/875 [1:16:12<53:42,  8.90s/it]Model Responding:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 514/875 [1:16:21<53:22,  8.87s/it]Model Responding:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 515/875 [1:16:30<53:01,  8.84s/it]Model Responding:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 516/875 [1:16:39<53:37,  8.96s/it]Model Responding:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 517/875 [1:16:48<53:50,  9.02s/it]Model Responding:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 518/875 [1:16:57<53:06,  8.92s/it]Model Responding:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 519/875 [1:17:06<53:15,  8.97s/it]Model Responding:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 520/875 [1:17:15<52:50,  8.93s/it]Model Responding:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 521/875 [1:17:23<50:53,  8.63s/it]Model Responding:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 522/875 [1:17:32<50:55,  8.66s/it]Model Responding:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 523/875 [1:17:41<51:22,  8.76s/it]Model Responding:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 524/875 [1:17:50<51:50,  8.86s/it]Model Responding:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 525/875 [1:17:59<53:09,  9.11s/it]Model Responding:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 526/875 [1:18:08<52:26,  9.02s/it]Model Responding:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 527/875 [1:18:18<52:41,  9.08s/it]Model Responding:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 528/875 [1:18:27<52:27,  9.07s/it]Model Responding:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 529/875 [1:18:36<52:06,  9.03s/it]Model Responding:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 530/875 [1:18:44<51:47,  9.01s/it]Model Responding:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 531/875 [1:18:54<52:27,  9.15s/it]Model Responding:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 532/875 [1:19:03<51:58,  9.09s/it]Model Responding:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 533/875 [1:19:12<51:09,  8.97s/it]Model Responding:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 534/875 [1:19:20<50:30,  8.89s/it]Model Responding:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 535/875 [1:19:30<51:20,  9.06s/it]Model Responding:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 536/875 [1:19:39<51:57,  9.20s/it]Model Responding:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 537/875 [1:19:48<51:08,  9.08s/it]Model Responding:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 538/875 [1:19:57<50:48,  9.05s/it]Model Responding:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 539/875 [1:20:05<49:24,  8.82s/it]Model Responding:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 540/875 [1:20:14<49:27,  8.86s/it]Model Responding:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 541/875 [1:20:24<50:15,  9.03s/it]Model Responding:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 542/875 [1:20:33<50:30,  9.10s/it]Model Responding:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 543/875 [1:20:41<48:43,  8.80s/it]Model Responding:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 544/875 [1:20:50<48:08,  8.73s/it]Model Responding:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 545/875 [1:20:58<47:32,  8.64s/it]Model Responding:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 546/875 [1:21:06<46:48,  8.54s/it]Model Responding:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 547/875 [1:21:15<46:12,  8.45s/it]Model Responding:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 548/875 [1:21:23<45:57,  8.43s/it]Model Responding:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 549/875 [1:21:32<46:52,  8.63s/it]Model Responding:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 550/875 [1:21:40<45:44,  8.44s/it]Model Responding:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 551/875 [1:21:49<45:49,  8.49s/it]Model Responding:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 552/875 [1:21:57<45:05,  8.38s/it]Model Responding:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 553/875 [1:22:05<45:14,  8.43s/it]Model Responding:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 554/875 [1:22:13<44:28,  8.31s/it]Model Responding:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 555/875 [1:22:22<44:59,  8.44s/it]Model Responding:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 556/875 [1:22:31<45:49,  8.62s/it]Model Responding:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 557/875 [1:22:41<47:08,  8.90s/it]Model Responding:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 558/875 [1:22:51<48:51,  9.25s/it]Model Responding:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 559/875 [1:23:00<47:55,  9.10s/it]Model Responding:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 560/875 [1:23:08<47:13,  8.99s/it]Model Responding:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 561/875 [1:23:17<46:17,  8.85s/it]Model Responding:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 562/875 [1:23:26<46:17,  8.87s/it]Model Responding:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 563/875 [1:23:34<45:37,  8.77s/it]Model Responding:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 564/875 [1:23:43<45:47,  8.84s/it]Model Responding:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 565/875 [1:23:52<45:55,  8.89s/it]Model Responding:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 566/875 [1:24:02<46:28,  9.03s/it]Model Responding:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 567/875 [1:24:10<45:49,  8.93s/it]Model Responding:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 568/875 [1:24:19<45:14,  8.84s/it]Model Responding:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 569/875 [1:24:27<44:29,  8.73s/it]Model Responding:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 570/875 [1:24:36<44:35,  8.77s/it]Model Responding:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 571/875 [1:24:45<45:04,  8.90s/it]Model Responding:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 572/875 [1:24:56<46:54,  9.29s/it]Model Responding:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 573/875 [1:25:05<47:12,  9.38s/it]Model Responding:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 574/875 [1:25:13<45:19,  9.04s/it]Model Responding:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 575/875 [1:25:22<45:04,  9.01s/it]Model Responding:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 576/875 [1:25:32<45:45,  9.18s/it]Model Responding:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 577/875 [1:25:41<45:15,  9.11s/it]Model Responding:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 578/875 [1:25:50<45:21,  9.16s/it]Model Responding:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 579/875 [1:26:00<46:13,  9.37s/it]Model Responding:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 580/875 [1:26:09<45:43,  9.30s/it]Model Responding:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 581/875 [1:26:19<45:50,  9.36s/it]Model Responding:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 582/875 [1:26:27<44:47,  9.17s/it]Model Responding:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 583/875 [1:26:37<45:06,  9.27s/it]Model Responding:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 584/875 [1:26:46<44:35,  9.19s/it]Model Responding:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 585/875 [1:26:55<44:34,  9.22s/it]Model Responding:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 586/875 [1:27:05<44:44,  9.29s/it]Model Responding:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 587/875 [1:27:14<44:04,  9.18s/it]Model Responding:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 588/875 [1:27:22<43:00,  8.99s/it]Model Responding:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 589/875 [1:27:31<42:43,  8.96s/it]Model Responding:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 590/875 [1:27:40<43:00,  9.05s/it]Model Responding:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 591/875 [1:27:50<43:39,  9.22s/it]Model Responding:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 592/875 [1:27:59<42:46,  9.07s/it]Model Responding:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 593/875 [1:28:08<43:26,  9.24s/it]Model Responding:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 594/875 [1:28:17<42:59,  9.18s/it]Model Responding:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 595/875 [1:28:26<42:14,  9.05s/it]Model Responding:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 596/875 [1:28:36<42:48,  9.21s/it]Model Responding:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 597/875 [1:28:45<42:18,  9.13s/it]Model Responding:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 598/875 [1:28:54<43:02,  9.32s/it]Model Responding:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 599/875 [1:29:03<42:00,  9.13s/it]Model Responding:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 600/875 [1:29:12<41:18,  9.01s/it]Model Responding:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 601/875 [1:29:21<40:43,  8.92s/it]Model Responding:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 602/875 [1:29:29<40:34,  8.92s/it]Model Responding:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 603/875 [1:29:38<40:28,  8.93s/it]Model Responding:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 604/875 [1:29:48<40:42,  9.01s/it]Model Responding:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 605/875 [1:29:57<41:02,  9.12s/it]Model Responding:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 606/875 [1:30:06<41:14,  9.20s/it]Model Responding:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 607/875 [1:30:15<40:32,  9.08s/it]Model Responding:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 608/875 [1:30:24<39:58,  8.98s/it]Model Responding:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 609/875 [1:30:33<40:11,  9.06s/it]Model Responding:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 610/875 [1:30:42<39:55,  9.04s/it]Model Responding:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 611/875 [1:30:52<40:35,  9.23s/it]Model Responding:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 612/875 [1:31:01<40:00,  9.13s/it]Model Responding:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 613/875 [1:31:10<39:46,  9.11s/it]Model Responding:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 614/875 [1:31:19<39:32,  9.09s/it]Model Responding:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 615/875 [1:31:28<39:52,  9.20s/it]Model Responding:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 616/875 [1:31:37<39:18,  9.11s/it]Model Responding:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 617/875 [1:31:46<38:08,  8.87s/it]Model Responding:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 618/875 [1:31:55<38:12,  8.92s/it]Model Responding:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 619/875 [1:32:03<37:17,  8.74s/it]Model Responding:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 620/875 [1:32:12<37:49,  8.90s/it]Model Responding:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 621/875 [1:32:21<37:34,  8.88s/it]Model Responding:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 622/875 [1:32:30<37:47,  8.96s/it]Model Responding:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 623/875 [1:32:39<38:03,  9.06s/it]Model Responding:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 624/875 [1:32:49<38:36,  9.23s/it]Model Responding:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 625/875 [1:32:58<38:31,  9.25s/it]Model Responding:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 626/875 [1:33:07<37:54,  9.13s/it]Model Responding:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 627/875 [1:33:16<37:02,  8.96s/it]Model Responding:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 628/875 [1:33:25<36:55,  8.97s/it]Model Responding:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 629/875 [1:33:34<36:54,  9.00s/it]Model Responding:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 630/875 [1:33:43<37:16,  9.13s/it]Model Responding:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 631/875 [1:33:53<37:21,  9.19s/it]Model Responding:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 632/875 [1:34:01<36:44,  9.07s/it]Model Responding:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 633/875 [1:34:10<36:24,  9.03s/it]Model Responding:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 634/875 [1:34:20<36:44,  9.15s/it]Model Responding:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 635/875 [1:34:29<36:25,  9.11s/it]Model Responding:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 636/875 [1:34:38<36:08,  9.07s/it]Model Responding:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 637/875 [1:34:48<36:58,  9.32s/it]Model Responding:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 638/875 [1:34:56<36:10,  9.16s/it]Model Responding:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 639/875 [1:35:05<34:55,  8.88s/it]Model Responding:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 640/875 [1:35:13<33:50,  8.64s/it]Model Responding:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 641/875 [1:35:21<33:22,  8.56s/it]Model Responding:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 642/875 [1:35:30<34:04,  8.77s/it]Model Responding:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 643/875 [1:35:39<34:05,  8.82s/it]Model Responding:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 644/875 [1:35:48<34:03,  8.85s/it]Model Responding:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 645/875 [1:35:58<35:31,  9.27s/it]Model Responding:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 646/875 [1:36:08<35:41,  9.35s/it]Model Responding:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 647/875 [1:36:17<34:48,  9.16s/it]Model Responding:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 648/875 [1:36:25<33:55,  8.97s/it]Model Responding:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 649/875 [1:36:34<33:25,  8.87s/it]Model Responding:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 650/875 [1:36:42<32:59,  8.80s/it]Model Responding:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 651/875 [1:36:53<34:33,  9.26s/it]Model Responding:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 652/875 [1:37:02<34:41,  9.33s/it]Model Responding:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 653/875 [1:37:12<34:24,  9.30s/it]Model Responding:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 654/875 [1:37:20<33:26,  9.08s/it]Model Responding:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 655/875 [1:37:29<33:12,  9.06s/it]Model Responding:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 656/875 [1:37:38<33:22,  9.14s/it]Model Responding:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 657/875 [1:37:48<33:18,  9.17s/it]Model Responding:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 658/875 [1:37:56<32:18,  8.93s/it]Model Responding:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 659/875 [1:38:05<32:05,  8.92s/it]Model Responding:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 660/875 [1:38:15<32:41,  9.12s/it]Model Responding:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 661/875 [1:38:24<32:50,  9.21s/it]Model Responding:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 662/875 [1:38:33<32:56,  9.28s/it]Model Responding:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 663/875 [1:38:43<32:56,  9.32s/it]Model Responding:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 664/875 [1:38:52<32:28,  9.23s/it]Model Responding:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 665/875 [1:39:01<32:34,  9.31s/it]Model Responding:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 666/875 [1:39:11<32:16,  9.26s/it]Model Responding:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 667/875 [1:39:20<31:53,  9.20s/it]Model Responding:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 668/875 [1:39:29<32:09,  9.32s/it]Model Responding:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 669/875 [1:39:39<32:45,  9.54s/it]Model Responding:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 670/875 [1:39:48<32:01,  9.38s/it]Model Responding:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 671/875 [1:39:57<31:40,  9.31s/it]Model Responding:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 672/875 [1:40:07<31:27,  9.30s/it]Model Responding:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 673/875 [1:40:16<31:10,  9.26s/it]Model Responding:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 674/875 [1:40:25<30:44,  9.17s/it]Model Responding:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 675/875 [1:40:35<31:19,  9.40s/it]Model Responding:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 676/875 [1:40:45<31:59,  9.64s/it]Model Responding:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 677/875 [1:40:55<32:11,  9.76s/it]Model Responding:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 678/875 [1:41:05<32:08,  9.79s/it]Model Responding:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 679/875 [1:41:15<32:01,  9.80s/it]Model Responding:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 680/875 [1:41:24<31:19,  9.64s/it]Model Responding:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 681/875 [1:41:33<30:18,  9.37s/it]Model Responding:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 682/875 [1:41:42<30:21,  9.44s/it]Model Responding:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 683/875 [1:41:52<30:08,  9.42s/it]Model Responding:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 684/875 [1:42:01<29:56,  9.41s/it]Model Responding:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 685/875 [1:42:10<29:36,  9.35s/it]Model Responding:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 686/875 [1:42:19<28:46,  9.14s/it]Model Responding:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 687/875 [1:42:28<28:50,  9.21s/it]Model Responding:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 688/875 [1:42:37<28:33,  9.16s/it]Model Responding:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 689/875 [1:42:47<28:57,  9.34s/it]Model Responding:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 690/875 [1:42:57<29:21,  9.52s/it]Model Responding:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 691/875 [1:43:06<29:08,  9.51s/it]Model Responding:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 692/875 [1:43:16<29:14,  9.59s/it]Model Responding:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 693/875 [1:43:26<28:52,  9.52s/it]Model Responding:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 694/875 [1:43:34<28:06,  9.32s/it]Model Responding:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 695/875 [1:43:44<27:56,  9.31s/it]Model Responding:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 696/875 [1:43:53<27:35,  9.25s/it]Model Responding:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 697/875 [1:44:02<27:13,  9.18s/it]Model Responding:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 698/875 [1:44:11<26:47,  9.08s/it]Model Responding:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 699/875 [1:44:19<26:20,  8.98s/it]Model Responding:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 700/875 [1:44:29<26:24,  9.06s/it]Model Responding:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 701/875 [1:44:37<26:01,  8.97s/it]Model Responding:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 702/875 [1:44:47<26:07,  9.06s/it]Model Responding:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 703/875 [1:44:56<26:05,  9.10s/it]Model Responding:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 704/875 [1:45:05<25:40,  9.01s/it]Model Responding:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 705/875 [1:45:14<25:46,  9.10s/it]Model Responding:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 706/875 [1:45:23<25:43,  9.13s/it]Model Responding:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 707/875 [1:45:33<25:56,  9.27s/it]Model Responding:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 708/875 [1:45:42<26:08,  9.39s/it]Model Responding:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 709/875 [1:45:52<26:08,  9.45s/it]Model Responding:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 710/875 [1:46:02<26:13,  9.54s/it]Model Responding:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 711/875 [1:46:11<26:01,  9.52s/it]Model Responding:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 712/875 [1:46:20<25:16,  9.30s/it]Model Responding:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 713/875 [1:46:30<25:27,  9.43s/it]Model Responding:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 714/875 [1:46:39<25:20,  9.44s/it]Model Responding:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 715/875 [1:46:49<25:13,  9.46s/it]Model Responding:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 716/875 [1:46:57<24:17,  9.16s/it]Model Responding:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 717/875 [1:47:07<24:15,  9.21s/it]Model Responding:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 718/875 [1:47:15<23:43,  9.07s/it]Model Responding:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 719/875 [1:47:24<23:11,  8.92s/it]Model Responding:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 720/875 [1:47:33<22:58,  8.89s/it]Model Responding:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 721/875 [1:47:41<22:36,  8.81s/it]Model Responding:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 722/875 [1:47:50<22:38,  8.88s/it]Model Responding:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 723/875 [1:47:59<22:29,  8.88s/it]Model Responding:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 724/875 [1:48:08<22:11,  8.82s/it]Model Responding:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 725/875 [1:48:17<22:32,  9.02s/it]Model Responding:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 726/875 [1:48:26<22:17,  8.97s/it]Model Responding:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 727/875 [1:48:35<22:16,  9.03s/it]Model Responding:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 728/875 [1:48:45<22:22,  9.14s/it]Model Responding:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 729/875 [1:48:54<22:13,  9.13s/it]Model Responding:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 730/875 [1:49:03<21:57,  9.09s/it]Model Responding:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 731/875 [1:49:13<22:17,  9.29s/it]Model Responding:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 732/875 [1:49:22<22:19,  9.37s/it]Model Responding:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 733/875 [1:49:32<22:24,  9.47s/it]Model Responding:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 734/875 [1:49:42<22:30,  9.58s/it]Model Responding:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 735/875 [1:49:51<22:13,  9.52s/it]Model Responding:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 736/875 [1:50:00<21:50,  9.42s/it]Model Responding:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 737/875 [1:50:09<21:18,  9.27s/it]Model Responding:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 738/875 [1:50:19<21:26,  9.39s/it]Model Responding:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 739/875 [1:50:28<21:22,  9.43s/it]Model Responding:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 740/875 [1:50:38<21:17,  9.46s/it]Model Responding:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 741/875 [1:50:47<20:58,  9.39s/it]Model Responding:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 742/875 [1:50:56<20:09,  9.10s/it]Model Responding:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 743/875 [1:51:05<20:21,  9.25s/it]Model Responding:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 744/875 [1:51:15<20:22,  9.33s/it]Model Responding:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 745/875 [1:51:24<20:09,  9.31s/it]Model Responding:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 746/875 [1:51:33<19:35,  9.11s/it]Model Responding:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 747/875 [1:51:41<18:58,  8.89s/it]Model Responding:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 748/875 [1:51:50<19:03,  9.01s/it]Model Responding:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 749/875 [1:52:00<19:07,  9.10s/it]Model Responding:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 750/875 [1:52:09<19:03,  9.15s/it]Model Responding:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 751/875 [1:52:18<18:45,  9.07s/it]Model Responding:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 752/875 [1:52:27<18:34,  9.06s/it]Model Responding:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 753/875 [1:52:36<18:39,  9.18s/it]Model Responding:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 754/875 [1:52:46<18:51,  9.35s/it]Model Responding:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 755/875 [1:52:56<18:58,  9.48s/it]Model Responding:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 756/875 [1:53:05<18:36,  9.38s/it]Model Responding:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 757/875 [1:53:14<18:27,  9.39s/it]Model Responding:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 758/875 [1:53:23<18:02,  9.26s/it]Model Responding:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 759/875 [1:53:32<17:35,  9.10s/it]Model Responding:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 760/875 [1:53:42<17:41,  9.23s/it]Model Responding:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 761/875 [1:53:51<17:51,  9.40s/it]Model Responding:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 762/875 [1:54:00<17:14,  9.16s/it]Model Responding:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 763/875 [1:54:09<16:59,  9.10s/it]Model Responding:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 764/875 [1:54:18<16:49,  9.09s/it]Model Responding:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 765/875 [1:54:27<16:22,  8.94s/it]Model Responding:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 766/875 [1:54:36<16:25,  9.04s/it]Model Responding:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 767/875 [1:54:45<16:19,  9.07s/it]Model Responding:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 768/875 [1:54:54<16:15,  9.12s/it]Model Responding:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 769/875 [1:55:04<16:11,  9.16s/it]Model Responding:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 770/875 [1:55:13<16:01,  9.15s/it]Model Responding:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 771/875 [1:55:22<15:56,  9.19s/it]Model Responding:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 772/875 [1:55:31<15:53,  9.25s/it]Model Responding:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 773/875 [1:55:41<15:41,  9.23s/it]Model Responding:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 774/875 [1:55:50<15:42,  9.34s/it]Model Responding:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 775/875 [1:55:59<15:26,  9.26s/it]Model Responding:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 776/875 [1:56:08<15:11,  9.21s/it]Model Responding:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 777/875 [1:56:18<15:08,  9.28s/it]Model Responding:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 778/875 [1:56:27<14:51,  9.19s/it]Model Responding:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 779/875 [1:56:37<14:59,  9.37s/it]Model Responding:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 780/875 [1:56:46<15:00,  9.48s/it]Model Responding:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 781/875 [1:56:55<14:43,  9.40s/it]Model Responding:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 782/875 [1:57:05<14:31,  9.38s/it]Model Responding:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 783/875 [1:57:14<14:19,  9.35s/it]Model Responding:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 784/875 [1:57:23<14:06,  9.30s/it]Model Responding:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 785/875 [1:57:32<13:48,  9.20s/it]Model Responding:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 786/875 [1:57:41<13:37,  9.18s/it]Model Responding:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 787/875 [1:57:51<13:36,  9.28s/it]Model Responding:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 788/875 [1:58:00<13:20,  9.20s/it]Model Responding:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 789/875 [1:58:09<13:01,  9.09s/it]Model Responding:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 790/875 [1:58:17<12:43,  8.98s/it]Model Responding:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 791/875 [1:58:27<12:41,  9.07s/it]Model Responding:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 792/875 [1:58:35<12:16,  8.87s/it]Model Responding:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 793/875 [1:58:44<12:12,  8.94s/it]Model Responding:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 794/875 [1:58:53<11:59,  8.89s/it]Model Responding:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 795/875 [1:59:02<11:49,  8.87s/it]Model Responding:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 796/875 [1:59:11<11:48,  8.97s/it]Model Responding:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 797/875 [1:59:20<11:41,  9.00s/it]Model Responding:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 798/875 [1:59:29<11:36,  9.04s/it]Model Responding:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 799/875 [1:59:38<11:17,  8.92s/it]Model Responding:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 800/875 [1:59:47<11:16,  9.02s/it]Model Responding:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 801/875 [1:59:56<11:04,  8.98s/it]Model Responding:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 802/875 [2:00:04<10:40,  8.77s/it]Model Responding:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 803/875 [2:00:14<10:46,  8.98s/it]Model Responding:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 804/875 [2:00:23<10:37,  8.99s/it]Model Responding:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 805/875 [2:00:32<10:31,  9.03s/it]Model Responding:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 806/875 [2:00:42<10:37,  9.24s/it]Model Responding:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 807/875 [2:00:51<10:39,  9.41s/it]Model Responding:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 808/875 [2:01:01<10:26,  9.34s/it]Model Responding:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 809/875 [2:01:10<10:11,  9.27s/it]Model Responding:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 810/875 [2:01:19<10:11,  9.41s/it]Model Responding:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 811/875 [2:01:29<10:08,  9.51s/it]Model Responding:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 812/875 [2:01:39<10:03,  9.58s/it]Model Responding:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 813/875 [2:01:49<10:01,  9.70s/it]Model Responding:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 814/875 [2:01:58<09:40,  9.52s/it]Model Responding:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 815/875 [2:02:08<09:36,  9.60s/it]Model Responding:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 816/875 [2:02:17<09:22,  9.53s/it]Model Responding:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 817/875 [2:02:27<09:11,  9.50s/it]Model Responding:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 818/875 [2:02:36<08:57,  9.42s/it]Model Responding:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 819/875 [2:02:45<08:45,  9.38s/it]Model Responding:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 820/875 [2:02:55<08:37,  9.42s/it]Model Responding:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 821/875 [2:03:04<08:25,  9.36s/it]Model Responding:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 822/875 [2:03:13<08:11,  9.27s/it]Model Responding:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 823/875 [2:03:22<08:06,  9.36s/it]Model Responding:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 824/875 [2:03:31<07:45,  9.13s/it]Model Responding:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 825/875 [2:03:40<07:27,  8.96s/it]Model Responding:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 826/875 [2:03:49<07:21,  9.01s/it]Model Responding:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 827/875 [2:03:58<07:15,  9.07s/it]Model Responding:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 828/875 [2:04:08<07:14,  9.25s/it]Model Responding:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 829/875 [2:04:16<06:58,  9.09s/it]Model Responding:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 830/875 [2:04:26<06:50,  9.12s/it]Model Responding:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 831/875 [2:04:34<06:38,  9.06s/it]Model Responding:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 832/875 [2:04:42<06:14,  8.72s/it]Model Responding:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 833/875 [2:04:52<06:17,  9.00s/it]Model Responding:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 834/875 [2:05:01<06:09,  9.02s/it]Model Responding:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 835/875 [2:05:10<06:02,  9.07s/it]Model Responding:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 836/875 [2:05:19<05:52,  9.04s/it]Model Responding:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 837/875 [2:05:28<05:36,  8.86s/it]Model Responding:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 838/875 [2:05:36<05:19,  8.63s/it]Model Responding:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 839/875 [2:05:45<05:13,  8.70s/it]Model Responding:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 840/875 [2:05:54<05:11,  8.90s/it]Model Responding:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 841/875 [2:06:04<05:11,  9.16s/it]Model Responding:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 842/875 [2:06:13<05:03,  9.20s/it]Model Responding:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 843/875 [2:06:22<04:52,  9.15s/it]Model Responding:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 844/875 [2:06:31<04:39,  9.03s/it]Model Responding:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 845/875 [2:06:40<04:28,  8.96s/it]Model Responding:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 846/875 [2:06:49<04:19,  8.94s/it]Model Responding:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 847/875 [2:06:57<04:09,  8.92s/it]Model Responding:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 848/875 [2:07:06<04:00,  8.92s/it]Model Responding:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 849/875 [2:07:15<03:48,  8.80s/it]Model Responding:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 850/875 [2:07:23<03:36,  8.68s/it]Model Responding:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 851/875 [2:07:32<03:30,  8.78s/it]Model Responding:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 852/875 [2:07:42<03:27,  9.02s/it]Model Responding:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 853/875 [2:07:52<03:23,  9.26s/it]Model Responding:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 854/875 [2:08:01<03:14,  9.25s/it]Model Responding:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 855/875 [2:08:10<03:05,  9.29s/it]Model Responding:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 856/875 [2:08:20<02:58,  9.40s/it]Model Responding:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 857/875 [2:08:29<02:49,  9.42s/it]Model Responding:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 858/875 [2:08:39<02:40,  9.44s/it]Model Responding:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 859/875 [2:08:48<02:30,  9.42s/it]Model Responding:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 860/875 [2:08:57<02:18,  9.25s/it]Model Responding:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 861/875 [2:09:06<02:08,  9.15s/it]Model Responding:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 862/875 [2:09:15<01:59,  9.18s/it]Model Responding:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 863/875 [2:09:24<01:50,  9.18s/it]Model Responding:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 864/875 [2:09:34<01:40,  9.15s/it]Model Responding:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 865/875 [2:09:43<01:32,  9.22s/it]Model Responding:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 866/875 [2:09:52<01:23,  9.26s/it]Model Responding:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 867/875 [2:10:01<01:13,  9.17s/it]Model Responding:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 868/875 [2:10:11<01:06,  9.45s/it]Model Responding:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 869/875 [2:10:21<00:56,  9.40s/it]Model Responding:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 870/875 [2:10:30<00:47,  9.51s/it]Model Responding: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 871/875 [2:10:39<00:37,  9.27s/it]Model Responding: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 872/875 [2:10:49<00:28,  9.44s/it]Model Responding: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 873/875 [2:10:58<00:18,  9.37s/it]Model Responding: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 874/875 [2:11:07<00:09,  9.24s/it]Model Responding: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 875/875 [2:11:16<00:00,  9.20s/it]Model Responding: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 875/875 [2:11:16<00:00,  9.00s/it]
Postprocessing:   0%|          | 0/125 [00:00<?, ?it/s]Postprocessing:   9%|‚ñâ         | 11/125 [00:00<00:01, 99.77it/s]Postprocessing:  17%|‚ñà‚ñã        | 21/125 [00:00<00:01, 98.16it/s]Postprocessing:  26%|‚ñà‚ñà‚ñå       | 32/125 [00:00<00:00, 100.29it/s]Postprocessing:  34%|‚ñà‚ñà‚ñà‚ñç      | 43/125 [00:00<00:00, 97.76it/s] Postprocessing:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 53/125 [00:00<00:00, 94.17it/s]Postprocessing:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 63/125 [00:00<00:00, 95.27it/s]Postprocessing:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 74/125 [00:00<00:00, 98.55it/s]Postprocessing:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 85/125 [00:00<00:00, 100.25it/s]Postprocessing:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 97/125 [00:00<00:00, 101.98it/s]Postprocessing:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 108/125 [00:01<00:00, 98.38it/s]Postprocessing:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 118/125 [00:01<00:00, 96.87it/s]Postprocessing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [00:01<00:00, 97.58it/s]
Postprocessing:   0%|          | 0/750 [00:00<?, ?it/s]Postprocessing:   2%|‚ñè         | 13/750 [00:00<00:05, 127.67it/s]Postprocessing:   3%|‚ñé         | 26/750 [00:00<00:06, 115.31it/s]Postprocessing:   5%|‚ñå         | 38/750 [00:00<00:06, 115.62it/s]Postprocessing:   7%|‚ñã         | 50/750 [00:00<00:06, 115.47it/s]Postprocessing:   8%|‚ñä         | 63/750 [00:00<00:05, 116.78it/s]Postprocessing:  10%|‚ñà         | 75/750 [00:00<00:05, 115.99it/s]Postprocessing:  12%|‚ñà‚ñè        | 87/750 [00:00<00:06, 105.27it/s]Postprocessing:  13%|‚ñà‚ñé        | 98/750 [00:00<00:06, 98.06it/s] Postprocessing:  15%|‚ñà‚ñç        | 111/750 [00:01<00:06, 106.24it/s]Postprocessing:  16%|‚ñà‚ñã        | 122/750 [00:01<00:05, 104.78it/s]Postprocessing:  18%|‚ñà‚ñä        | 133/750 [00:01<00:06, 99.00it/s] Postprocessing:  19%|‚ñà‚ñâ        | 144/750 [00:01<00:06, 100.54it/s]Postprocessing:  21%|‚ñà‚ñà        | 155/750 [00:01<00:05, 102.64it/s]Postprocessing:  22%|‚ñà‚ñà‚ñè       | 167/750 [00:01<00:05, 105.50it/s]Postprocessing:  24%|‚ñà‚ñà‚ñé       | 178/750 [00:01<00:05, 103.55it/s]Postprocessing:  25%|‚ñà‚ñà‚ñå       | 189/750 [00:01<00:05, 99.96it/s] Postprocessing:  27%|‚ñà‚ñà‚ñã       | 203/750 [00:01<00:04, 109.61it/s]Postprocessing:  29%|‚ñà‚ñà‚ñä       | 215/750 [00:02<00:05, 103.10it/s]Postprocessing:  30%|‚ñà‚ñà‚ñà       | 228/750 [00:02<00:04, 109.57it/s]Postprocessing:  32%|‚ñà‚ñà‚ñà‚ñè      | 240/750 [00:02<00:04, 110.61it/s]Postprocessing:  34%|‚ñà‚ñà‚ñà‚ñé      | 253/750 [00:02<00:04, 113.53it/s]Postprocessing:  35%|‚ñà‚ñà‚ñà‚ñå      | 265/750 [00:02<00:04, 112.98it/s]Postprocessing:  37%|‚ñà‚ñà‚ñà‚ñã      | 277/750 [00:02<00:04, 109.87it/s]Postprocessing:  39%|‚ñà‚ñà‚ñà‚ñä      | 289/750 [00:02<00:04, 109.65it/s]Postprocessing:  40%|‚ñà‚ñà‚ñà‚ñà      | 301/750 [00:02<00:04, 108.12it/s]Postprocessing:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 314/750 [00:02<00:03, 112.90it/s]Postprocessing:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 326/750 [00:03<00:03, 107.28it/s]Postprocessing:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 337/750 [00:03<00:03, 106.80it/s]Postprocessing:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 348/750 [00:03<00:03, 102.87it/s]Postprocessing:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 359/750 [00:03<00:03, 100.06it/s]Postprocessing:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 370/750 [00:03<00:04, 91.32it/s] Postprocessing:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 381/750 [00:03<00:03, 95.90it/s]Postprocessing:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 391/750 [00:03<00:03, 95.61it/s]Postprocessing:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 402/750 [00:03<00:03, 96.71it/s]Postprocessing:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 413/750 [00:03<00:03, 100.15it/s]Postprocessing:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 424/750 [00:04<00:03, 102.55it/s]Postprocessing:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 435/750 [00:04<00:03, 104.27it/s]Postprocessing:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 448/750 [00:04<00:02, 108.33it/s]Postprocessing:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 459/750 [00:04<00:02, 104.61it/s]Postprocessing:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 471/750 [00:04<00:02, 107.14it/s]Postprocessing:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 482/750 [00:04<00:02, 104.77it/s]Postprocessing:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 494/750 [00:04<00:02, 108.94it/s]Postprocessing:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 506/750 [00:04<00:02, 110.00it/s]Postprocessing:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 518/750 [00:04<00:02, 107.59it/s]Postprocessing:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 529/750 [00:05<00:02, 104.48it/s]Postprocessing:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 541/750 [00:05<00:01, 108.16it/s]Postprocessing:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 554/750 [00:05<00:01, 112.51it/s]Postprocessing:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 566/750 [00:05<00:01, 113.25it/s]Postprocessing:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 578/750 [00:05<00:01, 111.53it/s]Postprocessing:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 592/750 [00:05<00:01, 117.32it/s]Postprocessing:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 604/750 [00:05<00:01, 113.29it/s]Postprocessing:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 616/750 [00:05<00:01, 113.69it/s]Postprocessing:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 628/750 [00:05<00:01, 109.32it/s]Postprocessing:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 641/750 [00:05<00:00, 113.21it/s]Postprocessing:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 654/750 [00:06<00:00, 115.95it/s]Postprocessing:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 666/750 [00:06<00:00, 112.47it/s]Postprocessing:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 679/750 [00:06<00:00, 115.31it/s]Postprocessing:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 691/750 [00:06<00:00, 113.17it/s]Postprocessing:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 703/750 [00:06<00:00, 111.72it/s]Postprocessing:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 715/750 [00:06<00:00, 109.03it/s]Postprocessing:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 726/750 [00:06<00:00, 104.38it/s]Postprocessing:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 739/750 [00:06<00:00, 109.47it/s]Postprocessing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 750/750 [00:06<00:00, 107.53it/s]
[32m2024-12-15 01:14:18.412[0m | [1mINFO    [0m | [36mlmms_eval.loggers.evaluation_tracker[0m:[36msave_results_aggregated[0m:[36m188[0m - [1mSaving results aggregated[0m
[32m2024-12-15 01:14:18.418[0m | [1mINFO    [0m | [36mlmms_eval.loggers.evaluation_tracker[0m:[36msave_results_samples[0m:[36m255[0m - [1mSaving per-sample results for: pope_pop[0m
[32m2024-12-15 01:14:21.340[0m | [1mINFO    [0m | [36mlmms_eval.loggers.evaluation_tracker[0m:[36msave_results_samples[0m:[36m255[0m - [1mSaving per-sample results for: vqav2_val_lite[0m
llava (pretrained=liuhaotian/llava-v1.6-vicuna-7b), gen_kwargs: (), limit: None, num_fewshot: None, batch_size: 1
|    Tasks     |Version|Filter|n-shot|    Metric    |   |Value |   |Stderr|
|--------------|-------|------|-----:|--------------|---|-----:|---|------|
|pope_pop      |Yaml   |none  |     0|pope_accuracy |‚Üë  |0.8777|¬±  |   N/A|
|pope_pop      |Yaml   |none  |     0|pope_f1_score |‚Üë  |0.8651|¬±  |   N/A|
|pope_pop      |Yaml   |none  |     0|pope_precision|‚Üë  |0.9640|¬±  |   N/A|
|pope_pop      |Yaml   |none  |     0|pope_recall   |‚Üë  |0.7847|¬±  |   N/A|
|pope_pop      |Yaml   |none  |     0|pope_yes_ratio|‚Üë  |0.5000|¬±  |   N/A|
|vqav2_val_lite|Yaml   |none  |     0|exact_match   |‚Üë  |0.7514|¬±  |0.0178|

wandb: - 0.025 MB of 0.025 MB uploadedwandb: - 0.025 MB of 0.025 MB uploadedwandb: - 0.025 MB of 0.025 MB uploadedwandb: \ 0.025 MB of 0.025 MB uploadedwandb: \ 0.025 MB of 0.025 MB uploadedwandb: \ 0.025 MB of 0.025 MB uploadedwandb: | 0.038 MB of 0.038 MB uploadedwandb: / 0.038 MB of 0.038 MB uploadedwandb: - 0.038 MB of 0.038 MB uploadedwandb:                                                                                
wandb: | 0.025 MB of 0.025 MB uploadedwandb: | 0.025 MB of 0.025 MB uploadedwandb: üöÄ View run reverse4 at: https://wandb.ai/VLM_Hallucination_Woohyeon/llava1.6_recursive_eval_1126/runs/hh2kqkg5/workspace
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241214_224416-hh2kqkg5/logs
wandb: - 0.032 MB of 0.032 MB uploadedwandb: / 0.025 MB of 0.025 MB uploadedwandb: / 0.025 MB of 0.025 MB uploadedwandb: \ 0.032 MB of 0.032 MB uploadedwandb: - 0.025 MB of 0.038 MB uploadedwandb: - 0.038 MB of 0.038 MB uploadedwandb: \ 0.038 MB of 0.038 MB uploadedwandb: | 0.038 MB of 0.038 MB uploadedwandb:                                                                                
wandb: | 0.032 MB of 0.032 MB uploadedwandb: \ 0.038 MB of 0.038 MB uploadedwandb: | 0.038 MB of 0.038 MB uploadedwandb: / 0.038 MB of 0.038 MB uploadedwandb:                                                                                
wandb: üöÄ View run reverse4 at: https://wandb.ai/VLM_Hallucination_Woohyeon/llava1.6_recursive_eval_1126/runs/0jkokywl/workspace
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241214_224416-0jkokywl/logs
wandb: / 0.032 MB of 0.032 MB uploadedwandb: üöÄ View run reverse4 at: https://wandb.ai/VLM_Hallucination_Woohyeon/llava1.6_recursive_eval_1126/runs/mo1yyvo3/workspace
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241214_224416-mo1yyvo3/logs
wandb: - 0.032 MB of 0.032 MB uploadedwandb: \ 0.052 MB of 0.052 MB uploadedwandb: | 0.052 MB of 0.052 MB uploadedwandb: / 0.052 MB of 0.052 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:            pope_pop/pope_accuracy ‚ñÅ
wandb:            pope_pop/pope_f1_score ‚ñÅ
wandb:           pope_pop/pope_precision ‚ñÅ
wandb:              pope_pop/pope_recall ‚ñÅ
wandb:           pope_pop/pope_yes_ratio ‚ñÅ
wandb:        vqav2_val_lite/exact_match ‚ñÅ
wandb: vqav2_val_lite/exact_match_stderr ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    pope_pop/alias pope_pop
wandb:            pope_pop/pope_accuracy 0.87767
wandb:     pope_pop/pope_accuracy_stderr N/A
wandb:            pope_pop/pope_f1_score 0.86512
wandb:     pope_pop/pope_f1_score_stderr N/A
wandb:           pope_pop/pope_precision 0.96396
wandb:    pope_pop/pope_precision_stderr N/A
wandb:              pope_pop/pope_recall 0.78467
wandb:       pope_pop/pope_recall_stderr N/A
wandb:           pope_pop/pope_yes_ratio 0.5
wandb:    pope_pop/pope_yes_ratio_stderr N/A
wandb:              vqav2_val_lite/alias vqav2_val_lite
wandb:        vqav2_val_lite/exact_match 0.7514
wandb: vqav2_val_lite/exact_match_stderr 0.01784
wandb: 
wandb: üöÄ View run reverse4 at: https://wandb.ai/VLM_Hallucination_Woohyeon/llava1.6_recursive_eval_1126/runs/wwrne0gc/workspace
wandb: Synced 6 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241214_224416-wwrne0gc/logs
[rank0]:[W1215 01:14:36.895182487 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
The following values were not passed to `accelerate launch` and had defaults used instead:
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--num_machines` was set to a value of `1`
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
wandb: Currently logged in as: wjk9904 (VLM_Hallucination_Woohyeon). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: wjk9904 (VLM_Hallucination_Woohyeon). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: wjk9904 (VLM_Hallucination_Woohyeon). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: wjk9904 (VLM_Hallucination_Woohyeon). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.19.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.5
wandb: Run data is saved locally in /workspace/vlm/lmms-reverse/wandb/run-20241215_011446-t2hfeylq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run reverse5
wandb: ‚≠êÔ∏è View project at https://wandb.ai/VLM_Hallucination_Woohyeon/llava1.6_recursive_eval_1126
wandb: üöÄ View run at https://wandb.ai/VLM_Hallucination_Woohyeon/llava1.6_recursive_eval_1126/runs/t2hfeylq/workspace
wandb: wandb version 0.19.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.5
wandb: Run data is saved locally in /workspace/vlm/lmms-reverse/wandb/run-20241215_011446-brkeys1n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run reverse5
wandb: ‚≠êÔ∏è View project at https://wandb.ai/VLM_Hallucination_Woohyeon/llava1.6_recursive_eval_1126
wandb: üöÄ View run at https://wandb.ai/VLM_Hallucination_Woohyeon/llava1.6_recursive_eval_1126/runs/brkeys1n/workspace
wandb: wandb version 0.19.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.5
wandb: Run data is saved locally in /workspace/vlm/lmms-reverse/wandb/run-20241215_011446-jnbdom7z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run reverse5
wandb: ‚≠êÔ∏è View project at https://wandb.ai/VLM_Hallucination_Woohyeon/llava1.6_recursive_eval_1126
wandb: üöÄ View run at https://wandb.ai/VLM_Hallucination_Woohyeon/llava1.6_recursive_eval_1126/runs/jnbdom7z/workspace
[32m2024-12-15 01:14:49.058[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate[0m:[36m420[0m - [1mVerbosity set to DEBUG[0m
wandb: wandb version 0.19.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.5
wandb: Run data is saved locally in /workspace/vlm/lmms-reverse/wandb/run-20241215_011446-6glipbd9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run reverse5
wandb: ‚≠êÔ∏è View project at https://wandb.ai/VLM_Hallucination_Woohyeon/llava1.6_recursive_eval_1126
wandb: üöÄ View run at https://wandb.ai/VLM_Hallucination_Woohyeon/llava1.6_recursive_eval_1126/runs/6glipbd9/workspace
[32m2024-12-15 01:14:49.108[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate[0m:[36m420[0m - [1mVerbosity set to DEBUG[0m
[32m2024-12-15 01:14:49.149[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate[0m:[36m420[0m - [1mVerbosity set to DEBUG[0m
[32m2024-12-15 01:14:49.175[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate[0m:[36m420[0m - [1mVerbosity set to DEBUG[0m
[32m2024-12-15 01:14:54.933[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.tasks[0m:[36m_get_task_and_group[0m:[36m452[0m - [34m[1m`group` and `group_alias` keys in tasks' configs will no longer be used in the next release of lmms-eval. `tag` will be used to allow to call a collection of tasks just like `group`. `group` will be removed in order to not cause confusion with the new ConfigurableGroup which will be the offical way to create groups with addition of group-wide configuations.[0m
[32m2024-12-15 01:14:55.701[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m503[0m - [1mEvaluation tracker args: {'output_path': './logs/'}[0m
[32m2024-12-15 01:14:55.702[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m592[0m - [1mSelected Tasks: ['pope_pop', 'vqav2_val_lite'][0m
[32m2024-12-15 01:14:55.704[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36msimple_evaluate[0m:[36m155[0m - [1mSetting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234[0m
[32m2024-12-15 01:14:56.159[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.tasks[0m:[36m_get_task_and_group[0m:[36m452[0m - [34m[1m`group` and `group_alias` keys in tasks' configs will no longer be used in the next release of lmms-eval. `tag` will be used to allow to call a collection of tasks just like `group`. `group` will be removed in order to not cause confusion with the new ConfigurableGroup which will be the offical way to create groups with addition of group-wide configuations.[0m
[32m2024-12-15 01:14:56.240[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.tasks[0m:[36m_get_task_and_group[0m:[36m452[0m - [34m[1m`group` and `group_alias` keys in tasks' configs will no longer be used in the next release of lmms-eval. `tag` will be used to allow to call a collection of tasks just like `group`. `group` will be removed in order to not cause confusion with the new ConfigurableGroup which will be the offical way to create groups with addition of group-wide configuations.[0m
[32m2024-12-15 01:14:56.329[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.tasks[0m:[36m_get_task_and_group[0m:[36m452[0m - [34m[1m`group` and `group_alias` keys in tasks' configs will no longer be used in the next release of lmms-eval. `tag` will be used to allow to call a collection of tasks just like `group`. `group` will be removed in order to not cause confusion with the new ConfigurableGroup which will be the offical way to create groups with addition of group-wide configuations.[0m
[32m2024-12-15 01:14:56.896[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m503[0m - [1mEvaluation tracker args: {'output_path': './logs/'}[0m
[32m2024-12-15 01:14:56.897[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m592[0m - [1mSelected Tasks: ['pope_pop', 'vqav2_val_lite'][0m
[32m2024-12-15 01:14:56.899[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36msimple_evaluate[0m:[36m155[0m - [1mSetting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234[0m
[32m2024-12-15 01:14:56.991[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m503[0m - [1mEvaluation tracker args: {'output_path': './logs/'}[0m
[32m2024-12-15 01:14:56.993[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m592[0m - [1mSelected Tasks: ['pope_pop', 'vqav2_val_lite'][0m
[32m2024-12-15 01:14:56.999[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36msimple_evaluate[0m:[36m155[0m - [1mSetting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234[0m
[32m2024-12-15 01:14:57.085[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m503[0m - [1mEvaluation tracker args: {'output_path': './logs/'}[0m
[32m2024-12-15 01:14:57.087[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m592[0m - [1mSelected Tasks: ['pope_pop', 'vqav2_val_lite'][0m
[32m2024-12-15 01:14:57.090[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36msimple_evaluate[0m:[36m155[0m - [1mSetting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234[0m
initialize llava model with modification
initialize llava model with modification
OpenCLIP not installed
initialize llava model with modification
OpenCLIP not installed
initialize llava model with modification
OpenCLIP not installed
self.merging= None
model_name: llava-v1.6-vicuna-7b
Rank 0:  Loaded LLaVA model: liuhaotian/llava-v1.6-vicuna-7b
loding from here
self.merging= None
model_name: llava-v1.6-vicuna-7b
loding from here
OpenCLIP not installed
self.merging= None
model_name: llava-v1.6-vicuna-7b
loding from here
self.merging= None
model_name: llava-v1.6-vicuna-7b
loding from here
You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
Rank 0:  Loading vision tower: openai/clip-vit-large-patch14-336
You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:06<00:12,  6.06s/it]Loading checkpoint shards:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:05<00:11,  5.91s/it]Loading checkpoint shards:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:05<00:11,  5.70s/it]Loading checkpoint shards:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:06<00:12,  6.48s/it]Loading checkpoint shards:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:11<00:05,  5.50s/it]Loading checkpoint shards:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:11<00:05,  5.82s/it]Loading checkpoint shards:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:11<00:05,  5.88s/it]Loading checkpoint shards:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:12<00:06,  6.13s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:15<00:00,  5.20s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:15<00:00,  5.30s/it]
Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:16<00:00,  5.36s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:16<00:00,  5.51s/it]
device: cuda:0
generation_type: recursion
fix_grid: 2x2
attention_thresholding_type: layer_mean_topk
attention_norm: None
attention_threshold: [0.7,0.8,0.9]
detection_strategy: None
detection_threshold: 0.8
save_output: False
save_output_csv_path: generation_output.csv
target_token_selection_strategy: first
stages: [1, 0, -1, -2]device: cuda:0
positional_embedding_type: bilinear_interpolation
visualize_heatmap: False

square: 1generation_type: recursion

remove unpadding=True, change to 'spatial'
fix_grid: 2x2
attention_thresholding_type: layer_mean_topk
change positional embedding to bilinear_interpolationattention_norm: None

attention_threshold: [0.7,0.8,0.9]
detection_strategy: None
detection_threshold: 0.8
save_output: False
save_output_csv_path: generation_output.csv
target_token_selection_strategy: first
stages: [1, 0, -1, -2]
positional_embedding_type: bilinear_interpolation
visualize_heatmap: False
square: 1
remove unpadding=True, change to 'spatial'
change positional embedding to bilinear_interpolation
Bilienar interpolation embedding type.
Bilienar interpolation embedding type.
Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:17<00:00,  5.57s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:16<00:00,  5.57s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:17<00:00,  5.76s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:16<00:00,  5.66s/it]

device: cuda:0
generation_type: recursion
fix_grid: 2x2
attention_thresholding_type: layer_mean_topk
attention_norm: None
attention_threshold: [0.7,0.8,0.9]
detection_strategy: None
detection_threshold: 0.8
save_output: False
save_output_csv_path: generation_output.csv
target_token_selection_strategy: first
stages: [1, 0, -1, -2]
positional_embedding_type: bilinear_interpolation
visualize_heatmap: False
square: 1
remove unpadding=True, change to 'spatial'
change positional embedding to bilinear_interpolation
Rank 0:  Model Class: LlavaLlamaForCausalLM
device: cuda:0
generation_type: recursion
fix_grid: 2x2
attention_thresholding_type: layer_mean_topk
attention_norm: None
attention_threshold: [0.7,0.8,0.9]
detection_strategy: None
detection_threshold: 0.8
save_output: False
save_output_csv_path: generation_output.csv
target_token_selection_strategy: first
stages: [1, 0, -1, -2]
positional_embedding_type: bilinear_interpolation
visualize_heatmap: False
square: 1
remove unpadding=True, change to 'spatial'
change positional embedding to bilinear_interpolation
Bilienar interpolation embedding type.
Bilienar interpolation embedding type.
Bilienar interpolation embedding type.
Bilienar interpolation embedding type.
[32m2024-12-15 01:15:26.244[0m | [1mINFO    [0m | [36mlmms_eval.models.llava[0m:[36m__init__[0m:[36m306[0m - [1mUsing 4 devices with data parallelism[0m
[32m2024-12-15 01:15:26.245[0m | [1mINFO    [0m | [36mlmms_eval.evaluator_utils[0m:[36mfrom_taskdict[0m:[36m91[0m - [1mNo metadata found in task config for vqav2_val_lite, using default n_shot=0[0m
[32m2024-12-15 01:15:26.245[0m | [1mINFO    [0m | [36mlmms_eval.evaluator_utils[0m:[36mfrom_taskdict[0m:[36m91[0m - [1mNo metadata found in task config for pope_pop, using default n_shot=0[0m
[32m2024-12-15 01:15:26.245[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.caching.cache[0m:[36mload_from_cache[0m:[36m33[0m - [34m[1mrequests-vqav2_val_lite-0shot-rank0-world_size4-tokenizer is not cached, generating...[0m
[32m2024-12-15 01:15:26.245[0m | [1mINFO    [0m | [36mlmms_eval.api.task[0m:[36mbuild_all_requests[0m:[36m425[0m - [1mBuilding contexts for vqav2_val_lite on rank 0...[0m
Bilienar interpolation embedding type.
  0%|          | 0/125 [00:00<?, ?it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [00:00<00:00, 115431.09it/s]
[32m2024-12-15 01:15:27.433[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m455[0m - [34m[1mTask: vqav2_val_lite; number of requests on this rank: 125[0m
Bilienar interpolation embedding type.
[32m2024-12-15 01:15:27.774[0m | [1mINFO    [0m | [36mlmms_eval.evaluator_utils[0m:[36mfrom_taskdict[0m:[36m91[0m - [1mNo metadata found in task config for vqav2_val_lite, using default n_shot=0[0m
[32m2024-12-15 01:15:27.775[0m | [1mINFO    [0m | [36mlmms_eval.evaluator_utils[0m:[36mfrom_taskdict[0m:[36m91[0m - [1mNo metadata found in task config for pope_pop, using default n_shot=0[0m
[32m2024-12-15 01:15:27.776[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.caching.cache[0m:[36mload_from_cache[0m:[36m33[0m - [34m[1mrequests-vqav2_val_lite-0shot-rank1-world_size4-tokenizer is not cached, generating...[0m
[32m2024-12-15 01:15:27.776[0m | [1mINFO    [0m | [36mlmms_eval.api.task[0m:[36mbuild_all_requests[0m:[36m425[0m - [1mBuilding contexts for vqav2_val_lite on rank 1...[0m
[32m2024-12-15 01:15:27.937[0m | [1mINFO    [0m | [36mlmms_eval.evaluator_utils[0m:[36mfrom_taskdict[0m:[36m91[0m - [1mNo metadata found in task config for vqav2_val_lite, using default n_shot=0[0m
[32m2024-12-15 01:15:27.938[0m | [1mINFO    [0m | [36mlmms_eval.evaluator_utils[0m:[36mfrom_taskdict[0m:[36m91[0m - [1mNo metadata found in task config for pope_pop, using default n_shot=0[0m
[32m2024-12-15 01:15:27.938[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.caching.cache[0m:[36mload_from_cache[0m:[36m33[0m - [34m[1mrequests-vqav2_val_lite-0shot-rank2-world_size4-tokenizer is not cached, generating...[0m
[32m2024-12-15 01:15:27.938[0m | [1mINFO    [0m | [36mlmms_eval.api.task[0m:[36mbuild_all_requests[0m:[36m425[0m - [1mBuilding contexts for vqav2_val_lite on rank 2...[0m
  0%|          | 0/125 [00:00<?, ?it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [00:00<00:00, 103778.31it/s]
[32m2024-12-15 01:15:28.971[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m455[0m - [34m[1mTask: vqav2_val_lite; number of requests on this rank: 125[0m
  0%|          | 0/125 [00:00<?, ?it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [00:00<00:00, 96928.82it/s]
[32m2024-12-15 01:15:29.115[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m455[0m - [34m[1mTask: vqav2_val_lite; number of requests on this rank: 125[0m
[32m2024-12-15 01:15:29.186[0m | [1mINFO    [0m | [36mlmms_eval.evaluator_utils[0m:[36mfrom_taskdict[0m:[36m91[0m - [1mNo metadata found in task config for vqav2_val_lite, using default n_shot=0[0m
[32m2024-12-15 01:15:29.186[0m | [1mINFO    [0m | [36mlmms_eval.evaluator_utils[0m:[36mfrom_taskdict[0m:[36m91[0m - [1mNo metadata found in task config for pope_pop, using default n_shot=0[0m
[32m2024-12-15 01:15:29.187[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.caching.cache[0m:[36mload_from_cache[0m:[36m33[0m - [34m[1mrequests-vqav2_val_lite-0shot-rank3-world_size4-tokenizer is not cached, generating...[0m
[32m2024-12-15 01:15:29.187[0m | [1mINFO    [0m | [36mlmms_eval.api.task[0m:[36mbuild_all_requests[0m:[36m425[0m - [1mBuilding contexts for vqav2_val_lite on rank 3...[0m
  0%|          | 0/125 [00:00<?, ?it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [00:00<00:00, 101448.92it/s]
[32m2024-12-15 01:15:30.366[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m455[0m - [34m[1mTask: vqav2_val_lite; number of requests on this rank: 125[0m
[32m2024-12-15 01:15:38.062[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.caching.cache[0m:[36mload_from_cache[0m:[36m33[0m - [34m[1mrequests-pope_pop-0shot-rank3-world_size4-tokenizer is not cached, generating...[0m
[32m2024-12-15 01:15:38.062[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.caching.cache[0m:[36mload_from_cache[0m:[36m33[0m - [34m[1mrequests-pope_pop-0shot-rank2-world_size4-tokenizer is not cached, generating...[0m
[32m2024-12-15 01:15:38.062[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.caching.cache[0m:[36mload_from_cache[0m:[36m33[0m - [34m[1mrequests-pope_pop-0shot-rank0-world_size4-tokenizer is not cached, generating...[0m
[32m2024-12-15 01:15:38.062[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.caching.cache[0m:[36mload_from_cache[0m:[36m33[0m - [34m[1mrequests-pope_pop-0shot-rank1-world_size4-tokenizer is not cached, generating...[0m
[32m2024-12-15 01:15:38.063[0m | [1mINFO    [0m | [36mlmms_eval.api.task[0m:[36mbuild_all_requests[0m:[36m425[0m - [1mBuilding contexts for pope_pop on rank 3...[0m
[32m2024-12-15 01:15:38.063[0m | [1mINFO    [0m | [36mlmms_eval.api.task[0m:[36mbuild_all_requests[0m:[36m425[0m - [1mBuilding contexts for pope_pop on rank 2...[0m
[32m2024-12-15 01:15:38.063[0m | [1mINFO    [0m | [36mlmms_eval.api.task[0m:[36mbuild_all_requests[0m:[36m425[0m - [1mBuilding contexts for pope_pop on rank 1...[0m
[32m2024-12-15 01:15:38.063[0m | [1mINFO    [0m | [36mlmms_eval.api.task[0m:[36mbuild_all_requests[0m:[36m425[0m - [1mBuilding contexts for pope_pop on rank 0...[0m
  0%|          | 0/750 [00:00<?, ?it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 750/750 [00:00<00:00, 97514.74it/s]
[32m2024-12-15 01:15:45.368[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m455[0m - [34m[1mTask: pope_pop; number of requests on this rank: 750[0m
  0%|          | 0/750 [00:00<?, ?it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 750/750 [00:00<00:00, 106728.91it/s]
[32m2024-12-15 01:15:45.454[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m455[0m - [34m[1mTask: pope_pop; number of requests on this rank: 750[0m
  0%|          | 0/750 [00:00<?, ?it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 750/750 [00:00<00:00, 106411.20it/s]
[32m2024-12-15 01:15:45.497[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m455[0m - [34m[1mTask: pope_pop; number of requests on this rank: 750[0m
  0%|          | 0/750 [00:00<?, ?it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 750/750 [00:00<00:00, 100653.63it/s]
[32m2024-12-15 01:15:45.573[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m455[0m - [34m[1mTask: pope_pop; number of requests on this rank: 750[0m
[32m2024-12-15 01:15:45.574[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m476[0m - [1mRunning generate_until requests[0m
[32m2024-12-15 01:15:45.575[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m476[0m - [1mRunning generate_until requests[0m
[32m2024-12-15 01:15:45.575[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m476[0m - [1mRunning generate_until requests[0m
[32m2024-12-15 01:15:45.575[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m476[0m - [1mRunning generate_until requests[0m
Model Responding:   0%|          | 0/875 [00:00<?, ?it/s]CLIPModel is using CLIPSdpaAttention, but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation="eager"` when loading the model.
CLIPModel is using CLIPSdpaAttention, but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation="eager"` when loading the model.
CLIPModel is using CLIPSdpaAttention, but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation="eager"` when loading the model.
CLIPModel is using CLIPSdpaAttention, but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation="eager"` when loading the model.
LlamaModel is using LlamaSdpaAttention, but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation="eager"` when loading the model.
LlamaModel is using LlamaSdpaAttention, but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation="eager"` when loading the model.
LlamaModel is using LlamaSdpaAttention, but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation="eager"` when loading the model.
LlamaModel is using LlamaSdpaAttention, but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation="eager"` when loading the model.
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
Model Responding:   0%|          | 1/875 [00:09<2:24:52,  9.95s/it]Model Responding:   0%|          | 2/875 [00:18<2:16:31,  9.38s/it]Model Responding:   0%|          | 3/875 [00:27<2:10:16,  8.96s/it]Model Responding:   0%|          | 4/875 [00:35<2:03:06,  8.48s/it]Model Responding:   1%|          | 5/875 [00:43<2:02:08,  8.42s/it]Model Responding:   1%|          | 6/875 [00:51<2:02:17,  8.44s/it]Model Responding:   1%|          | 7/875 [00:59<2:00:18,  8.32s/it]Model Responding:   1%|          | 8/875 [01:08<2:00:41,  8.35s/it]Model Responding:   1%|          | 9/875 [01:16<1:58:05,  8.18s/it]Model Responding:   1%|          | 10/875 [01:25<2:01:11,  8.41s/it]Model Responding:   1%|‚ñè         | 11/875 [01:35<2:08:24,  8.92s/it]Model Responding:   1%|‚ñè         | 12/875 [01:43<2:07:18,  8.85s/it]Model Responding:   1%|‚ñè         | 13/875 [01:52<2:05:36,  8.74s/it]Model Responding:   2%|‚ñè         | 14/875 [02:00<2:03:59,  8.64s/it]Model Responding:   2%|‚ñè         | 15/875 [02:09<2:03:35,  8.62s/it]Model Responding:   2%|‚ñè         | 16/875 [02:18<2:03:54,  8.65s/it]Model Responding:   2%|‚ñè         | 17/875 [02:26<2:02:21,  8.56s/it]Model Responding:   2%|‚ñè         | 18/875 [02:34<2:00:06,  8.41s/it]Model Responding:   2%|‚ñè         | 19/875 [02:42<1:58:35,  8.31s/it]Model Responding:   2%|‚ñè         | 20/875 [02:51<1:59:43,  8.40s/it]Model Responding:   2%|‚ñè         | 21/875 [02:59<1:58:03,  8.29s/it]Model Responding:   3%|‚ñé         | 22/875 [03:07<1:57:14,  8.25s/it]Model Responding:   3%|‚ñé         | 23/875 [03:15<1:58:25,  8.34s/it]Model Responding:   3%|‚ñé         | 24/875 [03:24<2:00:16,  8.48s/it]Model Responding:   3%|‚ñé         | 25/875 [03:33<2:01:54,  8.60s/it]Model Responding:   3%|‚ñé         | 26/875 [03:42<2:02:26,  8.65s/it]Model Responding:   3%|‚ñé         | 27/875 [03:51<2:03:38,  8.75s/it]Model Responding:   3%|‚ñé         | 28/875 [04:00<2:03:09,  8.72s/it]Model Responding:   3%|‚ñé         | 29/875 [04:08<2:02:33,  8.69s/it]Model Responding:   3%|‚ñé         | 30/875 [04:17<2:01:49,  8.65s/it]Model Responding:   4%|‚ñé         | 31/875 [04:25<2:01:38,  8.65s/it]Model Responding:   4%|‚ñé         | 32/875 [04:34<2:01:05,  8.62s/it]Model Responding:   4%|‚ñç         | 33/875 [04:43<2:00:53,  8.61s/it]Model Responding:   4%|‚ñç         | 34/875 [04:51<1:58:05,  8.43s/it]Model Responding:   4%|‚ñç         | 35/875 [04:59<1:56:28,  8.32s/it]Model Responding:   4%|‚ñç         | 36/875 [05:07<1:57:00,  8.37s/it]Model Responding:   4%|‚ñç         | 37/875 [05:15<1:53:46,  8.15s/it]Model Responding:   4%|‚ñç         | 38/875 [05:24<1:56:55,  8.38s/it]Model Responding:   4%|‚ñç         | 39/875 [05:32<1:57:27,  8.43s/it]Model Responding:   5%|‚ñç         | 40/875 [05:41<1:57:16,  8.43s/it]Model Responding:   5%|‚ñç         | 41/875 [05:49<1:58:06,  8.50s/it]Model Responding:   5%|‚ñç         | 42/875 [05:57<1:56:10,  8.37s/it]Model Responding:   5%|‚ñç         | 43/875 [06:06<1:59:18,  8.60s/it]Model Responding:   5%|‚ñå         | 44/875 [06:15<1:58:35,  8.56s/it]Model Responding:   5%|‚ñå         | 45/875 [06:24<2:01:38,  8.79s/it]Model Responding:   5%|‚ñå         | 46/875 [06:32<1:58:56,  8.61s/it]Model Responding:   5%|‚ñå         | 47/875 [06:40<1:56:22,  8.43s/it]Model Responding:   5%|‚ñå         | 48/875 [06:49<1:57:33,  8.53s/it]Model Responding:   6%|‚ñå         | 49/875 [06:58<1:58:39,  8.62s/it]Model Responding:   6%|‚ñå         | 50/875 [07:07<2:00:52,  8.79s/it]Model Responding:   6%|‚ñå         | 51/875 [07:16<2:02:15,  8.90s/it]Model Responding:   6%|‚ñå         | 52/875 [07:25<2:01:06,  8.83s/it]Model Responding:   6%|‚ñå         | 53/875 [07:33<1:59:05,  8.69s/it]Model Responding:   6%|‚ñå         | 54/875 [07:42<1:57:46,  8.61s/it]Model Responding:   6%|‚ñã         | 55/875 [07:51<1:58:14,  8.65s/it]Model Responding:   6%|‚ñã         | 56/875 [08:00<1:59:54,  8.78s/it]Model Responding:   7%|‚ñã         | 57/875 [08:09<2:00:09,  8.81s/it]Model Responding:   7%|‚ñã         | 58/875 [08:18<2:01:12,  8.90s/it]Model Responding:   7%|‚ñã         | 59/875 [08:27<2:01:06,  8.91s/it]Model Responding:   7%|‚ñã         | 60/875 [08:35<1:59:25,  8.79s/it]Model Responding:   7%|‚ñã         | 61/875 [08:43<1:55:47,  8.54s/it]Model Responding:   7%|‚ñã         | 62/875 [08:52<1:55:44,  8.54s/it]Model Responding:   7%|‚ñã         | 63/875 [09:00<1:54:10,  8.44s/it]Model Responding:   7%|‚ñã         | 64/875 [09:08<1:54:51,  8.50s/it]Model Responding:   7%|‚ñã         | 65/875 [09:18<1:59:47,  8.87s/it]Model Responding:   8%|‚ñä         | 66/875 [09:27<1:58:16,  8.77s/it]Model Responding:   8%|‚ñä         | 67/875 [09:35<1:57:01,  8.69s/it]Model Responding:   8%|‚ñä         | 68/875 [09:43<1:54:31,  8.51s/it]Model Responding:   8%|‚ñä         | 69/875 [09:51<1:51:43,  8.32s/it]Model Responding:   8%|‚ñä         | 70/875 [10:00<1:52:05,  8.35s/it]Model Responding:   8%|‚ñä         | 71/875 [10:08<1:53:01,  8.43s/it]Model Responding:   8%|‚ñä         | 72/875 [10:17<1:53:47,  8.50s/it]Model Responding:   8%|‚ñä         | 73/875 [10:26<1:55:36,  8.65s/it]Model Responding:   8%|‚ñä         | 74/875 [10:34<1:54:10,  8.55s/it]Model Responding:   9%|‚ñä         | 75/875 [10:43<1:53:46,  8.53s/it]Model Responding:   9%|‚ñä         | 76/875 [10:51<1:50:47,  8.32s/it]Model Responding:   9%|‚ñâ         | 77/875 [10:59<1:51:45,  8.40s/it]Model Responding:   9%|‚ñâ         | 78/875 [11:08<1:51:26,  8.39s/it]Model Responding:   9%|‚ñâ         | 79/875 [11:16<1:53:03,  8.52s/it]Model Responding:   9%|‚ñâ         | 80/875 [11:25<1:55:26,  8.71s/it]Model Responding:   9%|‚ñâ         | 81/875 [11:34<1:56:07,  8.78s/it]Model Responding:   9%|‚ñâ         | 82/875 [11:44<1:58:22,  8.96s/it]Model Responding:   9%|‚ñâ         | 83/875 [11:53<1:59:50,  9.08s/it]Model Responding:  10%|‚ñâ         | 84/875 [12:02<2:00:27,  9.14s/it]Model Responding:  10%|‚ñâ         | 85/875 [12:12<2:00:10,  9.13s/it]Model Responding:  10%|‚ñâ         | 86/875 [12:20<1:58:22,  9.00s/it]Model Responding:  10%|‚ñâ         | 87/875 [12:29<1:56:36,  8.88s/it]Model Responding:  10%|‚ñà         | 88/875 [12:37<1:54:25,  8.72s/it]Model Responding:  10%|‚ñà         | 89/875 [12:45<1:52:12,  8.57s/it]Model Responding:  10%|‚ñà         | 90/875 [12:54<1:50:48,  8.47s/it]Model Responding:  10%|‚ñà         | 91/875 [13:02<1:48:52,  8.33s/it]Model Responding:  11%|‚ñà         | 92/875 [13:10<1:49:58,  8.43s/it]Model Responding:  11%|‚ñà         | 93/875 [13:20<1:52:52,  8.66s/it]Model Responding:  11%|‚ñà         | 94/875 [13:28<1:53:50,  8.75s/it]Model Responding:  11%|‚ñà         | 95/875 [13:37<1:54:39,  8.82s/it]Model Responding:  11%|‚ñà         | 96/875 [13:46<1:53:42,  8.76s/it]Model Responding:  11%|‚ñà         | 97/875 [13:55<1:53:30,  8.75s/it]Model Responding:  11%|‚ñà         | 98/875 [14:03<1:51:32,  8.61s/it]Model Responding:  11%|‚ñà‚ñè        | 99/875 [14:11<1:49:04,  8.43s/it]Model Responding:  11%|‚ñà‚ñè        | 100/875 [14:20<1:51:18,  8.62s/it]Model Responding:  12%|‚ñà‚ñè        | 101/875 [14:28<1:49:26,  8.48s/it]Model Responding:  12%|‚ñà‚ñè        | 102/875 [14:37<1:49:22,  8.49s/it]Model Responding:  12%|‚ñà‚ñè        | 103/875 [14:45<1:46:48,  8.30s/it]Model Responding:  12%|‚ñà‚ñè        | 104/875 [14:54<1:48:42,  8.46s/it]Model Responding:  12%|‚ñà‚ñè        | 105/875 [15:02<1:47:12,  8.35s/it]Model Responding:  12%|‚ñà‚ñè        | 106/875 [15:10<1:46:39,  8.32s/it]Model Responding:  12%|‚ñà‚ñè        | 107/875 [15:18<1:45:17,  8.23s/it]Model Responding:  12%|‚ñà‚ñè        | 108/875 [15:26<1:44:43,  8.19s/it]Model Responding:  12%|‚ñà‚ñè        | 109/875 [15:35<1:46:12,  8.32s/it]Model Responding:  13%|‚ñà‚ñé        | 110/875 [15:42<1:44:16,  8.18s/it]Model Responding:  13%|‚ñà‚ñé        | 111/875 [15:51<1:46:38,  8.37s/it]Model Responding:  13%|‚ñà‚ñé        | 112/875 [15:59<1:43:38,  8.15s/it]Model Responding:  13%|‚ñà‚ñé        | 113/875 [16:07<1:44:08,  8.20s/it]Model Responding:  13%|‚ñà‚ñé        | 114/875 [16:16<1:44:49,  8.26s/it]Model Responding:  13%|‚ñà‚ñé        | 115/875 [16:24<1:46:05,  8.38s/it]Model Responding:  13%|‚ñà‚ñé        | 116/875 [16:33<1:47:27,  8.49s/it]Model Responding:  13%|‚ñà‚ñé        | 117/875 [16:42<1:47:32,  8.51s/it]Model Responding:  13%|‚ñà‚ñé        | 118/875 [16:50<1:48:48,  8.62s/it]Model Responding:  14%|‚ñà‚ñé        | 119/875 [16:59<1:48:55,  8.64s/it]Model Responding:  14%|‚ñà‚ñé        | 120/875 [17:07<1:46:35,  8.47s/it]Model Responding:  14%|‚ñà‚ñç        | 121/875 [17:15<1:44:39,  8.33s/it]Model Responding:  14%|‚ñà‚ñç        | 122/875 [17:24<1:44:54,  8.36s/it]Model Responding:  14%|‚ñà‚ñç        | 123/875 [17:32<1:44:08,  8.31s/it]Model Responding:  14%|‚ñà‚ñç        | 124/875 [17:41<1:46:30,  8.51s/it]Model Responding:  14%|‚ñà‚ñç        | 125/875 [17:49<1:44:47,  8.38s/it]Model Responding:  14%|‚ñà‚ñç        | 126/875 [17:57<1:43:48,  8.32s/it]Model Responding:  15%|‚ñà‚ñç        | 127/875 [18:06<1:44:03,  8.35s/it]Model Responding:  15%|‚ñà‚ñç        | 128/875 [18:13<1:41:20,  8.14s/it]Model Responding:  15%|‚ñà‚ñç        | 129/875 [18:21<1:41:31,  8.17s/it]Model Responding:  15%|‚ñà‚ñç        | 130/875 [18:30<1:41:30,  8.18s/it]Model Responding:  15%|‚ñà‚ñç        | 131/875 [18:38<1:40:59,  8.14s/it]Model Responding:  15%|‚ñà‚ñå        | 132/875 [18:45<1:39:32,  8.04s/it]Model Responding:  15%|‚ñà‚ñå        | 133/875 [18:54<1:41:55,  8.24s/it]Model Responding:  15%|‚ñà‚ñå        | 134/875 [19:03<1:42:28,  8.30s/it]Model Responding:  15%|‚ñà‚ñå        | 135/875 [19:11<1:43:05,  8.36s/it]Model Responding:  16%|‚ñà‚ñå        | 136/875 [19:19<1:42:36,  8.33s/it]Model Responding:  16%|‚ñà‚ñå        | 137/875 [19:28<1:42:35,  8.34s/it]Model Responding:  16%|‚ñà‚ñå        | 138/875 [19:37<1:44:58,  8.55s/it]Model Responding:  16%|‚ñà‚ñå        | 139/875 [19:45<1:45:07,  8.57s/it]Model Responding:  16%|‚ñà‚ñå        | 140/875 [19:54<1:43:59,  8.49s/it]Model Responding:  16%|‚ñà‚ñå        | 141/875 [20:02<1:43:08,  8.43s/it]Model Responding:  16%|‚ñà‚ñå        | 142/875 [20:10<1:41:57,  8.35s/it]Model Responding:  16%|‚ñà‚ñã        | 143/875 [20:19<1:42:00,  8.36s/it]Model Responding:  16%|‚ñà‚ñã        | 144/875 [20:28<1:45:10,  8.63s/it]Model Responding:  17%|‚ñà‚ñã        | 145/875 [20:36<1:44:20,  8.58s/it]Model Responding:  17%|‚ñà‚ñã        | 146/875 [20:44<1:42:42,  8.45s/it]Model Responding:  17%|‚ñà‚ñã        | 147/875 [20:53<1:41:37,  8.38s/it]Model Responding:  17%|‚ñà‚ñã        | 148/875 [21:02<1:44:09,  8.60s/it]Model Responding:  17%|‚ñà‚ñã        | 149/875 [21:10<1:44:01,  8.60s/it]Model Responding:  17%|‚ñà‚ñã        | 150/875 [21:19<1:43:52,  8.60s/it]Model Responding:  17%|‚ñà‚ñã        | 151/875 [21:28<1:46:12,  8.80s/it]Model Responding:  17%|‚ñà‚ñã        | 152/875 [21:37<1:46:00,  8.80s/it]Model Responding:  17%|‚ñà‚ñã        | 153/875 [21:45<1:42:51,  8.55s/it]Model Responding:  18%|‚ñà‚ñä        | 154/875 [21:53<1:42:18,  8.51s/it]Model Responding:  18%|‚ñà‚ñä        | 155/875 [22:02<1:41:04,  8.42s/it]Model Responding:  18%|‚ñà‚ñä        | 156/875 [22:10<1:39:26,  8.30s/it]Model Responding:  18%|‚ñà‚ñä        | 157/875 [22:18<1:41:23,  8.47s/it]Model Responding:  18%|‚ñà‚ñä        | 158/875 [22:27<1:41:57,  8.53s/it]Model Responding:  18%|‚ñà‚ñä        | 159/875 [22:36<1:42:22,  8.58s/it]Model Responding:  18%|‚ñà‚ñä        | 160/875 [22:44<1:41:34,  8.52s/it]Model Responding:  18%|‚ñà‚ñä        | 161/875 [22:52<1:40:24,  8.44s/it]Model Responding:  19%|‚ñà‚ñä        | 162/875 [23:01<1:38:58,  8.33s/it]Model Responding:  19%|‚ñà‚ñä        | 163/875 [23:09<1:38:24,  8.29s/it]Model Responding:  19%|‚ñà‚ñä        | 164/875 [23:17<1:39:48,  8.42s/it]Model Responding:  19%|‚ñà‚ñâ        | 165/875 [23:26<1:40:36,  8.50s/it]Model Responding:  19%|‚ñà‚ñâ        | 166/875 [23:34<1:37:25,  8.25s/it]Model Responding:  19%|‚ñà‚ñâ        | 167/875 [23:42<1:37:40,  8.28s/it]Model Responding:  19%|‚ñà‚ñâ        | 168/875 [23:50<1:36:11,  8.16s/it]Model Responding:  19%|‚ñà‚ñâ        | 169/875 [23:59<1:39:32,  8.46s/it]Model Responding:  19%|‚ñà‚ñâ        | 170/875 [24:08<1:39:47,  8.49s/it]Model Responding:  20%|‚ñà‚ñâ        | 171/875 [24:17<1:40:50,  8.59s/it]Model Responding:  20%|‚ñà‚ñâ        | 172/875 [24:25<1:40:27,  8.57s/it]Model Responding:  20%|‚ñà‚ñâ        | 173/875 [24:34<1:40:06,  8.56s/it]Model Responding:  20%|‚ñà‚ñâ        | 174/875 [24:41<1:37:15,  8.32s/it]Model Responding:  20%|‚ñà‚ñà        | 175/875 [24:50<1:37:42,  8.37s/it]Model Responding:  20%|‚ñà‚ñà        | 176/875 [24:58<1:36:57,  8.32s/it]Model Responding:  20%|‚ñà‚ñà        | 177/875 [25:06<1:36:14,  8.27s/it]Model Responding:  20%|‚ñà‚ñà        | 178/875 [25:15<1:36:23,  8.30s/it]Model Responding:  20%|‚ñà‚ñà        | 179/875 [25:23<1:36:23,  8.31s/it]Model Responding:  21%|‚ñà‚ñà        | 180/875 [25:31<1:36:39,  8.34s/it]Model Responding:  21%|‚ñà‚ñà        | 181/875 [25:41<1:39:25,  8.60s/it]Model Responding:  21%|‚ñà‚ñà        | 182/875 [25:49<1:39:54,  8.65s/it]Model Responding:  21%|‚ñà‚ñà        | 183/875 [25:58<1:40:00,  8.67s/it]Model Responding:  21%|‚ñà‚ñà        | 184/875 [26:07<1:41:11,  8.79s/it]Model Responding:  21%|‚ñà‚ñà        | 185/875 [26:16<1:39:48,  8.68s/it]Model Responding:  21%|‚ñà‚ñà‚ñè       | 186/875 [26:24<1:38:31,  8.58s/it]Model Responding:  21%|‚ñà‚ñà‚ñè       | 187/875 [26:32<1:37:37,  8.51s/it]Model Responding:  21%|‚ñà‚ñà‚ñè       | 188/875 [26:40<1:36:07,  8.40s/it]Model Responding:  22%|‚ñà‚ñà‚ñè       | 189/875 [26:49<1:35:32,  8.36s/it]Model Responding:  22%|‚ñà‚ñà‚ñè       | 190/875 [26:56<1:33:38,  8.20s/it]Model Responding:  22%|‚ñà‚ñà‚ñè       | 191/875 [27:05<1:33:22,  8.19s/it]Model Responding:  22%|‚ñà‚ñà‚ñè       | 192/875 [27:13<1:34:07,  8.27s/it]Model Responding:  22%|‚ñà‚ñà‚ñè       | 193/875 [27:22<1:37:05,  8.54s/it]Model Responding:  22%|‚ñà‚ñà‚ñè       | 194/875 [27:32<1:39:34,  8.77s/it]Model Responding:  22%|‚ñà‚ñà‚ñè       | 195/875 [27:40<1:38:47,  8.72s/it]Model Responding:  22%|‚ñà‚ñà‚ñè       | 196/875 [27:49<1:38:13,  8.68s/it]Model Responding:  23%|‚ñà‚ñà‚ñé       | 197/875 [27:57<1:36:07,  8.51s/it]Model Responding:  23%|‚ñà‚ñà‚ñé       | 198/875 [28:05<1:34:03,  8.34s/it]Model Responding:  23%|‚ñà‚ñà‚ñé       | 199/875 [28:13<1:32:56,  8.25s/it]Model Responding:  23%|‚ñà‚ñà‚ñé       | 200/875 [28:21<1:32:32,  8.23s/it]Model Responding:  23%|‚ñà‚ñà‚ñé       | 201/875 [28:29<1:32:27,  8.23s/it]Model Responding:  23%|‚ñà‚ñà‚ñé       | 202/875 [28:37<1:31:44,  8.18s/it]Model Responding:  23%|‚ñà‚ñà‚ñé       | 203/875 [28:46<1:31:38,  8.18s/it]Model Responding:  23%|‚ñà‚ñà‚ñé       | 204/875 [28:54<1:31:36,  8.19s/it]Model Responding:  23%|‚ñà‚ñà‚ñé       | 205/875 [29:02<1:30:36,  8.11s/it]Model Responding:  24%|‚ñà‚ñà‚ñé       | 206/875 [29:10<1:30:24,  8.11s/it]Model Responding:  24%|‚ñà‚ñà‚ñé       | 207/875 [29:17<1:28:56,  7.99s/it]Model Responding:  24%|‚ñà‚ñà‚ñç       | 208/875 [29:27<1:33:18,  8.39s/it]Model Responding:  24%|‚ñà‚ñà‚ñç       | 209/875 [29:36<1:34:34,  8.52s/it]Model Responding:  24%|‚ñà‚ñà‚ñç       | 210/875 [29:44<1:33:16,  8.42s/it]Model Responding:  24%|‚ñà‚ñà‚ñç       | 211/875 [29:52<1:32:37,  8.37s/it]Model Responding:  24%|‚ñà‚ñà‚ñç       | 212/875 [30:00<1:32:19,  8.36s/it]Model Responding:  24%|‚ñà‚ñà‚ñç       | 213/875 [30:08<1:30:34,  8.21s/it]Model Responding:  24%|‚ñà‚ñà‚ñç       | 214/875 [30:16<1:30:00,  8.17s/it]Model Responding:  25%|‚ñà‚ñà‚ñç       | 215/875 [30:24<1:29:18,  8.12s/it]Model Responding:  25%|‚ñà‚ñà‚ñç       | 216/875 [30:32<1:28:01,  8.01s/it]Model Responding:  25%|‚ñà‚ñà‚ñç       | 217/875 [30:40<1:28:51,  8.10s/it]Model Responding:  25%|‚ñà‚ñà‚ñç       | 218/875 [30:48<1:27:34,  8.00s/it]Model Responding:  25%|‚ñà‚ñà‚ñå       | 219/875 [30:56<1:28:00,  8.05s/it]Model Responding:  25%|‚ñà‚ñà‚ñå       | 220/875 [31:05<1:29:59,  8.24s/it]Model Responding:  25%|‚ñà‚ñà‚ñå       | 221/875 [31:14<1:30:39,  8.32s/it]Model Responding:  25%|‚ñà‚ñà‚ñå       | 222/875 [31:22<1:31:11,  8.38s/it]Model Responding:  25%|‚ñà‚ñà‚ñå       | 223/875 [31:30<1:31:02,  8.38s/it]Model Responding:  26%|‚ñà‚ñà‚ñå       | 224/875 [31:38<1:29:10,  8.22s/it]Model Responding:  26%|‚ñà‚ñà‚ñå       | 225/875 [31:47<1:30:11,  8.32s/it]Model Responding:  26%|‚ñà‚ñà‚ñå       | 226/875 [31:56<1:33:04,  8.61s/it]Model Responding:  26%|‚ñà‚ñà‚ñå       | 227/875 [32:05<1:34:28,  8.75s/it]Model Responding:  26%|‚ñà‚ñà‚ñå       | 228/875 [32:14<1:35:37,  8.87s/it]Model Responding:  26%|‚ñà‚ñà‚ñå       | 229/875 [32:23<1:35:55,  8.91s/it]Model Responding:  26%|‚ñà‚ñà‚ñã       | 230/875 [32:32<1:34:59,  8.84s/it]Model Responding:  26%|‚ñà‚ñà‚ñã       | 231/875 [32:41<1:34:00,  8.76s/it]Model Responding:  27%|‚ñà‚ñà‚ñã       | 232/875 [32:48<1:30:07,  8.41s/it]Model Responding:  27%|‚ñà‚ñà‚ñã       | 233/875 [32:57<1:30:30,  8.46s/it]Model Responding:  27%|‚ñà‚ñà‚ñã       | 234/875 [33:05<1:30:35,  8.48s/it]Model Responding:  27%|‚ñà‚ñà‚ñã       | 235/875 [33:14<1:29:53,  8.43s/it]Model Responding:  27%|‚ñà‚ñà‚ñã       | 236/875 [33:22<1:30:40,  8.51s/it]Model Responding:  27%|‚ñà‚ñà‚ñã       | 237/875 [33:32<1:33:00,  8.75s/it]Model Responding:  27%|‚ñà‚ñà‚ñã       | 238/875 [33:40<1:32:50,  8.75s/it]Model Responding:  27%|‚ñà‚ñà‚ñã       | 239/875 [33:49<1:30:56,  8.58s/it]Model Responding:  27%|‚ñà‚ñà‚ñã       | 240/875 [33:57<1:30:03,  8.51s/it]Model Responding:  28%|‚ñà‚ñà‚ñä       | 241/875 [34:05<1:29:24,  8.46s/it]Model Responding:  28%|‚ñà‚ñà‚ñä       | 242/875 [34:14<1:29:54,  8.52s/it]Model Responding:  28%|‚ñà‚ñà‚ñä       | 243/875 [34:23<1:30:06,  8.56s/it]Model Responding:  28%|‚ñà‚ñà‚ñä       | 244/875 [34:31<1:29:38,  8.52s/it]Model Responding:  28%|‚ñà‚ñà‚ñä       | 245/875 [34:39<1:28:04,  8.39s/it]Model Responding:  28%|‚ñà‚ñà‚ñä       | 246/875 [34:48<1:28:54,  8.48s/it]Model Responding:  28%|‚ñà‚ñà‚ñä       | 247/875 [34:57<1:30:14,  8.62s/it]Model Responding:  28%|‚ñà‚ñà‚ñä       | 248/875 [35:06<1:31:02,  8.71s/it]Model Responding:  28%|‚ñà‚ñà‚ñä       | 249/875 [35:14<1:30:46,  8.70s/it]Model Responding:  29%|‚ñà‚ñà‚ñä       | 250/875 [35:23<1:30:38,  8.70s/it]Model Responding:  29%|‚ñà‚ñà‚ñä       | 251/875 [35:32<1:31:14,  8.77s/it]Model Responding:  29%|‚ñà‚ñà‚ñâ       | 252/875 [35:40<1:29:14,  8.59s/it]Model Responding:  29%|‚ñà‚ñà‚ñâ       | 253/875 [35:49<1:30:03,  8.69s/it]Model Responding:  29%|‚ñà‚ñà‚ñâ       | 254/875 [35:58<1:32:20,  8.92s/it]Model Responding:  29%|‚ñà‚ñà‚ñâ       | 255/875 [36:07<1:29:59,  8.71s/it]Model Responding:  29%|‚ñà‚ñà‚ñâ       | 256/875 [36:15<1:28:38,  8.59s/it]Model Responding:  29%|‚ñà‚ñà‚ñâ       | 257/875 [36:23<1:27:40,  8.51s/it]Model Responding:  29%|‚ñà‚ñà‚ñâ       | 258/875 [36:32<1:27:13,  8.48s/it]Model Responding:  30%|‚ñà‚ñà‚ñâ       | 259/875 [36:40<1:26:13,  8.40s/it]Model Responding:  30%|‚ñà‚ñà‚ñâ       | 260/875 [36:48<1:24:44,  8.27s/it]Model Responding:  30%|‚ñà‚ñà‚ñâ       | 261/875 [36:56<1:24:01,  8.21s/it]Model Responding:  30%|‚ñà‚ñà‚ñâ       | 262/875 [37:04<1:23:46,  8.20s/it]Model Responding:  30%|‚ñà‚ñà‚ñà       | 263/875 [37:12<1:23:46,  8.21s/it]Model Responding:  30%|‚ñà‚ñà‚ñà       | 264/875 [37:21<1:25:29,  8.40s/it]Model Responding:  30%|‚ñà‚ñà‚ñà       | 265/875 [37:30<1:25:57,  8.45s/it]Model Responding:  30%|‚ñà‚ñà‚ñà       | 266/875 [37:38<1:25:57,  8.47s/it]Model Responding:  31%|‚ñà‚ñà‚ñà       | 267/875 [37:47<1:25:16,  8.42s/it]Model Responding:  31%|‚ñà‚ñà‚ñà       | 268/875 [37:54<1:23:19,  8.24s/it]Model Responding:  31%|‚ñà‚ñà‚ñà       | 269/875 [38:03<1:23:44,  8.29s/it]Model Responding:  31%|‚ñà‚ñà‚ñà       | 270/875 [38:11<1:24:06,  8.34s/it]Model Responding:  31%|‚ñà‚ñà‚ñà       | 271/875 [38:20<1:24:34,  8.40s/it]Model Responding:  31%|‚ñà‚ñà‚ñà       | 272/875 [38:27<1:21:42,  8.13s/it]Model Responding:  31%|‚ñà‚ñà‚ñà       | 273/875 [38:35<1:21:25,  8.12s/it]Model Responding:  31%|‚ñà‚ñà‚ñà‚ñè      | 274/875 [38:43<1:20:28,  8.03s/it]Model Responding:  31%|‚ñà‚ñà‚ñà‚ñè      | 275/875 [38:51<1:20:47,  8.08s/it]Model Responding:  32%|‚ñà‚ñà‚ñà‚ñè      | 276/875 [39:00<1:21:21,  8.15s/it]Model Responding:  32%|‚ñà‚ñà‚ñà‚ñè      | 277/875 [39:08<1:22:07,  8.24s/it]Model Responding:  32%|‚ñà‚ñà‚ñà‚ñè      | 278/875 [39:17<1:22:32,  8.30s/it]Model Responding:  32%|‚ñà‚ñà‚ñà‚ñè      | 279/875 [39:25<1:22:15,  8.28s/it]Model Responding:  32%|‚ñà‚ñà‚ñà‚ñè      | 280/875 [39:34<1:24:03,  8.48s/it]Model Responding:  32%|‚ñà‚ñà‚ñà‚ñè      | 281/875 [39:43<1:25:10,  8.60s/it]Model Responding:  32%|‚ñà‚ñà‚ñà‚ñè      | 282/875 [39:52<1:26:02,  8.71s/it]Model Responding:  32%|‚ñà‚ñà‚ñà‚ñè      | 283/875 [40:01<1:26:42,  8.79s/it]Model Responding:  32%|‚ñà‚ñà‚ñà‚ñè      | 284/875 [40:10<1:27:37,  8.90s/it]Model Responding:  33%|‚ñà‚ñà‚ñà‚ñé      | 285/875 [40:18<1:26:42,  8.82s/it]Model Responding:  33%|‚ñà‚ñà‚ñà‚ñé      | 286/875 [40:27<1:26:37,  8.82s/it]Model Responding:  33%|‚ñà‚ñà‚ñà‚ñé      | 287/875 [40:36<1:26:05,  8.78s/it]Model Responding:  33%|‚ñà‚ñà‚ñà‚ñé      | 288/875 [40:45<1:26:31,  8.84s/it]Model Responding:  33%|‚ñà‚ñà‚ñà‚ñé      | 289/875 [40:53<1:25:08,  8.72s/it]Model Responding:  33%|‚ñà‚ñà‚ñà‚ñé      | 290/875 [41:02<1:24:50,  8.70s/it]Model Responding:  33%|‚ñà‚ñà‚ñà‚ñé      | 291/875 [41:10<1:23:35,  8.59s/it]Model Responding:  33%|‚ñà‚ñà‚ñà‚ñé      | 292/875 [41:19<1:23:54,  8.64s/it]Model Responding:  33%|‚ñà‚ñà‚ñà‚ñé      | 293/875 [41:28<1:23:29,  8.61s/it]Model Responding:  34%|‚ñà‚ñà‚ñà‚ñé      | 294/875 [41:36<1:23:07,  8.58s/it]Model Responding:  34%|‚ñà‚ñà‚ñà‚ñé      | 295/875 [41:44<1:21:07,  8.39s/it]Model Responding:  34%|‚ñà‚ñà‚ñà‚ñç      | 296/875 [41:52<1:20:03,  8.30s/it]Model Responding:  34%|‚ñà‚ñà‚ñà‚ñç      | 297/875 [42:01<1:20:20,  8.34s/it]Model Responding:  34%|‚ñà‚ñà‚ñà‚ñç      | 298/875 [42:09<1:21:07,  8.44s/it]Model Responding:  34%|‚ñà‚ñà‚ñà‚ñç      | 299/875 [42:19<1:23:24,  8.69s/it]Model Responding:  34%|‚ñà‚ñà‚ñà‚ñç      | 300/875 [42:28<1:24:34,  8.83s/it]Model Responding:  34%|‚ñà‚ñà‚ñà‚ñç      | 301/875 [42:37<1:26:38,  9.06s/it]Model Responding:  35%|‚ñà‚ñà‚ñà‚ñç      | 302/875 [42:46<1:26:39,  9.07s/it]Model Responding:  35%|‚ñà‚ñà‚ñà‚ñç      | 303/875 [42:55<1:25:00,  8.92s/it]Model Responding:  35%|‚ñà‚ñà‚ñà‚ñç      | 304/875 [43:03<1:23:07,  8.74s/it]Model Responding:  35%|‚ñà‚ñà‚ñà‚ñç      | 305/875 [43:11<1:20:27,  8.47s/it]Model Responding:  35%|‚ñà‚ñà‚ñà‚ñç      | 306/875 [43:20<1:22:22,  8.69s/it]Model Responding:  35%|‚ñà‚ñà‚ñà‚ñå      | 307/875 [43:30<1:23:59,  8.87s/it]Model Responding:  35%|‚ñà‚ñà‚ñà‚ñå      | 308/875 [43:39<1:24:42,  8.96s/it]Model Responding:  35%|‚ñà‚ñà‚ñà‚ñå      | 309/875 [43:47<1:22:28,  8.74s/it]Model Responding:  35%|‚ñà‚ñà‚ñà‚ñå      | 310/875 [43:55<1:20:52,  8.59s/it]Model Responding:  36%|‚ñà‚ñà‚ñà‚ñå      | 311/875 [44:04<1:21:07,  8.63s/it]Model Responding:  36%|‚ñà‚ñà‚ñà‚ñå      | 312/875 [44:13<1:21:25,  8.68s/it]Model Responding:  36%|‚ñà‚ñà‚ñà‚ñå      | 313/875 [44:22<1:22:26,  8.80s/it]Model Responding:  36%|‚ñà‚ñà‚ñà‚ñå      | 314/875 [44:31<1:22:00,  8.77s/it]Model Responding:  36%|‚ñà‚ñà‚ñà‚ñå      | 315/875 [44:39<1:22:13,  8.81s/it]Model Responding:  36%|‚ñà‚ñà‚ñà‚ñå      | 316/875 [44:48<1:22:01,  8.80s/it]Model Responding:  36%|‚ñà‚ñà‚ñà‚ñå      | 317/875 [44:56<1:19:48,  8.58s/it]Model Responding:  36%|‚ñà‚ñà‚ñà‚ñã      | 318/875 [45:05<1:19:14,  8.54s/it]Model Responding:  36%|‚ñà‚ñà‚ñà‚ñã      | 319/875 [45:13<1:19:16,  8.55s/it]Model Responding:  37%|‚ñà‚ñà‚ñà‚ñã      | 320/875 [45:22<1:19:12,  8.56s/it]Model Responding:  37%|‚ñà‚ñà‚ñà‚ñã      | 321/875 [45:30<1:18:37,  8.52s/it]Model Responding:  37%|‚ñà‚ñà‚ñà‚ñã      | 322/875 [45:39<1:19:06,  8.58s/it]Model Responding:  37%|‚ñà‚ñà‚ñà‚ñã      | 323/875 [45:47<1:18:27,  8.53s/it]Model Responding:  37%|‚ñà‚ñà‚ñà‚ñã      | 324/875 [45:55<1:16:45,  8.36s/it]Model Responding:  37%|‚ñà‚ñà‚ñà‚ñã      | 325/875 [46:04<1:18:26,  8.56s/it]Model Responding:  37%|‚ñà‚ñà‚ñà‚ñã      | 326/875 [46:13<1:17:09,  8.43s/it]Model Responding:  37%|‚ñà‚ñà‚ñà‚ñã      | 327/875 [46:21<1:17:02,  8.44s/it]Model Responding:  37%|‚ñà‚ñà‚ñà‚ñã      | 328/875 [46:29<1:16:31,  8.39s/it]Model Responding:  38%|‚ñà‚ñà‚ñà‚ñä      | 329/875 [46:37<1:15:19,  8.28s/it]Model Responding:  38%|‚ñà‚ñà‚ñà‚ñä      | 330/875 [46:47<1:18:54,  8.69s/it]Model Responding:  38%|‚ñà‚ñà‚ñà‚ñä      | 331/875 [46:56<1:19:44,  8.80s/it]Model Responding:  38%|‚ñà‚ñà‚ñà‚ñä      | 332/875 [47:04<1:18:25,  8.67s/it]Model Responding:  38%|‚ñà‚ñà‚ñà‚ñä      | 333/875 [47:13<1:16:46,  8.50s/it]Model Responding:  38%|‚ñà‚ñà‚ñà‚ñä      | 334/875 [47:21<1:17:44,  8.62s/it]Model Responding:  38%|‚ñà‚ñà‚ñà‚ñä      | 335/875 [47:31<1:18:53,  8.76s/it]Model Responding:  38%|‚ñà‚ñà‚ñà‚ñä      | 336/875 [47:39<1:17:06,  8.58s/it]Model Responding:  39%|‚ñà‚ñà‚ñà‚ñä      | 337/875 [47:48<1:19:05,  8.82s/it]Model Responding:  39%|‚ñà‚ñà‚ñà‚ñä      | 338/875 [47:56<1:17:40,  8.68s/it]Model Responding:  39%|‚ñà‚ñà‚ñà‚ñä      | 339/875 [48:06<1:19:23,  8.89s/it]Model Responding:  39%|‚ñà‚ñà‚ñà‚ñâ      | 340/875 [48:15<1:20:04,  8.98s/it]Model Responding:  39%|‚ñà‚ñà‚ñà‚ñâ      | 341/875 [48:24<1:20:41,  9.07s/it]Model Responding:  39%|‚ñà‚ñà‚ñà‚ñâ      | 342/875 [48:32<1:17:53,  8.77s/it]Model Responding:  39%|‚ñà‚ñà‚ñà‚ñâ      | 343/875 [48:41<1:18:38,  8.87s/it]Model Responding:  39%|‚ñà‚ñà‚ñà‚ñâ      | 344/875 [48:50<1:17:05,  8.71s/it]Model Responding:  39%|‚ñà‚ñà‚ñà‚ñâ      | 345/875 [48:59<1:18:15,  8.86s/it]Model Responding:  40%|‚ñà‚ñà‚ñà‚ñâ      | 346/875 [49:08<1:19:11,  8.98s/it]Model Responding:  40%|‚ñà‚ñà‚ñà‚ñâ      | 347/875 [49:17<1:18:26,  8.91s/it]Model Responding:  40%|‚ñà‚ñà‚ñà‚ñâ      | 348/875 [49:26<1:18:01,  8.88s/it]Model Responding:  40%|‚ñà‚ñà‚ñà‚ñâ      | 349/875 [49:34<1:16:56,  8.78s/it]Model Responding:  40%|‚ñà‚ñà‚ñà‚ñà      | 350/875 [49:43<1:17:12,  8.82s/it]Model Responding:  40%|‚ñà‚ñà‚ñà‚ñà      | 351/875 [49:52<1:16:09,  8.72s/it]Model Responding:  40%|‚ñà‚ñà‚ñà‚ñà      | 352/875 [50:00<1:14:51,  8.59s/it]Model Responding:  40%|‚ñà‚ñà‚ñà‚ñà      | 353/875 [50:09<1:14:34,  8.57s/it]Model Responding:  40%|‚ñà‚ñà‚ñà‚ñà      | 354/875 [50:17<1:14:53,  8.62s/it]Model Responding:  41%|‚ñà‚ñà‚ñà‚ñà      | 355/875 [50:26<1:14:52,  8.64s/it]Model Responding:  41%|‚ñà‚ñà‚ñà‚ñà      | 356/875 [50:34<1:13:00,  8.44s/it]Model Responding:  41%|‚ñà‚ñà‚ñà‚ñà      | 357/875 [50:42<1:12:25,  8.39s/it]Model Responding:  41%|‚ñà‚ñà‚ñà‚ñà      | 358/875 [50:51<1:12:03,  8.36s/it]Model Responding:  41%|‚ñà‚ñà‚ñà‚ñà      | 359/875 [50:58<1:10:16,  8.17s/it]Model Responding:  41%|‚ñà‚ñà‚ñà‚ñà      | 360/875 [51:07<1:11:40,  8.35s/it]Model Responding:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 361/875 [51:15<1:10:18,  8.21s/it]Model Responding:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 362/875 [51:24<1:12:02,  8.43s/it]Model Responding:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 363/875 [51:32<1:11:09,  8.34s/it]Model Responding:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 364/875 [51:40<1:11:20,  8.38s/it]Model Responding:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 365/875 [51:49<1:11:48,  8.45s/it]Model Responding:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 366/875 [51:57<1:10:15,  8.28s/it]Model Responding:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 367/875 [52:05<1:10:43,  8.35s/it]Model Responding:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 368/875 [52:14<1:11:12,  8.43s/it]Model Responding:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 369/875 [52:23<1:11:33,  8.48s/it]Model Responding:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 370/875 [52:31<1:11:12,  8.46s/it]Model Responding:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 371/875 [52:39<1:10:12,  8.36s/it]Model Responding:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 372/875 [52:48<1:11:22,  8.51s/it]Model Responding:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 373/875 [52:57<1:12:34,  8.67s/it]Model Responding:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 374/875 [53:06<1:11:57,  8.62s/it]Model Responding:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 375/875 [53:14<1:11:37,  8.59s/it]Model Responding:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 376/875 [53:23<1:13:10,  8.80s/it]Model Responding:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 377/875 [53:32<1:12:36,  8.75s/it]Model Responding:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 378/875 [53:41<1:13:27,  8.87s/it]Model Responding:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 379/875 [53:50<1:12:07,  8.72s/it]Model Responding:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 380/875 [53:57<1:09:50,  8.47s/it]Model Responding:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 381/875 [54:06<1:10:31,  8.57s/it]Model Responding:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 382/875 [54:14<1:08:26,  8.33s/it]Model Responding:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 383/875 [54:23<1:08:59,  8.41s/it]Model Responding:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 384/875 [54:31<1:08:56,  8.42s/it]Model Responding:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 385/875 [54:39<1:06:43,  8.17s/it]Model Responding:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 386/875 [54:47<1:06:35,  8.17s/it]Model Responding:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 387/875 [54:55<1:06:56,  8.23s/it]Model Responding:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 388/875 [55:03<1:06:33,  8.20s/it]Model Responding:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 389/875 [55:12<1:06:47,  8.25s/it]Model Responding:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 390/875 [55:20<1:06:48,  8.26s/it]Model Responding:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 391/875 [55:28<1:06:06,  8.20s/it]Model Responding:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 392/875 [55:36<1:05:46,  8.17s/it]Model Responding:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 393/875 [55:44<1:05:44,  8.18s/it]Model Responding:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 394/875 [55:53<1:05:55,  8.22s/it]Model Responding:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 395/875 [56:01<1:06:48,  8.35s/it]Model Responding:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 396/875 [56:10<1:07:39,  8.48s/it]Model Responding:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 397/875 [56:19<1:08:43,  8.63s/it]Model Responding:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 398/875 [56:28<1:08:33,  8.62s/it]Model Responding:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 399/875 [56:36<1:08:14,  8.60s/it]Model Responding:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 400/875 [56:44<1:06:24,  8.39s/it]Model Responding:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 401/875 [56:52<1:05:50,  8.33s/it]Model Responding:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 402/875 [57:01<1:05:23,  8.30s/it]Model Responding:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 403/875 [57:09<1:04:41,  8.22s/it]Model Responding:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 404/875 [57:17<1:05:31,  8.35s/it]Model Responding:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 405/875 [57:25<1:05:08,  8.32s/it]Model Responding:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 406/875 [57:34<1:05:32,  8.39s/it]Model Responding:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 407/875 [57:43<1:06:28,  8.52s/it]Model Responding:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 408/875 [57:52<1:06:44,  8.58s/it]Model Responding:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 409/875 [58:00<1:06:12,  8.52s/it]Model Responding:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 410/875 [58:09<1:06:11,  8.54s/it]Model Responding:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 411/875 [58:17<1:06:26,  8.59s/it]Model Responding:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 412/875 [58:26<1:06:08,  8.57s/it]Model Responding:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 413/875 [58:35<1:06:52,  8.68s/it]Model Responding:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 414/875 [58:43<1:05:44,  8.56s/it]Model Responding:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 415/875 [58:52<1:06:43,  8.70s/it]Model Responding:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 416/875 [59:01<1:06:02,  8.63s/it]Model Responding:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 417/875 [59:09<1:05:25,  8.57s/it]Model Responding:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 418/875 [59:17<1:04:16,  8.44s/it]Model Responding:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 419/875 [59:25<1:03:49,  8.40s/it]Model Responding:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 420/875 [59:34<1:03:04,  8.32s/it]Model Responding:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 421/875 [59:42<1:02:51,  8.31s/it]Model Responding:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 422/875 [59:50<1:03:37,  8.43s/it]Model Responding:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 423/875 [59:59<1:03:54,  8.48s/it]Model Responding:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 424/875 [1:00:08<1:04:30,  8.58s/it]Model Responding:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 425/875 [1:00:16<1:04:12,  8.56s/it]Model Responding:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 426/875 [1:00:26<1:05:48,  8.79s/it]Model Responding:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 427/875 [1:00:34<1:04:54,  8.69s/it]Model Responding:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 428/875 [1:00:43<1:03:56,  8.58s/it]Model Responding:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 429/875 [1:00:51<1:03:17,  8.51s/it]Model Responding:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 430/875 [1:00:59<1:03:15,  8.53s/it]Model Responding:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 431/875 [1:01:08<1:04:11,  8.68s/it]Model Responding:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 432/875 [1:01:17<1:04:20,  8.71s/it]Model Responding:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 433/875 [1:01:26<1:03:21,  8.60s/it]Model Responding:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 434/875 [1:01:34<1:02:54,  8.56s/it]Model Responding:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 435/875 [1:01:42<1:02:17,  8.49s/it]Model Responding:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 436/875 [1:01:51<1:02:38,  8.56s/it]Model Responding:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 437/875 [1:01:59<1:00:47,  8.33s/it]Model Responding:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 438/875 [1:02:08<1:01:11,  8.40s/it]Model Responding:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 439/875 [1:02:16<1:01:30,  8.46s/it]Model Responding:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 440/875 [1:02:25<1:02:00,  8.55s/it]Model Responding:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 441/875 [1:02:34<1:02:19,  8.62s/it]Model Responding:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 442/875 [1:02:42<1:01:28,  8.52s/it]Model Responding:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 443/875 [1:02:50<1:00:52,  8.46s/it]Model Responding:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 444/875 [1:02:59<1:00:53,  8.48s/it]Model Responding:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 445/875 [1:03:07<1:00:18,  8.41s/it]Model Responding:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 446/875 [1:03:15<59:46,  8.36s/it]  Model Responding:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 447/875 [1:03:24<59:31,  8.34s/it]Model Responding:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 448/875 [1:03:33<1:00:47,  8.54s/it]Model Responding:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 449/875 [1:03:42<1:01:34,  8.67s/it]Model Responding:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 450/875 [1:03:51<1:02:51,  8.87s/it]Model Responding:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 451/875 [1:03:59<1:01:51,  8.75s/it]Model Responding:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 452/875 [1:04:08<1:00:46,  8.62s/it]Model Responding:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 453/875 [1:04:16<59:38,  8.48s/it]  Model Responding:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 454/875 [1:04:25<1:00:07,  8.57s/it]Model Responding:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 455/875 [1:04:33<1:00:15,  8.61s/it]Model Responding:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 456/875 [1:04:42<59:51,  8.57s/it]  Model Responding:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 457/875 [1:04:50<59:12,  8.50s/it]Model Responding:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 458/875 [1:04:59<58:51,  8.47s/it]Model Responding:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 459/875 [1:05:07<58:22,  8.42s/it]Model Responding:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 460/875 [1:05:15<57:33,  8.32s/it]Model Responding:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 461/875 [1:05:23<57:13,  8.29s/it]Model Responding:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 462/875 [1:05:31<56:14,  8.17s/it]Model Responding:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 463/875 [1:05:39<56:08,  8.18s/it]Model Responding:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 464/875 [1:05:48<56:47,  8.29s/it]Model Responding:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 465/875 [1:05:56<56:31,  8.27s/it]Model Responding:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 466/875 [1:06:04<56:24,  8.27s/it]Model Responding:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 467/875 [1:06:13<56:44,  8.34s/it]Model Responding:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 468/875 [1:06:21<57:08,  8.42s/it]Model Responding:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 469/875 [1:06:30<57:40,  8.52s/it]Model Responding:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 470/875 [1:06:38<56:47,  8.41s/it]Model Responding:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 471/875 [1:06:47<57:27,  8.53s/it]Model Responding:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 472/875 [1:06:55<56:49,  8.46s/it]Model Responding:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 473/875 [1:07:04<57:02,  8.51s/it]Model Responding:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 474/875 [1:07:12<55:44,  8.34s/it]Model Responding:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 475/875 [1:07:21<55:57,  8.39s/it]Model Responding:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 476/875 [1:07:29<55:01,  8.27s/it]Model Responding:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 477/875 [1:07:37<54:51,  8.27s/it]Model Responding:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 478/875 [1:07:46<56:15,  8.50s/it]Model Responding:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 479/875 [1:07:54<55:49,  8.46s/it]Model Responding:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 480/875 [1:08:03<55:36,  8.45s/it]Model Responding:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 481/875 [1:08:11<55:58,  8.52s/it]Model Responding:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 482/875 [1:08:20<55:57,  8.54s/it]Model Responding:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 483/875 [1:08:28<54:26,  8.33s/it]Model Responding:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 484/875 [1:08:37<55:10,  8.47s/it]Model Responding:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 485/875 [1:08:45<54:51,  8.44s/it]Model Responding:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 486/875 [1:08:53<54:24,  8.39s/it]Model Responding:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 487/875 [1:09:02<54:41,  8.46s/it]Model Responding:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 488/875 [1:09:11<55:32,  8.61s/it]Model Responding:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 489/875 [1:09:20<56:09,  8.73s/it]Model Responding:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 490/875 [1:09:28<55:47,  8.69s/it]Model Responding:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 491/875 [1:09:37<55:07,  8.61s/it]Model Responding:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 492/875 [1:09:45<54:37,  8.56s/it]Model Responding:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 493/875 [1:09:53<53:36,  8.42s/it]Model Responding:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 494/875 [1:10:02<54:40,  8.61s/it]Model Responding:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 495/875 [1:10:12<55:37,  8.78s/it]Model Responding:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 496/875 [1:10:21<56:05,  8.88s/it]Model Responding:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 497/875 [1:10:30<56:05,  8.90s/it]Model Responding:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 498/875 [1:10:39<56:23,  8.98s/it]Model Responding:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 499/875 [1:10:48<56:28,  9.01s/it]Model Responding:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 500/875 [1:10:56<55:25,  8.87s/it]Model Responding:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 501/875 [1:11:05<54:07,  8.68s/it]Model Responding:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 502/875 [1:11:13<53:44,  8.65s/it]Model Responding:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 503/875 [1:11:22<54:05,  8.72s/it]Model Responding:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 504/875 [1:11:31<54:37,  8.83s/it]Model Responding:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 505/875 [1:11:41<55:27,  8.99s/it]Model Responding:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 506/875 [1:11:49<54:56,  8.93s/it]Model Responding:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 507/875 [1:11:58<54:02,  8.81s/it]Model Responding:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 508/875 [1:12:06<52:13,  8.54s/it]Model Responding:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 509/875 [1:12:14<51:01,  8.37s/it]Model Responding:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 510/875 [1:12:22<51:28,  8.46s/it]Model Responding:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 511/875 [1:12:31<52:05,  8.59s/it]Model Responding:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 512/875 [1:12:40<51:17,  8.48s/it]Model Responding:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 513/875 [1:12:48<50:54,  8.44s/it]Model Responding:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 514/875 [1:12:56<50:38,  8.42s/it]Model Responding:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 515/875 [1:13:05<50:58,  8.50s/it]Model Responding:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 516/875 [1:13:14<51:29,  8.61s/it]Model Responding:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 517/875 [1:13:23<51:45,  8.68s/it]Model Responding:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 518/875 [1:13:31<51:24,  8.64s/it]Model Responding:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 519/875 [1:13:39<50:07,  8.45s/it]Model Responding:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 520/875 [1:13:48<50:18,  8.50s/it]Model Responding:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 521/875 [1:13:56<50:20,  8.53s/it]Model Responding:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 522/875 [1:14:04<49:16,  8.38s/it]Model Responding:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 523/875 [1:14:13<49:58,  8.52s/it]Model Responding:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 524/875 [1:14:22<50:51,  8.69s/it]Model Responding:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 525/875 [1:14:31<50:54,  8.73s/it]Model Responding:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 526/875 [1:14:40<51:22,  8.83s/it]Model Responding:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 527/875 [1:14:49<50:43,  8.74s/it]Model Responding:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 528/875 [1:14:58<50:33,  8.74s/it]Model Responding:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 529/875 [1:15:06<50:00,  8.67s/it]Model Responding:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 530/875 [1:15:14<48:59,  8.52s/it]Model Responding:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 531/875 [1:15:24<50:32,  8.82s/it]Model Responding:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 532/875 [1:15:33<50:21,  8.81s/it]Model Responding:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 533/875 [1:15:41<49:31,  8.69s/it]Model Responding:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 534/875 [1:15:50<49:24,  8.69s/it]Model Responding:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 535/875 [1:15:58<49:29,  8.73s/it]Model Responding:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 536/875 [1:16:07<49:08,  8.70s/it]Model Responding:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 537/875 [1:16:16<48:35,  8.62s/it]Model Responding:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 538/875 [1:16:25<49:13,  8.76s/it]Model Responding:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 539/875 [1:16:34<49:17,  8.80s/it]Model Responding:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 540/875 [1:16:42<48:34,  8.70s/it]Model Responding:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 541/875 [1:16:50<47:20,  8.51s/it]Model Responding:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 542/875 [1:16:58<46:51,  8.44s/it]Model Responding:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 543/875 [1:17:07<47:51,  8.65s/it]Model Responding:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 544/875 [1:17:17<48:32,  8.80s/it]Model Responding:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 545/875 [1:17:25<48:03,  8.74s/it]Model Responding:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 546/875 [1:17:34<47:20,  8.63s/it]Model Responding:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 547/875 [1:17:42<47:09,  8.63s/it]Model Responding:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 548/875 [1:17:51<46:59,  8.62s/it]Model Responding:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 549/875 [1:18:00<47:23,  8.72s/it]Model Responding:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 550/875 [1:18:09<47:42,  8.81s/it]Model Responding:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 551/875 [1:18:17<47:06,  8.72s/it]Model Responding:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 552/875 [1:18:26<47:00,  8.73s/it]Model Responding:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 553/875 [1:18:34<45:54,  8.55s/it]Model Responding:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 554/875 [1:18:43<46:47,  8.75s/it]Model Responding:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 555/875 [1:18:52<46:42,  8.76s/it]Model Responding:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 556/875 [1:19:00<45:36,  8.58s/it]Model Responding:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 557/875 [1:19:09<45:43,  8.63s/it]Model Responding:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 558/875 [1:19:18<45:17,  8.57s/it]Model Responding:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 559/875 [1:19:26<44:39,  8.48s/it]Model Responding:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 560/875 [1:19:34<44:35,  8.49s/it]Model Responding:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 561/875 [1:19:43<44:30,  8.50s/it]Model Responding:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 562/875 [1:19:51<44:20,  8.50s/it]Model Responding:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 563/875 [1:20:00<44:11,  8.50s/it]Model Responding:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 564/875 [1:20:10<45:59,  8.87s/it]Model Responding:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 565/875 [1:20:19<46:59,  9.09s/it]Model Responding:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 566/875 [1:20:28<46:25,  9.01s/it]Model Responding:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 567/875 [1:20:36<45:23,  8.84s/it]Model Responding:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 568/875 [1:20:45<44:59,  8.79s/it]Model Responding:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 569/875 [1:20:53<43:35,  8.55s/it]Model Responding:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 570/875 [1:21:01<43:03,  8.47s/it]Model Responding:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 571/875 [1:21:10<43:21,  8.56s/it]Model Responding:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 572/875 [1:21:19<44:15,  8.77s/it]Model Responding:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 573/875 [1:21:28<44:03,  8.75s/it]Model Responding:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 574/875 [1:21:36<42:34,  8.49s/it]Model Responding:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 575/875 [1:21:44<42:26,  8.49s/it]Model Responding:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 576/875 [1:21:53<42:40,  8.56s/it]Model Responding:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 577/875 [1:22:02<43:07,  8.68s/it]Model Responding:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 578/875 [1:22:11<42:43,  8.63s/it]Model Responding:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 579/875 [1:22:19<42:38,  8.64s/it]Model Responding:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 580/875 [1:22:28<42:57,  8.74s/it]Model Responding:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 581/875 [1:22:37<43:19,  8.84s/it]Model Responding:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 582/875 [1:22:46<42:21,  8.68s/it]Model Responding:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 583/875 [1:22:54<42:17,  8.69s/it]Model Responding:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 584/875 [1:23:03<42:22,  8.74s/it]Model Responding:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 585/875 [1:23:12<41:33,  8.60s/it]Model Responding:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 586/875 [1:23:20<41:42,  8.66s/it]Model Responding:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 587/875 [1:23:29<40:57,  8.53s/it]Model Responding:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 588/875 [1:23:37<40:18,  8.43s/it]Model Responding:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 589/875 [1:23:45<40:14,  8.44s/it]Model Responding:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 590/875 [1:23:53<39:32,  8.32s/it]Model Responding:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 591/875 [1:24:02<39:51,  8.42s/it]Model Responding:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 592/875 [1:24:10<39:35,  8.40s/it]Model Responding:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 593/875 [1:24:19<40:09,  8.55s/it]Model Responding:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 594/875 [1:24:28<39:58,  8.53s/it]Model Responding:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 595/875 [1:24:36<39:43,  8.51s/it]Model Responding:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 596/875 [1:24:45<39:34,  8.51s/it]Model Responding:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 597/875 [1:24:53<38:56,  8.41s/it]Model Responding:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 598/875 [1:25:01<38:21,  8.31s/it]Model Responding:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 599/875 [1:25:10<38:48,  8.44s/it]Model Responding:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 600/875 [1:25:18<38:52,  8.48s/it]Model Responding:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 601/875 [1:25:27<39:06,  8.56s/it]Model Responding:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 602/875 [1:25:35<38:56,  8.56s/it]Model Responding:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 603/875 [1:25:44<39:20,  8.68s/it]Model Responding:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 604/875 [1:25:52<37:43,  8.35s/it]Model Responding:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 605/875 [1:26:01<38:07,  8.47s/it]Model Responding:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 606/875 [1:26:09<37:46,  8.43s/it]Model Responding:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 607/875 [1:26:18<37:40,  8.43s/it]Model Responding:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 608/875 [1:26:27<38:23,  8.63s/it]Model Responding:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 609/875 [1:26:35<38:25,  8.67s/it]Model Responding:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 610/875 [1:26:44<38:40,  8.76s/it]Model Responding:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 611/875 [1:26:53<38:09,  8.67s/it]Model Responding:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 612/875 [1:27:01<37:37,  8.59s/it]Model Responding:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 613/875 [1:27:10<37:51,  8.67s/it]Model Responding:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 614/875 [1:27:18<37:04,  8.52s/it]Model Responding:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 615/875 [1:27:27<37:17,  8.61s/it]Model Responding:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 616/875 [1:27:36<37:17,  8.64s/it]Model Responding:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 617/875 [1:27:45<37:30,  8.72s/it]Model Responding:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 618/875 [1:27:53<37:20,  8.72s/it]Model Responding:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 619/875 [1:28:02<36:55,  8.66s/it]Model Responding:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 620/875 [1:28:10<36:16,  8.54s/it]Model Responding:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 621/875 [1:28:18<35:19,  8.35s/it]Model Responding:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 622/875 [1:28:28<36:41,  8.70s/it]Model Responding:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 623/875 [1:28:36<36:28,  8.68s/it]Model Responding:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 624/875 [1:28:45<36:32,  8.73s/it]Model Responding:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 625/875 [1:28:54<36:16,  8.71s/it]Model Responding:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 626/875 [1:29:02<36:09,  8.71s/it]Model Responding:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 627/875 [1:29:11<36:15,  8.77s/it]Model Responding:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 628/875 [1:29:20<36:05,  8.77s/it]Model Responding:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 629/875 [1:29:29<36:35,  8.92s/it]Model Responding:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 630/875 [1:29:38<36:22,  8.91s/it]Model Responding:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 631/875 [1:29:47<35:45,  8.79s/it]Model Responding:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 632/875 [1:29:55<35:21,  8.73s/it]Model Responding:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 633/875 [1:30:04<35:37,  8.83s/it]Model Responding:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 634/875 [1:30:14<35:52,  8.93s/it]Model Responding:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 635/875 [1:30:23<36:18,  9.08s/it]Model Responding:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 636/875 [1:30:32<36:14,  9.10s/it]Model Responding:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 637/875 [1:30:41<35:49,  9.03s/it]Model Responding:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 638/875 [1:30:49<34:46,  8.80s/it]Model Responding:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 639/875 [1:30:58<34:22,  8.74s/it]Model Responding:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 640/875 [1:31:06<33:57,  8.67s/it]Model Responding:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 641/875 [1:31:15<33:31,  8.60s/it]Model Responding:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 642/875 [1:31:24<33:52,  8.72s/it]Model Responding:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 643/875 [1:31:32<33:21,  8.63s/it]Model Responding:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 644/875 [1:31:41<33:14,  8.63s/it]Model Responding:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 645/875 [1:31:50<33:14,  8.67s/it]Model Responding:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 646/875 [1:31:58<32:55,  8.63s/it]Model Responding:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 647/875 [1:32:07<32:51,  8.65s/it]Model Responding:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 648/875 [1:32:16<33:28,  8.85s/it]Model Responding:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 649/875 [1:32:26<34:19,  9.11s/it]Model Responding:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 650/875 [1:32:34<33:21,  8.90s/it]Model Responding:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 651/875 [1:32:43<33:04,  8.86s/it]Model Responding:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 652/875 [1:32:52<32:38,  8.78s/it]Model Responding:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 653/875 [1:33:00<32:22,  8.75s/it]Model Responding:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 654/875 [1:33:09<31:50,  8.65s/it]Model Responding:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 655/875 [1:33:18<31:56,  8.71s/it]Model Responding:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 656/875 [1:33:27<32:11,  8.82s/it]Model Responding:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 657/875 [1:33:36<32:06,  8.84s/it]Model Responding:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 658/875 [1:33:44<30:59,  8.57s/it]Model Responding:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 659/875 [1:33:53<31:43,  8.81s/it]Model Responding:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 660/875 [1:34:02<31:58,  8.92s/it]Model Responding:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 661/875 [1:34:11<31:28,  8.82s/it]Model Responding:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 662/875 [1:34:20<31:32,  8.88s/it]Model Responding:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 663/875 [1:34:29<31:29,  8.91s/it]Model Responding:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 664/875 [1:34:38<31:20,  8.91s/it]Model Responding:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 665/875 [1:34:46<30:57,  8.84s/it]Model Responding:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 666/875 [1:34:56<31:13,  8.96s/it]Model Responding:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 667/875 [1:35:04<30:23,  8.76s/it]Model Responding:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 668/875 [1:35:13<30:08,  8.74s/it]Model Responding:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 669/875 [1:35:21<29:50,  8.69s/it]Model Responding:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 670/875 [1:35:30<29:25,  8.61s/it]Model Responding:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 671/875 [1:35:38<29:14,  8.60s/it]Model Responding:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 672/875 [1:35:47<29:01,  8.58s/it]Model Responding:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 673/875 [1:35:55<29:08,  8.65s/it]Model Responding:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 674/875 [1:36:04<28:36,  8.54s/it]Model Responding:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 675/875 [1:36:13<28:49,  8.65s/it]Model Responding:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 676/875 [1:36:22<29:03,  8.76s/it]Model Responding:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 677/875 [1:36:30<28:39,  8.69s/it]Model Responding:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 678/875 [1:36:39<28:39,  8.73s/it]Model Responding:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 679/875 [1:36:47<28:07,  8.61s/it]Model Responding:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 680/875 [1:36:55<27:30,  8.47s/it]Model Responding:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 681/875 [1:37:04<27:32,  8.52s/it]Model Responding:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 682/875 [1:37:13<27:57,  8.69s/it]Model Responding:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 683/875 [1:37:22<27:48,  8.69s/it]Model Responding:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 684/875 [1:37:30<27:03,  8.50s/it]Model Responding:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 685/875 [1:37:38<26:50,  8.47s/it]Model Responding:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 686/875 [1:37:47<26:49,  8.52s/it]Model Responding:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 687/875 [1:37:55<26:37,  8.50s/it]Model Responding:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 688/875 [1:38:04<26:28,  8.49s/it]Model Responding:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 689/875 [1:38:12<26:10,  8.44s/it]Model Responding:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 690/875 [1:38:21<26:03,  8.45s/it]Model Responding:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 691/875 [1:38:29<25:46,  8.41s/it]Model Responding:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 692/875 [1:38:37<25:07,  8.24s/it]Model Responding:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 693/875 [1:38:45<25:04,  8.27s/it]Model Responding:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 694/875 [1:38:54<24:59,  8.28s/it]Model Responding:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 695/875 [1:39:01<24:24,  8.14s/it]Model Responding:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 696/875 [1:39:10<24:22,  8.17s/it]Model Responding:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 697/875 [1:39:18<24:47,  8.36s/it]Model Responding:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 698/875 [1:39:27<24:44,  8.39s/it]Model Responding:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 699/875 [1:39:35<24:39,  8.41s/it]Model Responding:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 700/875 [1:39:43<24:18,  8.34s/it]Model Responding:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 701/875 [1:39:52<24:09,  8.33s/it]Model Responding:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 702/875 [1:40:01<24:36,  8.54s/it]Model Responding:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 703/875 [1:40:10<24:41,  8.61s/it]Model Responding:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 704/875 [1:40:19<24:53,  8.73s/it]Model Responding:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 705/875 [1:40:27<24:17,  8.58s/it]Model Responding:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 706/875 [1:40:36<24:31,  8.71s/it]Model Responding:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 707/875 [1:40:44<24:10,  8.63s/it]Model Responding:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 708/875 [1:40:53<24:06,  8.66s/it]Model Responding:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 709/875 [1:41:02<24:04,  8.70s/it]Model Responding:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 710/875 [1:41:11<24:11,  8.80s/it]Model Responding:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 711/875 [1:41:20<24:03,  8.80s/it]Model Responding:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 712/875 [1:41:29<24:38,  9.07s/it]Model Responding:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 713/875 [1:41:38<23:52,  8.84s/it]Model Responding:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 714/875 [1:41:47<23:50,  8.88s/it]Model Responding:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 715/875 [1:41:55<23:33,  8.84s/it]Model Responding:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 716/875 [1:42:04<23:31,  8.88s/it]Model Responding:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 717/875 [1:42:13<23:05,  8.77s/it]Model Responding:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 718/875 [1:42:22<23:19,  8.91s/it]Model Responding:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 719/875 [1:42:31<22:54,  8.81s/it]Model Responding:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 720/875 [1:42:39<22:27,  8.70s/it]Model Responding:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 721/875 [1:42:48<22:14,  8.67s/it]Model Responding:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 722/875 [1:42:56<21:54,  8.59s/it]Model Responding:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 723/875 [1:43:04<21:31,  8.50s/it]Model Responding:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 724/875 [1:43:13<21:23,  8.50s/it]Model Responding:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 725/875 [1:43:22<21:49,  8.73s/it]Model Responding:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 726/875 [1:43:31<21:41,  8.74s/it]Model Responding:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 727/875 [1:43:39<21:01,  8.53s/it]Model Responding:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 728/875 [1:43:47<20:53,  8.52s/it]Model Responding:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 729/875 [1:43:56<20:49,  8.56s/it]Model Responding:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 730/875 [1:44:04<20:28,  8.47s/it]Model Responding:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 731/875 [1:44:13<20:30,  8.55s/it]Model Responding:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 732/875 [1:44:22<20:53,  8.76s/it]Model Responding:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 733/875 [1:44:31<20:38,  8.72s/it]Model Responding:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 734/875 [1:44:39<19:46,  8.41s/it]Model Responding:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 735/875 [1:44:47<19:53,  8.53s/it]Model Responding:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 736/875 [1:44:56<19:43,  8.51s/it]Model Responding:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 737/875 [1:45:05<19:42,  8.57s/it]Model Responding:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 738/875 [1:45:13<19:43,  8.64s/it]Model Responding:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 739/875 [1:45:22<19:49,  8.74s/it]Model Responding:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 740/875 [1:45:31<19:44,  8.77s/it]Model Responding:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 741/875 [1:45:40<19:40,  8.81s/it]Model Responding:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 742/875 [1:45:49<19:32,  8.81s/it]Model Responding:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 743/875 [1:45:57<19:09,  8.71s/it]Model Responding:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 744/875 [1:46:05<18:34,  8.51s/it]Model Responding:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 745/875 [1:46:14<18:21,  8.48s/it]Model Responding:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 746/875 [1:46:22<18:07,  8.43s/it]Model Responding:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 747/875 [1:46:31<18:02,  8.46s/it]Model Responding:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 748/875 [1:46:39<17:45,  8.39s/it]Model Responding:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 749/875 [1:46:48<17:42,  8.43s/it]Model Responding:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 750/875 [1:46:56<17:53,  8.59s/it]Model Responding:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 751/875 [1:47:05<17:51,  8.64s/it]Model Responding:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 752/875 [1:47:13<17:18,  8.44s/it]Model Responding:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 753/875 [1:47:23<17:46,  8.74s/it]Model Responding:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 754/875 [1:47:31<17:37,  8.74s/it]Model Responding:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 755/875 [1:47:39<17:03,  8.53s/it]Model Responding:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 756/875 [1:47:48<16:45,  8.45s/it]Model Responding:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 757/875 [1:47:57<16:50,  8.56s/it]Model Responding:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 758/875 [1:48:05<16:42,  8.57s/it]Model Responding:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 759/875 [1:48:13<16:25,  8.50s/it]Model Responding:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 760/875 [1:48:23<17:08,  8.94s/it]Model Responding:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 761/875 [1:48:32<16:49,  8.85s/it]Model Responding:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 762/875 [1:48:41<16:53,  8.97s/it]Model Responding:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 763/875 [1:48:51<17:03,  9.14s/it]Model Responding:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 764/875 [1:48:59<16:30,  8.92s/it]Model Responding:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 765/875 [1:49:08<16:07,  8.79s/it]Model Responding:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 766/875 [1:49:17<16:09,  8.90s/it]Model Responding:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 767/875 [1:49:25<15:49,  8.79s/it]Model Responding:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 768/875 [1:49:35<16:06,  9.03s/it]Model Responding:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 769/875 [1:49:43<15:26,  8.74s/it]Model Responding:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 770/875 [1:49:53<15:42,  8.98s/it]Model Responding:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 771/875 [1:50:02<15:44,  9.08s/it]Model Responding:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 772/875 [1:50:10<15:17,  8.90s/it]Model Responding:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 773/875 [1:50:20<15:33,  9.16s/it]Model Responding:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 774/875 [1:50:29<15:29,  9.21s/it]Model Responding:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 775/875 [1:50:38<15:00,  9.01s/it]Model Responding:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 776/875 [1:50:47<14:47,  8.96s/it]Model Responding:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 777/875 [1:50:55<14:23,  8.81s/it]Model Responding:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 778/875 [1:51:04<14:00,  8.67s/it]Model Responding:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 779/875 [1:51:12<13:38,  8.53s/it]Model Responding:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 780/875 [1:51:21<13:34,  8.57s/it]Model Responding:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 781/875 [1:51:29<13:26,  8.58s/it]Model Responding:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 782/875 [1:51:38<13:21,  8.62s/it]Model Responding:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 783/875 [1:51:46<13:10,  8.60s/it]Model Responding:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 784/875 [1:51:55<13:11,  8.69s/it]Model Responding:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 785/875 [1:52:05<13:17,  8.86s/it]Model Responding:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 786/875 [1:52:13<13:03,  8.81s/it]Model Responding:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 787/875 [1:52:22<12:52,  8.78s/it]Model Responding:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 788/875 [1:52:31<12:58,  8.95s/it]Model Responding:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 789/875 [1:52:40<12:51,  8.97s/it]Model Responding:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 790/875 [1:52:50<12:50,  9.06s/it]Model Responding:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 791/875 [1:52:58<12:31,  8.95s/it]Model Responding:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 792/875 [1:53:07<12:28,  9.02s/it]Model Responding:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 793/875 [1:53:16<12:06,  8.86s/it]Model Responding:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 794/875 [1:53:25<11:56,  8.85s/it]Model Responding:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 795/875 [1:53:34<11:45,  8.82s/it]Model Responding:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 796/875 [1:53:42<11:24,  8.67s/it]Model Responding:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 797/875 [1:53:50<11:10,  8.60s/it]Model Responding:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 798/875 [1:53:59<10:55,  8.51s/it]Model Responding:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 799/875 [1:54:07<10:44,  8.49s/it]Model Responding:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 800/875 [1:54:16<10:41,  8.55s/it]Model Responding:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 801/875 [1:54:25<10:38,  8.63s/it]Model Responding:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 802/875 [1:54:33<10:24,  8.56s/it]Model Responding:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 803/875 [1:54:41<10:10,  8.47s/it]Model Responding:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 804/875 [1:54:50<10:05,  8.53s/it]Model Responding:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 805/875 [1:54:59<10:07,  8.68s/it]Model Responding:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 806/875 [1:55:08<10:00,  8.71s/it]Model Responding:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 807/875 [1:55:16<09:51,  8.70s/it]Model Responding:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 808/875 [1:55:25<09:44,  8.73s/it]Model Responding:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 809/875 [1:55:34<09:29,  8.63s/it]Model Responding:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 810/875 [1:55:42<09:16,  8.56s/it]Model Responding:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 811/875 [1:55:50<09:03,  8.49s/it]Model Responding:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 812/875 [1:55:59<08:50,  8.41s/it]Model Responding:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 813/875 [1:56:07<08:43,  8.45s/it]Model Responding:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 814/875 [1:56:15<08:34,  8.43s/it]Model Responding:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 815/875 [1:56:24<08:24,  8.41s/it]Model Responding:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 816/875 [1:56:33<08:30,  8.66s/it]Model Responding:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 817/875 [1:56:41<08:18,  8.60s/it]Model Responding:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 818/875 [1:56:50<08:10,  8.61s/it]Model Responding:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 819/875 [1:56:59<08:08,  8.73s/it]Model Responding:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 820/875 [1:57:08<08:01,  8.75s/it]Model Responding:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 821/875 [1:57:17<07:55,  8.80s/it]Model Responding:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 822/875 [1:57:25<07:43,  8.75s/it]Model Responding:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 823/875 [1:57:34<07:38,  8.81s/it]Model Responding:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 824/875 [1:57:43<07:31,  8.86s/it]Model Responding:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 825/875 [1:57:52<07:22,  8.84s/it]Model Responding:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 826/875 [1:58:01<07:11,  8.80s/it]Model Responding:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 827/875 [1:58:10<07:05,  8.86s/it]Model Responding:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 828/875 [1:58:19<07:00,  8.94s/it]Model Responding:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 829/875 [1:58:28<06:47,  8.85s/it]Model Responding:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 830/875 [1:58:36<06:31,  8.70s/it]Model Responding:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 831/875 [1:58:44<06:20,  8.64s/it]Model Responding:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 832/875 [1:58:53<06:08,  8.57s/it]Model Responding:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 833/875 [1:59:01<05:57,  8.51s/it]Model Responding:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 834/875 [1:59:09<05:43,  8.37s/it]Model Responding:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 835/875 [1:59:18<05:36,  8.40s/it]Model Responding:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 836/875 [1:59:26<05:27,  8.41s/it]Model Responding:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 837/875 [1:59:35<05:21,  8.47s/it]Model Responding:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 838/875 [1:59:43<05:08,  8.32s/it]Model Responding:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 839/875 [1:59:51<05:01,  8.37s/it]Model Responding:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 840/875 [2:00:00<04:53,  8.37s/it]Model Responding:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 841/875 [2:00:08<04:45,  8.41s/it]Model Responding:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 842/875 [2:00:18<04:49,  8.78s/it]Model Responding:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 843/875 [2:00:27<04:45,  8.91s/it]Model Responding:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 844/875 [2:00:36<04:37,  8.96s/it]Model Responding:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 845/875 [2:00:45<04:28,  8.95s/it]Model Responding:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 846/875 [2:00:53<04:14,  8.78s/it]Model Responding:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 847/875 [2:01:01<03:59,  8.54s/it]Model Responding:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 848/875 [2:01:10<03:51,  8.56s/it]Model Responding:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 849/875 [2:01:19<03:42,  8.56s/it]Model Responding:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 850/875 [2:01:28<03:42,  8.91s/it]Model Responding:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 851/875 [2:01:37<03:31,  8.79s/it]Model Responding:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 852/875 [2:01:47<03:30,  9.15s/it]Model Responding:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 853/875 [2:01:57<03:26,  9.39s/it]Model Responding:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 854/875 [2:02:06<03:15,  9.29s/it]Model Responding:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 855/875 [2:02:14<03:01,  9.08s/it]Model Responding:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 856/875 [2:02:23<02:52,  9.07s/it]Model Responding:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 857/875 [2:02:33<02:46,  9.24s/it]Model Responding:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 858/875 [2:02:42<02:37,  9.25s/it]Model Responding:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 859/875 [2:02:51<02:26,  9.16s/it]Model Responding:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 860/875 [2:03:01<02:17,  9.19s/it]Model Responding:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 861/875 [2:03:09<02:04,  8.88s/it]Model Responding:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 862/875 [2:03:18<01:56,  8.99s/it]Model Responding:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 863/875 [2:03:27<01:47,  8.98s/it]Model Responding:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 864/875 [2:03:36<01:39,  9.02s/it]Model Responding:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 865/875 [2:03:44<01:28,  8.83s/it]Model Responding:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 866/875 [2:03:53<01:19,  8.80s/it]Model Responding:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 867/875 [2:04:02<01:09,  8.69s/it]Model Responding:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 868/875 [2:04:10<01:01,  8.72s/it]Model Responding:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 869/875 [2:04:20<00:53,  8.93s/it]Model Responding:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 870/875 [2:04:28<00:44,  8.80s/it]Model Responding: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 871/875 [2:04:37<00:35,  8.82s/it]Model Responding: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 872/875 [2:04:46<00:26,  8.74s/it]Model Responding: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 873/875 [2:04:54<00:17,  8.61s/it]Model Responding: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 874/875 [2:05:02<00:08,  8.57s/it]Model Responding: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 875/875 [2:05:10<00:00,  8.32s/it]Model Responding: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 875/875 [2:05:10<00:00,  8.58s/it]
Postprocessing:   0%|          | 0/125 [00:00<?, ?it/s]Postprocessing:   8%|‚ñä         | 10/125 [00:00<00:01, 98.34it/s]Postprocessing:  16%|‚ñà‚ñå        | 20/125 [00:00<00:01, 88.89it/s]Postprocessing:  23%|‚ñà‚ñà‚ñé       | 29/125 [00:00<00:01, 88.95it/s]Postprocessing:  30%|‚ñà‚ñà‚ñà       | 38/125 [00:00<00:00, 88.91it/s]Postprocessing:  38%|‚ñà‚ñà‚ñà‚ñä      | 47/125 [00:00<00:00, 85.82it/s]Postprocessing:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 56/125 [00:00<00:00, 86.93it/s]Postprocessing:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 65/125 [00:00<00:00, 85.16it/s]Postprocessing:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 75/125 [00:00<00:00, 88.20it/s]Postprocessing:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 85/125 [00:00<00:00, 89.22it/s]Postprocessing:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 94/125 [00:01<00:00, 88.42it/s]Postprocessing:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 103/125 [00:01<00:00, 86.89it/s]Postprocessing:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 112/125 [00:01<00:00, 86.31it/s]Postprocessing:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 121/125 [00:01<00:00, 84.80it/s]Postprocessing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [00:01<00:00, 86.90it/s]
Postprocessing:   0%|          | 0/750 [00:00<?, ?it/s]Postprocessing:   2%|‚ñè         | 12/750 [00:00<00:06, 118.13it/s]Postprocessing:   3%|‚ñé         | 24/750 [00:00<00:06, 106.94it/s]Postprocessing:   5%|‚ñç         | 35/750 [00:00<00:06, 103.01it/s]Postprocessing:   6%|‚ñã         | 47/750 [00:00<00:06, 106.08it/s]Postprocessing:   8%|‚ñä         | 59/750 [00:00<00:06, 110.24it/s]Postprocessing:   9%|‚ñâ         | 71/750 [00:00<00:06, 109.30it/s]Postprocessing:  11%|‚ñà         | 82/750 [00:00<00:06, 99.39it/s] Postprocessing:  12%|‚ñà‚ñè        | 93/750 [00:00<00:07, 93.62it/s]Postprocessing:  14%|‚ñà‚ñé        | 103/750 [00:01<00:06, 95.26it/s]Postprocessing:  15%|‚ñà‚ñå        | 115/750 [00:01<00:06, 100.73it/s]Postprocessing:  17%|‚ñà‚ñã        | 126/750 [00:01<00:06, 92.01it/s] Postprocessing:  18%|‚ñà‚ñä        | 136/750 [00:01<00:06, 88.24it/s]Postprocessing:  19%|‚ñà‚ñâ        | 145/750 [00:01<00:06, 87.18it/s]Postprocessing:  21%|‚ñà‚ñà        | 155/750 [00:01<00:06, 90.23it/s]Postprocessing:  22%|‚ñà‚ñà‚ñè       | 165/750 [00:01<00:06, 92.85it/s]Postprocessing:  23%|‚ñà‚ñà‚ñé       | 175/750 [00:01<00:06, 92.24it/s]Postprocessing:  25%|‚ñà‚ñà‚ñç       | 185/750 [00:01<00:06, 93.04it/s]Postprocessing:  26%|‚ñà‚ñà‚ñå       | 195/750 [00:02<00:05, 94.77it/s]Postprocessing:  27%|‚ñà‚ñà‚ñã       | 206/750 [00:02<00:05, 97.05it/s]Postprocessing:  29%|‚ñà‚ñà‚ñâ       | 217/750 [00:02<00:05, 99.30it/s]Postprocessing:  30%|‚ñà‚ñà‚ñà       | 228/750 [00:02<00:05, 100.63it/s]Postprocessing:  32%|‚ñà‚ñà‚ñà‚ñè      | 240/750 [00:02<00:04, 103.24it/s]Postprocessing:  34%|‚ñà‚ñà‚ñà‚ñé      | 252/750 [00:02<00:04, 107.67it/s]Postprocessing:  35%|‚ñà‚ñà‚ñà‚ñå      | 263/750 [00:02<00:04, 104.14it/s]Postprocessing:  37%|‚ñà‚ñà‚ñà‚ñã      | 274/750 [00:02<00:04, 103.75it/s]Postprocessing:  38%|‚ñà‚ñà‚ñà‚ñä      | 285/750 [00:02<00:04, 103.06it/s]Postprocessing:  39%|‚ñà‚ñà‚ñà‚ñâ      | 296/750 [00:02<00:04, 100.57it/s]Postprocessing:  41%|‚ñà‚ñà‚ñà‚ñà      | 307/750 [00:03<00:04, 97.98it/s] Postprocessing:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 320/750 [00:03<00:04, 105.10it/s]Postprocessing:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 331/750 [00:03<00:04, 102.53it/s]Postprocessing:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 342/750 [00:03<00:04, 97.67it/s] Postprocessing:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 352/750 [00:03<00:04, 96.75it/s]Postprocessing:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 362/750 [00:03<00:04, 93.45it/s]Postprocessing:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 372/750 [00:03<00:04, 93.34it/s]Postprocessing:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 383/750 [00:03<00:03, 96.13it/s]Postprocessing:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 394/750 [00:04<00:03, 97.69it/s]Postprocessing:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 404/750 [00:04<00:03, 94.70it/s]Postprocessing:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 415/750 [00:04<00:03, 98.25it/s]Postprocessing:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 426/750 [00:04<00:03, 99.90it/s]Postprocessing:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 437/750 [00:04<00:03, 101.49it/s]Postprocessing:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 448/750 [00:04<00:02, 103.02it/s]Postprocessing:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 459/750 [00:04<00:02, 97.12it/s] Postprocessing:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 470/750 [00:04<00:02, 98.95it/s]Postprocessing:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 480/750 [00:04<00:02, 96.22it/s]Postprocessing:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 491/750 [00:04<00:02, 97.51it/s]Postprocessing:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 501/750 [00:05<00:02, 97.80it/s]Postprocessing:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 511/750 [00:05<00:02, 97.17it/s]Postprocessing:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 522/750 [00:05<00:02, 98.43it/s]Postprocessing:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 532/750 [00:05<00:02, 98.30it/s]Postprocessing:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 544/750 [00:05<00:02, 102.21it/s]Postprocessing:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 556/750 [00:05<00:01, 106.53it/s]Postprocessing:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 567/750 [00:05<00:01, 106.16it/s]Postprocessing:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 578/750 [00:05<00:01, 101.30it/s]Postprocessing:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 590/750 [00:05<00:01, 106.55it/s]Postprocessing:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 601/750 [00:06<00:01, 103.54it/s]Postprocessing:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 612/750 [00:06<00:01, 100.07it/s]Postprocessing:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 623/750 [00:06<00:01, 96.54it/s] Postprocessing:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 633/750 [00:06<00:01, 95.94it/s]Postprocessing:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 646/750 [00:06<00:00, 104.96it/s]Postprocessing:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 658/750 [00:06<00:00, 107.64it/s]Postprocessing:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 669/750 [00:06<00:00, 105.50it/s]Postprocessing:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 680/750 [00:06<00:00, 105.72it/s]Postprocessing:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 691/750 [00:06<00:00, 105.12it/s]Postprocessing:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 702/750 [00:07<00:00, 106.06it/s]Postprocessing:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 713/750 [00:07<00:00, 106.42it/s]Postprocessing:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 724/750 [00:07<00:00, 106.76it/s]Postprocessing:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 737/750 [00:07<00:00, 111.68it/s]Postprocessing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 749/750 [00:07<00:00, 107.24it/s]Postprocessing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 750/750 [00:07<00:00, 100.20it/s]
[32m2024-12-15 03:40:30.488[0m | [1mINFO    [0m | [36mlmms_eval.loggers.evaluation_tracker[0m:[36msave_results_aggregated[0m:[36m188[0m - [1mSaving results aggregated[0m
[32m2024-12-15 03:40:30.493[0m | [1mINFO    [0m | [36mlmms_eval.loggers.evaluation_tracker[0m:[36msave_results_samples[0m:[36m255[0m - [1mSaving per-sample results for: pope_pop[0m
[32m2024-12-15 03:40:33.404[0m | [1mINFO    [0m | [36mlmms_eval.loggers.evaluation_tracker[0m:[36msave_results_samples[0m:[36m255[0m - [1mSaving per-sample results for: vqav2_val_lite[0m
llava (pretrained=liuhaotian/llava-v1.6-vicuna-7b), gen_kwargs: (), limit: None, num_fewshot: None, batch_size: 1
|    Tasks     |Version|Filter|n-shot|    Metric    |   |Value |   |Stderr|
|--------------|-------|------|-----:|--------------|---|-----:|---|------|
|pope_pop      |Yaml   |none  |     0|pope_accuracy |‚Üë  |0.8767|¬±  |   N/A|
|pope_pop      |Yaml   |none  |     0|pope_f1_score |‚Üë  |0.8645|¬±  |   N/A|
|pope_pop      |Yaml   |none  |     0|pope_precision|‚Üë  |0.9593|¬±  |   N/A|
|pope_pop      |Yaml   |none  |     0|pope_recall   |‚Üë  |0.7867|¬±  |   N/A|
|pope_pop      |Yaml   |none  |     0|pope_yes_ratio|‚Üë  |0.5000|¬±  |   N/A|
|vqav2_val_lite|Yaml   |none  |     0|exact_match   |‚Üë  |0.7520|¬±  |0.0178|

wandb: - 0.025 MB of 0.025 MB uploadedwandb: - 0.025 MB of 0.025 MB uploadedwandb: - 0.025 MB of 0.025 MB uploadedwandb: \ 0.025 MB of 0.025 MB uploadedwandb: \ 0.025 MB of 0.025 MB uploadedwandb: \ 0.025 MB of 0.025 MB uploadedwandb: | 0.025 MB of 0.025 MB uploadedwandb: | 0.025 MB of 0.030 MB uploadedwandb: | 0.025 MB of 0.038 MB uploadedwandb: / 0.025 MB of 0.038 MB uploadedwandb: / 0.025 MB of 0.038 MB uploadedwandb: - 0.038 MB of 0.038 MB uploadedwandb:                                                                                
wandb: / 0.025 MB of 0.030 MB uploadedwandb: - 0.038 MB of 0.038 MB uploadedwandb:                                                                                
wandb: - 0.025 MB of 0.038 MB uploadedwandb: \ 0.038 MB of 0.038 MB uploadedwandb:                                                                                
wandb: - 0.032 MB of 0.032 MB uploadedwandb: üöÄ View run reverse5 at: https://wandb.ai/VLM_Hallucination_Woohyeon/llava1.6_recursive_eval_1126/runs/6glipbd9/workspace
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241215_011446-6glipbd9/logs
wandb: üöÄ View run reverse5 at: https://wandb.ai/VLM_Hallucination_Woohyeon/llava1.6_recursive_eval_1126/runs/jnbdom7z/workspace
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241215_011446-jnbdom7z/logs
wandb: üöÄ View run reverse5 at: https://wandb.ai/VLM_Hallucination_Woohyeon/llava1.6_recursive_eval_1126/runs/brkeys1n/workspace
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241215_011446-brkeys1n/logs
wandb: \ 0.032 MB of 0.032 MB uploadedwandb: | 0.032 MB of 0.032 MB uploadedwandb: / 0.032 MB of 0.032 MB uploadedwandb: - 0.032 MB of 0.052 MB uploadedwandb: \ 0.052 MB of 0.052 MB uploadedwandb: | 0.052 MB of 0.052 MB uploadedwandb: / 0.052 MB of 0.052 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:            pope_pop/pope_accuracy ‚ñÅ
wandb:            pope_pop/pope_f1_score ‚ñÅ
wandb:           pope_pop/pope_precision ‚ñÅ
wandb:              pope_pop/pope_recall ‚ñÅ
wandb:           pope_pop/pope_yes_ratio ‚ñÅ
wandb:        vqav2_val_lite/exact_match ‚ñÅ
wandb: vqav2_val_lite/exact_match_stderr ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    pope_pop/alias pope_pop
wandb:            pope_pop/pope_accuracy 0.87667
wandb:     pope_pop/pope_accuracy_stderr N/A
wandb:            pope_pop/pope_f1_score 0.86447
wandb:     pope_pop/pope_f1_score_stderr N/A
wandb:           pope_pop/pope_precision 0.95935
wandb:    pope_pop/pope_precision_stderr N/A
wandb:              pope_pop/pope_recall 0.78667
wandb:       pope_pop/pope_recall_stderr N/A
wandb:           pope_pop/pope_yes_ratio 0.5
wandb:    pope_pop/pope_yes_ratio_stderr N/A
wandb:              vqav2_val_lite/alias vqav2_val_lite
wandb:        vqav2_val_lite/exact_match 0.752
wandb: vqav2_val_lite/exact_match_stderr 0.0178
wandb: 
wandb: üöÄ View run reverse5 at: https://wandb.ai/VLM_Hallucination_Woohyeon/llava1.6_recursive_eval_1126/runs/t2hfeylq/workspace
wandb: Synced 6 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241215_011446-t2hfeylq/logs
[rank0]:[W1215 03:40:48.997479498 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
