The following values were not passed to `accelerate launch` and had defaults used instead:
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--num_machines` was set to a value of `1`
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
[32m2024-12-26 14:52:42.871[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate[0m:[36m420[0m - [1mVerbosity set to DEBUG[0m
[32m2024-12-26 14:52:42.871[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate[0m:[36m420[0m - [1mVerbosity set to DEBUG[0m
[32m2024-12-26 14:52:42.875[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate[0m:[36m420[0m - [1mVerbosity set to DEBUG[0m
[32m2024-12-26 14:52:42.876[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate[0m:[36m420[0m - [1mVerbosity set to DEBUG[0m
[32m2024-12-26 14:52:47.824[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.tasks[0m:[36m_get_task_and_group[0m:[36m452[0m - [34m[1m`group` and `group_alias` keys in tasks' configs will no longer be used in the next release of lmms-eval. `tag` will be used to allow to call a collection of tasks just like `group`. `group` will be removed in order to not cause confusion with the new ConfigurableGroup which will be the offical way to create groups with addition of group-wide configuations.[0m
[32m2024-12-26 14:52:48.321[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.tasks[0m:[36m_get_task_and_group[0m:[36m452[0m - [34m[1m`group` and `group_alias` keys in tasks' configs will no longer be used in the next release of lmms-eval. `tag` will be used to allow to call a collection of tasks just like `group`. `group` will be removed in order to not cause confusion with the new ConfigurableGroup which will be the offical way to create groups with addition of group-wide configuations.[0m
[32m2024-12-26 14:52:48.325[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.tasks[0m:[36m_get_task_and_group[0m:[36m452[0m - [34m[1m`group` and `group_alias` keys in tasks' configs will no longer be used in the next release of lmms-eval. `tag` will be used to allow to call a collection of tasks just like `group`. `group` will be removed in order to not cause confusion with the new ConfigurableGroup which will be the offical way to create groups with addition of group-wide configuations.[0m
[32m2024-12-26 14:52:48.429[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.tasks[0m:[36m_get_task_and_group[0m:[36m452[0m - [34m[1m`group` and `group_alias` keys in tasks' configs will no longer be used in the next release of lmms-eval. `tag` will be used to allow to call a collection of tasks just like `group`. `group` will be removed in order to not cause confusion with the new ConfigurableGroup which will be the offical way to create groups with addition of group-wide configuations.[0m
[32m2024-12-26 14:52:48.563[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m503[0m - [1mEvaluation tracker args: {'output_path': './logs/'}[0m
[32m2024-12-26 14:52:48.563[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m592[0m - [1mSelected Tasks: ['pope_pop'][0m
[32m2024-12-26 14:52:48.567[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36msimple_evaluate[0m:[36m155[0m - [1mSetting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234[0m
[32m2024-12-26 14:52:49.042[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m503[0m - [1mEvaluation tracker args: {'output_path': './logs/'}[0m
[32m2024-12-26 14:52:49.042[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m592[0m - [1mSelected Tasks: ['pope_pop'][0m
[32m2024-12-26 14:52:49.044[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m503[0m - [1mEvaluation tracker args: {'output_path': './logs/'}[0m
[32m2024-12-26 14:52:49.044[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m592[0m - [1mSelected Tasks: ['pope_pop'][0m
[32m2024-12-26 14:52:49.047[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36msimple_evaluate[0m:[36m155[0m - [1mSetting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234[0m
[32m2024-12-26 14:52:49.047[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36msimple_evaluate[0m:[36m155[0m - [1mSetting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234[0m
[32m2024-12-26 14:52:49.175[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m503[0m - [1mEvaluation tracker args: {'output_path': './logs/'}[0m
[32m2024-12-26 14:52:49.177[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m592[0m - [1mSelected Tasks: ['pope_pop'][0m
[32m2024-12-26 14:52:49.184[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36msimple_evaluate[0m:[36m155[0m - [1mSetting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234[0m
initialize llava model with modification
initialize llava model with modification
initialize llava model with modification
OpenCLIP not installed
OpenCLIP not installed
initialize llava model with modification
OpenCLIP not installed
OpenCLIP not installed
self.merging= None
model_name: llava-v1.6-vicuna-7b
loding from here
self.merging= None
model_name: llava-v1.6-vicuna-7b
loding from here
self.merging= None
model_name: llava-v1.6-vicuna-7b
Rank 0:  Loaded LLaVA model: liuhaotian/llava-v1.6-vicuna-7b
loding from here
self.merging= None
model_name: llava-v1.6-vicuna-7b
loding from here
You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
Rank 0:  Loading vision tower: openai/clip-vit-large-patch14-336
You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:05<00:10,  5.05s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:05<00:10,  5.04s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:05<00:10,  5.03s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:05<00:10,  5.34s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:09<00:04,  4.90s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:09<00:04,  4.93s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:09<00:04,  4.84s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:10<00:05,  5.20s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:13<00:00,  4.38s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:13<00:00,  4.52s/it]
Loading checkpoint shards: 100%|██████████| 3/3 [00:14<00:00,  4.63s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:14<00:00,  4.72s/it]
device: cuda:0
generation_type: recursion
fix_grid: 2x2
attention_thresholding_type: layer_mean_topk
attention_norm: None
attention_threshold: [1.0,0.3]
detection_strategy: None
detection_threshold: 0.8
save_output: False
save_output_csv_path: generation_output.csv
target_token_selection_strategy: first
stages: [-1, 0, 1]
positional_embedding_type: reduced
visualize_heatmap: False
square: 1
remove unpadding=True, change to 'spatial'
change positional embedding to reduced
Reduced embedding type.
Loading checkpoint shards: 100%|██████████| 3/3 [00:14<00:00,  4.72s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:14<00:00,  4.79s/it]
device: cuda:0
generation_type: recursion
fix_grid: 2x2
attention_thresholding_type: layer_mean_topk
attention_norm: None
attention_threshold: [1.0,0.3]
detection_strategy: None
detection_threshold: 0.8
save_output: False
save_output_csv_path: generation_output.csv
target_token_selection_strategy: first
stages: [-1, 0, 1]
positional_embedding_type: reduced
visualize_heatmap: False
square: 1
remove unpadding=True, change to 'spatial'
change positional embedding to reduced
device: cuda:0
generation_type: recursion
fix_grid: 2x2
attention_thresholding_type: layer_mean_topk
attention_norm: None
attention_threshold: [1.0,0.3]
detection_strategy: None
detection_threshold: 0.8
save_output: False
save_output_csv_path: generation_output.csv
target_token_selection_strategy: first
stages: [-1, 0, 1]
positional_embedding_type: reduced
visualize_heatmap: False
square: 1
remove unpadding=True, change to 'spatial'
change positional embedding to reduced
Reduced embedding type.
Reduced embedding type.
Loading checkpoint shards: 100%|██████████| 3/3 [00:15<00:00,  4.94s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:15<00:00,  5.02s/it]
Rank 0:  Model Class: LlavaLlamaForCausalLM
device: cuda:0
generation_type: recursion
fix_grid: 2x2
attention_thresholding_type: layer_mean_topk
attention_norm: None
attention_threshold: [1.0,0.3]
detection_strategy: None
detection_threshold: 0.8
save_output: False
save_output_csv_path: generation_output.csv
target_token_selection_strategy: first
stages: [-1, 0, 1]
positional_embedding_type: reduced
visualize_heatmap: False
square: 1
remove unpadding=True, change to 'spatial'
change positional embedding to reduced
Reduced embedding type.
[32m2024-12-26 14:53:12.760[0m | [1mINFO    [0m | [36mlmms_eval.models.llava[0m:[36m__init__[0m:[36m313[0m - [1mUsing 4 devices with data parallelism[0m
[32m2024-12-26 14:53:12.760[0m | [1mINFO    [0m | [36mlmms_eval.evaluator_utils[0m:[36mfrom_taskdict[0m:[36m91[0m - [1mNo metadata found in task config for pope_pop, using default n_shot=0[0m
[32m2024-12-26 14:53:12.761[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.caching.cache[0m:[36mload_from_cache[0m:[36m33[0m - [34m[1mrequests-pope_pop-0shot-rank0-world_size4-tokenizer is not cached, generating...[0m
[32m2024-12-26 14:53:12.761[0m | [1mINFO    [0m | [36mlmms_eval.api.task[0m:[36mbuild_all_requests[0m:[36m425[0m - [1mBuilding contexts for pope_pop on rank 0...[0m
[32m2024-12-26 14:53:12.887[0m | [1mINFO    [0m | [36mlmms_eval.evaluator_utils[0m:[36mfrom_taskdict[0m:[36m91[0m - [1mNo metadata found in task config for pope_pop, using default n_shot=0[0m
[32m2024-12-26 14:53:12.888[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.caching.cache[0m:[36mload_from_cache[0m:[36m33[0m - [34m[1mrequests-pope_pop-0shot-rank2-world_size4-tokenizer is not cached, generating...[0m
[32m2024-12-26 14:53:12.889[0m | [1mINFO    [0m | [36mlmms_eval.api.task[0m:[36mbuild_all_requests[0m:[36m425[0m - [1mBuilding contexts for pope_pop on rank 2...[0m
[32m2024-12-26 14:53:13.645[0m | [1mINFO    [0m | [36mlmms_eval.evaluator_utils[0m:[36mfrom_taskdict[0m:[36m91[0m - [1mNo metadata found in task config for pope_pop, using default n_shot=0[0m
[32m2024-12-26 14:53:13.645[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.caching.cache[0m:[36mload_from_cache[0m:[36m33[0m - [34m[1mrequests-pope_pop-0shot-rank1-world_size4-tokenizer is not cached, generating...[0m
[32m2024-12-26 14:53:13.647[0m | [1mINFO    [0m | [36mlmms_eval.api.task[0m:[36mbuild_all_requests[0m:[36m425[0m - [1mBuilding contexts for pope_pop on rank 1...[0m
[32m2024-12-26 14:53:13.905[0m | [1mINFO    [0m | [36mlmms_eval.evaluator_utils[0m:[36mfrom_taskdict[0m:[36m91[0m - [1mNo metadata found in task config for pope_pop, using default n_shot=0[0m
[32m2024-12-26 14:53:13.905[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.caching.cache[0m:[36mload_from_cache[0m:[36m33[0m - [34m[1mrequests-pope_pop-0shot-rank3-world_size4-tokenizer is not cached, generating...[0m
[32m2024-12-26 14:53:13.906[0m | [1mINFO    [0m | [36mlmms_eval.api.task[0m:[36mbuild_all_requests[0m:[36m425[0m - [1mBuilding contexts for pope_pop on rank 3...[0m
  0%|          | 0/750 [00:00<?, ?it/s]100%|██████████| 750/750 [00:00<00:00, 98853.87it/s]
[32m2024-12-26 14:53:19.997[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m455[0m - [34m[1mTask: pope_pop; number of requests on this rank: 750[0m
  0%|          | 0/750 [00:00<?, ?it/s]100%|██████████| 750/750 [00:00<00:00, 102580.32it/s]
[32m2024-12-26 14:53:20.013[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m455[0m - [34m[1mTask: pope_pop; number of requests on this rank: 750[0m
  0%|          | 0/750 [00:00<?, ?it/s]100%|██████████| 750/750 [00:00<00:00, 106310.51it/s]
[32m2024-12-26 14:53:20.839[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m455[0m - [34m[1mTask: pope_pop; number of requests on this rank: 750[0m
  0%|          | 0/750 [00:00<?, ?it/s]100%|██████████| 750/750 [00:00<00:00, 100560.32it/s]
[32m2024-12-26 14:53:21.098[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m455[0m - [34m[1mTask: pope_pop; number of requests on this rank: 750[0m
[32m2024-12-26 14:53:25.271[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m476[0m - [1mRunning generate_until requests[0m
[32m2024-12-26 14:53:25.271[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m476[0m - [1mRunning generate_until requests[0m
[32m2024-12-26 14:53:25.271[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m476[0m - [1mRunning generate_until requests[0m
[32m2024-12-26 14:53:25.272[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m476[0m - [1mRunning generate_until requests[0m
Model Responding:   0%|          | 0/750 [00:00<?, ?it/s]CLIPModel is using CLIPSdpaAttention, but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation="eager"` when loading the model.
CLIPModel is using CLIPSdpaAttention, but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation="eager"` when loading the model.
CLIPModel is using CLIPSdpaAttention, but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation="eager"` when loading the model.
CLIPModel is using CLIPSdpaAttention, but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation="eager"` when loading the model.
LlamaModel is using LlamaSdpaAttention, but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation="eager"` when loading the model.
LlamaModel is using LlamaSdpaAttention, but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation="eager"` when loading the model.
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
LlamaModel is using LlamaSdpaAttention, but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation="eager"` when loading the model.
LlamaModel is using LlamaSdpaAttention, but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation="eager"` when loading the model.
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
Model Responding:   0%|          | 1/750 [00:02<28:02,  2.25s/it]Model Responding:   0%|          | 2/750 [00:03<19:54,  1.60s/it]Model Responding:   0%|          | 3/750 [00:04<17:28,  1.40s/it]Model Responding:   1%|          | 4/750 [00:05<16:15,  1.31s/it]Model Responding:   1%|          | 5/750 [00:06<15:22,  1.24s/it]Model Responding:   1%|          | 6/750 [00:08<15:04,  1.22s/it]Model Responding:   1%|          | 7/750 [00:09<14:49,  1.20s/it]Model Responding:   1%|          | 8/750 [00:10<14:42,  1.19s/it]Model Responding:   1%|          | 9/750 [00:11<14:37,  1.18s/it]Model Responding:   1%|▏         | 10/750 [00:12<14:33,  1.18s/it]Model Responding:   1%|▏         | 11/750 [00:13<14:25,  1.17s/it]Model Responding:   2%|▏         | 12/750 [00:15<14:42,  1.20s/it]Model Responding:   2%|▏         | 13/750 [00:16<14:29,  1.18s/it]Model Responding:   2%|▏         | 14/750 [00:17<14:33,  1.19s/it]Model Responding:   2%|▏         | 15/750 [00:18<14:27,  1.18s/it]Model Responding:   2%|▏         | 16/750 [00:19<14:32,  1.19s/it]Model Responding:   2%|▏         | 17/750 [00:21<14:38,  1.20s/it]Model Responding:   2%|▏         | 18/750 [00:22<14:05,  1.16s/it]Model Responding:   3%|▎         | 19/750 [00:23<14:10,  1.16s/it]Model Responding:   3%|▎         | 20/750 [00:24<14:10,  1.16s/it]Model Responding:   3%|▎         | 21/750 [00:25<14:34,  1.20s/it]Model Responding:   3%|▎         | 22/750 [00:26<14:27,  1.19s/it]Model Responding:   3%|▎         | 23/750 [00:28<14:24,  1.19s/it]Model Responding:   3%|▎         | 24/750 [00:29<14:16,  1.18s/it]Model Responding:   3%|▎         | 25/750 [00:30<14:08,  1.17s/it]Model Responding:   3%|▎         | 26/750 [00:31<14:11,  1.18s/it]Model Responding:   4%|▎         | 27/750 [00:32<14:07,  1.17s/it]Model Responding:   4%|▎         | 28/750 [00:33<14:05,  1.17s/it]Model Responding:   4%|▍         | 29/750 [00:35<14:21,  1.19s/it]Model Responding:   4%|▍         | 30/750 [00:36<14:27,  1.20s/it]Model Responding:   4%|▍         | 31/750 [00:37<14:14,  1.19s/it]Model Responding:   4%|▍         | 32/750 [00:38<14:09,  1.18s/it]Model Responding:   4%|▍         | 33/750 [00:40<14:47,  1.24s/it]Model Responding:   5%|▍         | 34/750 [00:41<14:30,  1.22s/it]Model Responding:   5%|▍         | 35/750 [00:42<14:24,  1.21s/it]Model Responding:   5%|▍         | 36/750 [00:43<14:16,  1.20s/it]Model Responding:   5%|▍         | 37/750 [00:44<13:53,  1.17s/it]Model Responding:   5%|▌         | 38/750 [00:45<14:04,  1.19s/it]Model Responding:   5%|▌         | 39/750 [00:47<13:55,  1.18s/it]Model Responding:   5%|▌         | 40/750 [00:48<13:51,  1.17s/it]Model Responding:   5%|▌         | 41/750 [00:49<13:47,  1.17s/it]Model Responding:   6%|▌         | 42/750 [00:50<13:52,  1.18s/it]Model Responding:   6%|▌         | 43/750 [00:51<13:51,  1.18s/it]Model Responding:   6%|▌         | 44/750 [00:52<13:53,  1.18s/it]Model Responding:   6%|▌         | 45/750 [00:54<13:46,  1.17s/it]Model Responding:   6%|▌         | 46/750 [00:55<13:51,  1.18s/it]Model Responding:   6%|▋         | 47/750 [00:56<13:56,  1.19s/it]Model Responding:   6%|▋         | 48/750 [00:57<13:55,  1.19s/it]Model Responding:   7%|▋         | 49/750 [00:58<13:40,  1.17s/it]Model Responding:   7%|▋         | 50/750 [01:00<13:39,  1.17s/it]Model Responding:   7%|▋         | 51/750 [01:01<13:39,  1.17s/it]Model Responding:   7%|▋         | 52/750 [01:02<13:42,  1.18s/it]Model Responding:   7%|▋         | 53/750 [01:03<13:39,  1.18s/it]Model Responding:   7%|▋         | 54/750 [01:04<13:23,  1.15s/it]Model Responding:   7%|▋         | 55/750 [01:05<13:21,  1.15s/it]Model Responding:   7%|▋         | 56/750 [01:06<13:23,  1.16s/it]Model Responding:   8%|▊         | 57/750 [01:08<13:22,  1.16s/it]Model Responding:   8%|▊         | 58/750 [01:09<13:24,  1.16s/it]Model Responding:   8%|▊         | 59/750 [01:10<13:12,  1.15s/it]Model Responding:   8%|▊         | 60/750 [01:11<13:15,  1.15s/it]Model Responding:   8%|▊         | 61/750 [01:12<13:27,  1.17s/it]Model Responding:   8%|▊         | 62/750 [01:13<13:21,  1.16s/it]Model Responding:   8%|▊         | 63/750 [01:15<13:24,  1.17s/it]Model Responding:   9%|▊         | 64/750 [01:16<13:22,  1.17s/it]Model Responding:   9%|▊         | 65/750 [01:17<13:28,  1.18s/it]Model Responding:   9%|▉         | 66/750 [01:18<13:23,  1.17s/it]Model Responding:   9%|▉         | 67/750 [01:19<13:19,  1.17s/it]Model Responding:   9%|▉         | 68/750 [01:21<13:29,  1.19s/it]Model Responding:   9%|▉         | 69/750 [01:22<13:34,  1.20s/it]Model Responding:   9%|▉         | 70/750 [01:23<13:31,  1.19s/it]Model Responding:   9%|▉         | 71/750 [01:24<13:23,  1.18s/it]Model Responding:  10%|▉         | 72/750 [01:25<13:23,  1.19s/it]Model Responding:  10%|▉         | 73/750 [01:26<13:15,  1.18s/it]Model Responding:  10%|▉         | 74/750 [01:28<13:17,  1.18s/it]Model Responding:  10%|█         | 75/750 [01:29<13:46,  1.22s/it]Model Responding:  10%|█         | 76/750 [01:30<13:32,  1.21s/it]Model Responding:  10%|█         | 77/750 [01:31<13:23,  1.19s/it]Model Responding:  10%|█         | 78/750 [01:33<13:35,  1.21s/it]Model Responding:  11%|█         | 79/750 [01:34<13:24,  1.20s/it]Model Responding:  11%|█         | 80/750 [01:35<13:29,  1.21s/it]Model Responding:  11%|█         | 81/750 [01:36<13:21,  1.20s/it]Model Responding:  11%|█         | 82/750 [01:37<13:18,  1.20s/it]Model Responding:  11%|█         | 83/750 [01:38<12:55,  1.16s/it]Model Responding:  11%|█         | 84/750 [01:40<12:47,  1.15s/it]Model Responding:  11%|█▏        | 85/750 [01:41<12:59,  1.17s/it]Model Responding:  11%|█▏        | 86/750 [01:42<12:59,  1.17s/it]Model Responding:  12%|█▏        | 87/750 [01:43<12:53,  1.17s/it]Model Responding:  12%|█▏        | 88/750 [01:44<13:00,  1.18s/it]Model Responding:  12%|█▏        | 89/750 [01:46<13:13,  1.20s/it]Model Responding:  12%|█▏        | 90/750 [01:47<12:53,  1.17s/it]Model Responding:  12%|█▏        | 91/750 [01:48<12:52,  1.17s/it]Model Responding:  12%|█▏        | 92/750 [01:49<12:58,  1.18s/it]Model Responding:  12%|█▏        | 93/750 [01:50<12:54,  1.18s/it]Model Responding:  13%|█▎        | 94/750 [01:51<12:57,  1.18s/it]Model Responding:  13%|█▎        | 95/750 [01:53<12:57,  1.19s/it]Model Responding:  13%|█▎        | 96/750 [01:54<12:54,  1.18s/it]Model Responding:  13%|█▎        | 97/750 [01:55<13:00,  1.20s/it]Model Responding:  13%|█▎        | 98/750 [01:56<13:05,  1.20s/it]Model Responding:  13%|█▎        | 99/750 [01:57<12:43,  1.17s/it]Model Responding:  13%|█▎        | 100/750 [01:59<12:46,  1.18s/it]Model Responding:  13%|█▎        | 101/750 [02:00<12:29,  1.15s/it]Model Responding:  14%|█▎        | 102/750 [02:01<12:28,  1.16s/it]Model Responding:  14%|█▎        | 103/750 [02:02<12:33,  1.16s/it]Model Responding:  14%|█▍        | 104/750 [02:03<12:34,  1.17s/it]Model Responding:  14%|█▍        | 105/750 [02:04<12:39,  1.18s/it]Model Responding:  14%|█▍        | 106/750 [02:05<12:23,  1.15s/it]Model Responding:  14%|█▍        | 107/750 [02:07<12:28,  1.16s/it]Model Responding:  14%|█▍        | 108/750 [02:08<12:26,  1.16s/it]Model Responding:  15%|█▍        | 109/750 [02:09<12:36,  1.18s/it]Model Responding:  15%|█▍        | 110/750 [02:10<12:39,  1.19s/it]Model Responding:  15%|█▍        | 111/750 [02:11<12:39,  1.19s/it]Model Responding:  15%|█▍        | 112/750 [02:13<12:34,  1.18s/it]Model Responding:  15%|█▌        | 113/750 [02:14<12:31,  1.18s/it]Model Responding:  15%|█▌        | 114/750 [02:15<12:40,  1.20s/it]Model Responding:  15%|█▌        | 115/750 [02:16<12:45,  1.21s/it]Model Responding:  15%|█▌        | 116/750 [02:17<13:05,  1.24s/it]Model Responding:  16%|█▌        | 117/750 [02:19<12:50,  1.22s/it]Model Responding:  16%|█▌        | 118/750 [02:20<12:42,  1.21s/it]Model Responding:  16%|█▌        | 119/750 [02:21<12:35,  1.20s/it]Model Responding:  16%|█▌        | 120/750 [02:22<12:33,  1.20s/it]Model Responding:  16%|█▌        | 121/750 [02:23<12:27,  1.19s/it]Model Responding:  16%|█▋        | 122/750 [02:25<12:29,  1.19s/it]Model Responding:  16%|█▋        | 123/750 [02:26<12:33,  1.20s/it]Model Responding:  17%|█▋        | 124/750 [02:27<12:24,  1.19s/it]Model Responding:  17%|█▋        | 125/750 [02:28<12:20,  1.18s/it]Model Responding:  17%|█▋        | 126/750 [02:29<12:16,  1.18s/it]Model Responding:  17%|█▋        | 127/750 [02:30<12:15,  1.18s/it]Model Responding:  17%|█▋        | 128/750 [02:32<12:15,  1.18s/it]Model Responding:  17%|█▋        | 129/750 [02:33<12:12,  1.18s/it]Model Responding:  17%|█▋        | 130/750 [02:34<12:19,  1.19s/it]Model Responding:  17%|█▋        | 131/750 [02:35<12:26,  1.21s/it]Model Responding:  18%|█▊        | 132/750 [02:37<12:34,  1.22s/it]Model Responding:  18%|█▊        | 133/750 [02:38<12:21,  1.20s/it]Model Responding:  18%|█▊        | 134/750 [02:39<12:13,  1.19s/it]Model Responding:  18%|█▊        | 135/750 [02:40<12:13,  1.19s/it]Model Responding:  18%|█▊        | 136/750 [02:41<12:24,  1.21s/it]Model Responding:  18%|█▊        | 137/750 [02:43<12:33,  1.23s/it]Model Responding:  18%|█▊        | 138/750 [02:44<12:21,  1.21s/it]Model Responding:  19%|█▊        | 139/750 [02:45<12:27,  1.22s/it]Model Responding:  19%|█▊        | 140/750 [02:46<12:30,  1.23s/it]Model Responding:  19%|█▉        | 141/750 [02:47<12:18,  1.21s/it]Model Responding:  19%|█▉        | 142/750 [02:49<12:07,  1.20s/it]Model Responding:  19%|█▉        | 143/750 [02:50<12:07,  1.20s/it]Model Responding:  19%|█▉        | 144/750 [02:51<11:50,  1.17s/it]Model Responding:  19%|█▉        | 145/750 [02:52<11:54,  1.18s/it]Model Responding:  19%|█▉        | 146/750 [02:53<11:52,  1.18s/it]Model Responding:  20%|█▉        | 147/750 [02:54<11:51,  1.18s/it]Model Responding:  20%|█▉        | 148/750 [02:56<11:56,  1.19s/it]Model Responding:  20%|█▉        | 149/750 [02:57<11:56,  1.19s/it]Model Responding:  20%|██        | 150/750 [02:58<11:52,  1.19s/it]Model Responding:  20%|██        | 151/750 [02:59<11:50,  1.19s/it]Model Responding:  20%|██        | 152/750 [03:00<11:46,  1.18s/it]Model Responding:  20%|██        | 153/750 [03:02<11:46,  1.18s/it]Model Responding:  21%|██        | 154/750 [03:03<11:43,  1.18s/it]Model Responding:  21%|██        | 155/750 [03:04<11:34,  1.17s/it]Model Responding:  21%|██        | 156/750 [03:05<11:41,  1.18s/it]Model Responding:  21%|██        | 157/750 [03:06<11:48,  1.20s/it]Model Responding:  21%|██        | 158/750 [03:08<12:08,  1.23s/it]Model Responding:  21%|██        | 159/750 [03:09<11:54,  1.21s/it]Model Responding:  21%|██▏       | 160/750 [03:10<11:50,  1.20s/it]Model Responding:  21%|██▏       | 161/750 [03:11<11:42,  1.19s/it]Model Responding:  22%|██▏       | 162/750 [03:12<11:47,  1.20s/it]Model Responding:  22%|██▏       | 163/750 [03:14<11:38,  1.19s/it]Model Responding:  22%|██▏       | 164/750 [03:15<11:36,  1.19s/it]Model Responding:  22%|██▏       | 165/750 [03:16<11:40,  1.20s/it]Model Responding:  22%|██▏       | 166/750 [03:17<11:33,  1.19s/it]Model Responding:  22%|██▏       | 167/750 [03:18<11:31,  1.19s/it]Model Responding:  22%|██▏       | 168/750 [03:20<11:28,  1.18s/it]Model Responding:  23%|██▎       | 169/750 [03:21<11:25,  1.18s/it]Model Responding:  23%|██▎       | 170/750 [03:22<11:18,  1.17s/it]Model Responding:  23%|██▎       | 171/750 [03:23<11:23,  1.18s/it]Model Responding:  23%|██▎       | 172/750 [03:24<11:32,  1.20s/it]Model Responding:  23%|██▎       | 173/750 [03:25<11:26,  1.19s/it]Model Responding:  23%|██▎       | 174/750 [03:27<11:30,  1.20s/it]Model Responding:  23%|██▎       | 175/750 [03:28<11:24,  1.19s/it]Model Responding:  23%|██▎       | 176/750 [03:29<11:18,  1.18s/it]Model Responding:  24%|██▎       | 177/750 [03:30<11:13,  1.17s/it]Model Responding:  24%|██▎       | 178/750 [03:31<11:14,  1.18s/it]Model Responding:  24%|██▍       | 179/750 [03:33<11:12,  1.18s/it]Model Responding:  24%|██▍       | 180/750 [03:34<11:11,  1.18s/it]Model Responding:  24%|██▍       | 181/750 [03:35<11:17,  1.19s/it]Model Responding:  24%|██▍       | 182/750 [03:36<11:00,  1.16s/it]Model Responding:  24%|██▍       | 183/750 [03:37<11:02,  1.17s/it]Model Responding:  25%|██▍       | 184/750 [03:38<11:01,  1.17s/it]Model Responding:  25%|██▍       | 185/750 [03:40<11:02,  1.17s/it]Model Responding:  25%|██▍       | 186/750 [03:41<10:58,  1.17s/it]Model Responding:  25%|██▍       | 187/750 [03:42<11:01,  1.17s/it]Model Responding:  25%|██▌       | 188/750 [03:43<11:02,  1.18s/it]Model Responding:  25%|██▌       | 189/750 [03:44<11:14,  1.20s/it]Model Responding:  25%|██▌       | 190/750 [03:46<11:20,  1.21s/it]Model Responding:  25%|██▌       | 191/750 [03:47<11:22,  1.22s/it]Model Responding:  26%|██▌       | 192/750 [03:48<11:12,  1.20s/it]Model Responding:  26%|██▌       | 193/750 [03:49<11:04,  1.19s/it]Model Responding:  26%|██▌       | 194/750 [03:50<11:01,  1.19s/it]Model Responding:  26%|██▌       | 195/750 [03:52<10:59,  1.19s/it]Model Responding:  26%|██▌       | 196/750 [03:53<10:58,  1.19s/it]Model Responding:  26%|██▋       | 197/750 [03:54<10:55,  1.19s/it]Model Responding:  26%|██▋       | 198/750 [03:55<10:56,  1.19s/it]Model Responding:  27%|██▋       | 199/750 [03:56<11:26,  1.25s/it]Model Responding:  27%|██▋       | 200/750 [03:58<11:11,  1.22s/it]Model Responding:  27%|██▋       | 201/750 [03:59<11:01,  1.20s/it]Model Responding:  27%|██▋       | 202/750 [04:00<10:59,  1.20s/it]Model Responding:  27%|██▋       | 203/750 [04:01<10:53,  1.19s/it]Model Responding:  27%|██▋       | 204/750 [04:02<10:51,  1.19s/it]Model Responding:  27%|██▋       | 205/750 [04:04<10:46,  1.19s/it]Model Responding:  27%|██▋       | 206/750 [04:05<10:48,  1.19s/it]Model Responding:  28%|██▊       | 207/750 [04:06<10:53,  1.20s/it]Model Responding:  28%|██▊       | 208/750 [04:07<10:44,  1.19s/it]Model Responding:  28%|██▊       | 209/750 [04:08<10:38,  1.18s/it]Model Responding:  28%|██▊       | 210/750 [04:10<10:43,  1.19s/it]Model Responding:  28%|██▊       | 211/750 [04:11<10:37,  1.18s/it]Model Responding:  28%|██▊       | 212/750 [04:12<10:35,  1.18s/it]Model Responding:  28%|██▊       | 213/750 [04:13<10:32,  1.18s/it]Model Responding:  29%|██▊       | 214/750 [04:14<10:37,  1.19s/it]Model Responding:  29%|██▊       | 215/750 [04:15<10:32,  1.18s/it]Model Responding:  29%|██▉       | 216/750 [04:17<10:30,  1.18s/it]Model Responding:  29%|██▉       | 217/750 [04:18<10:30,  1.18s/it]Model Responding:  29%|██▉       | 218/750 [04:19<10:31,  1.19s/it]Model Responding:  29%|██▉       | 219/750 [04:20<10:15,  1.16s/it]Model Responding:  29%|██▉       | 220/750 [04:21<10:16,  1.16s/it]Model Responding:  29%|██▉       | 221/750 [04:22<10:20,  1.17s/it]Model Responding:  30%|██▉       | 222/750 [04:24<10:10,  1.16s/it]Model Responding:  30%|██▉       | 223/750 [04:25<09:58,  1.14s/it]Model Responding:  30%|██▉       | 224/750 [04:26<10:07,  1.16s/it]Model Responding:  30%|███       | 225/750 [04:27<10:08,  1.16s/it]Model Responding:  30%|███       | 226/750 [04:28<10:08,  1.16s/it]Model Responding:  30%|███       | 227/750 [04:29<10:12,  1.17s/it]Model Responding:  30%|███       | 228/750 [04:31<10:12,  1.17s/it]Model Responding:  31%|███       | 229/750 [04:32<10:16,  1.18s/it]Model Responding:  31%|███       | 230/750 [04:33<10:14,  1.18s/it]Model Responding:  31%|███       | 231/750 [04:34<10:13,  1.18s/it]Model Responding:  31%|███       | 232/750 [04:35<10:21,  1.20s/it]Model Responding:  31%|███       | 233/750 [04:37<10:29,  1.22s/it]Model Responding:  31%|███       | 234/750 [04:38<10:21,  1.20s/it]Model Responding:  31%|███▏      | 235/750 [04:39<10:12,  1.19s/it]Model Responding:  31%|███▏      | 236/750 [04:40<10:09,  1.19s/it]Model Responding:  32%|███▏      | 237/750 [04:41<10:10,  1.19s/it]Model Responding:  32%|███▏      | 238/750 [04:42<09:57,  1.17s/it]Model Responding:  32%|███▏      | 239/750 [04:44<09:44,  1.14s/it]Model Responding:  32%|███▏      | 240/750 [04:45<10:04,  1.18s/it]Model Responding:  32%|███▏      | 241/750 [04:46<10:03,  1.19s/it]Model Responding:  32%|███▏      | 242/750 [04:47<10:03,  1.19s/it]Model Responding:  32%|███▏      | 243/750 [04:48<09:57,  1.18s/it]Model Responding:  33%|███▎      | 244/750 [04:49<09:52,  1.17s/it]Model Responding:  33%|███▎      | 245/750 [04:51<09:51,  1.17s/it]Model Responding:  33%|███▎      | 246/750 [04:52<09:41,  1.15s/it]Model Responding:  33%|███▎      | 247/750 [04:53<09:43,  1.16s/it]Model Responding:  33%|███▎      | 248/750 [04:54<09:49,  1.17s/it]Model Responding:  33%|███▎      | 249/750 [04:55<09:49,  1.18s/it]Model Responding:  33%|███▎      | 250/750 [04:56<09:36,  1.15s/it]Model Responding:  33%|███▎      | 251/750 [04:58<09:44,  1.17s/it]Model Responding:  34%|███▎      | 252/750 [04:59<09:45,  1.18s/it]Model Responding:  34%|███▎      | 253/750 [05:00<09:48,  1.18s/it]Model Responding:  34%|███▍      | 254/750 [05:01<09:48,  1.19s/it]Model Responding:  34%|███▍      | 255/750 [05:02<09:49,  1.19s/it]Model Responding:  34%|███▍      | 256/750 [05:04<09:50,  1.20s/it]Model Responding:  34%|███▍      | 257/750 [05:05<09:49,  1.20s/it]Model Responding:  34%|███▍      | 258/750 [05:06<09:39,  1.18s/it]Model Responding:  35%|███▍      | 259/750 [05:07<09:41,  1.19s/it]Model Responding:  35%|███▍      | 260/750 [05:08<09:40,  1.18s/it]Model Responding:  35%|███▍      | 261/750 [05:10<09:41,  1.19s/it]Model Responding:  35%|███▍      | 262/750 [05:11<09:39,  1.19s/it]Model Responding:  35%|███▌      | 263/750 [05:12<09:35,  1.18s/it]Model Responding:  35%|███▌      | 264/750 [05:13<09:34,  1.18s/it]Model Responding:  35%|███▌      | 265/750 [05:14<09:36,  1.19s/it]Model Responding:  35%|███▌      | 266/750 [05:16<09:45,  1.21s/it]Model Responding:  36%|███▌      | 267/750 [05:17<09:37,  1.20s/it]Model Responding:  36%|███▌      | 268/750 [05:18<09:33,  1.19s/it]Model Responding:  36%|███▌      | 269/750 [05:19<09:29,  1.18s/it]Model Responding:  36%|███▌      | 270/750 [05:20<09:25,  1.18s/it]Model Responding:  36%|███▌      | 271/750 [05:21<09:27,  1.18s/it]Model Responding:  36%|███▋      | 272/750 [05:23<09:21,  1.18s/it]Model Responding:  36%|███▋      | 273/750 [05:24<09:18,  1.17s/it]Model Responding:  37%|███▋      | 274/750 [05:25<09:26,  1.19s/it]Model Responding:  37%|███▋      | 275/750 [05:26<09:34,  1.21s/it]Model Responding:  37%|███▋      | 276/750 [05:27<09:28,  1.20s/it]Model Responding:  37%|███▋      | 277/750 [05:29<09:23,  1.19s/it]Model Responding:  37%|███▋      | 278/750 [05:30<09:19,  1.19s/it]Model Responding:  37%|███▋      | 279/750 [05:31<09:24,  1.20s/it]Model Responding:  37%|███▋      | 280/750 [05:32<09:20,  1.19s/it]Model Responding:  37%|███▋      | 281/750 [05:34<09:43,  1.24s/it]Model Responding:  38%|███▊      | 282/750 [05:35<09:49,  1.26s/it]Model Responding:  38%|███▊      | 283/750 [05:36<09:39,  1.24s/it]Model Responding:  38%|███▊      | 284/750 [05:37<09:32,  1.23s/it]Model Responding:  38%|███▊      | 285/750 [05:38<09:22,  1.21s/it]Model Responding:  38%|███▊      | 286/750 [05:40<09:17,  1.20s/it]Model Responding:  38%|███▊      | 287/750 [05:41<09:15,  1.20s/it]Model Responding:  38%|███▊      | 288/750 [05:42<09:09,  1.19s/it]Model Responding:  39%|███▊      | 289/750 [05:43<09:08,  1.19s/it]Model Responding:  39%|███▊      | 290/750 [05:44<09:11,  1.20s/it]Model Responding:  39%|███▉      | 291/750 [05:46<09:16,  1.21s/it]Model Responding:  39%|███▉      | 292/750 [05:47<09:12,  1.21s/it]Model Responding:  39%|███▉      | 293/750 [05:48<09:06,  1.20s/it]Model Responding:  39%|███▉      | 294/750 [05:49<09:05,  1.20s/it]Model Responding:  39%|███▉      | 295/750 [05:50<09:02,  1.19s/it]Model Responding:  39%|███▉      | 296/750 [05:52<09:00,  1.19s/it]Model Responding:  40%|███▉      | 297/750 [05:53<08:56,  1.18s/it]Model Responding:  40%|███▉      | 298/750 [05:54<08:52,  1.18s/it]Model Responding:  40%|███▉      | 299/750 [05:55<09:00,  1.20s/it]Model Responding:  40%|████      | 300/750 [05:56<09:03,  1.21s/it]Model Responding:  40%|████      | 301/750 [05:58<08:59,  1.20s/it]Model Responding:  40%|████      | 302/750 [05:59<08:53,  1.19s/it]Model Responding:  40%|████      | 303/750 [06:00<08:51,  1.19s/it]Model Responding:  41%|████      | 304/750 [06:01<08:52,  1.19s/it]Model Responding:  41%|████      | 305/750 [06:02<08:50,  1.19s/it]Model Responding:  41%|████      | 306/750 [06:03<08:47,  1.19s/it]Model Responding:  41%|████      | 307/750 [06:05<08:38,  1.17s/it]Model Responding:  41%|████      | 308/750 [06:06<08:47,  1.19s/it]Model Responding:  41%|████      | 309/750 [06:07<08:45,  1.19s/it]Model Responding:  41%|████▏     | 310/750 [06:08<08:44,  1.19s/it]Model Responding:  41%|████▏     | 311/750 [06:09<08:42,  1.19s/it]Model Responding:  42%|████▏     | 312/750 [06:11<08:39,  1.19s/it]Model Responding:  42%|████▏     | 313/750 [06:12<08:38,  1.19s/it]Model Responding:  42%|████▏     | 314/750 [06:13<08:36,  1.18s/it]Model Responding:  42%|████▏     | 315/750 [06:14<08:35,  1.18s/it]Model Responding:  42%|████▏     | 316/750 [06:15<08:41,  1.20s/it]Model Responding:  42%|████▏     | 317/750 [06:17<08:37,  1.20s/it]Model Responding:  42%|████▏     | 318/750 [06:18<08:31,  1.18s/it]Model Responding:  43%|████▎     | 319/750 [06:19<08:27,  1.18s/it]Model Responding:  43%|████▎     | 320/750 [06:20<08:23,  1.17s/it]Model Responding:  43%|████▎     | 321/750 [06:21<08:22,  1.17s/it]Model Responding:  43%|████▎     | 322/750 [06:23<08:42,  1.22s/it]Model Responding:  43%|████▎     | 323/750 [06:24<08:35,  1.21s/it]Model Responding:  43%|████▎     | 324/750 [06:25<08:30,  1.20s/it]Model Responding:  43%|████▎     | 325/750 [06:26<08:32,  1.21s/it]Model Responding:  43%|████▎     | 326/750 [06:27<08:23,  1.19s/it]Model Responding:  44%|████▎     | 327/750 [06:28<08:15,  1.17s/it]Model Responding:  44%|████▎     | 328/750 [06:29<08:06,  1.15s/it]Model Responding:  44%|████▍     | 329/750 [06:31<08:06,  1.16s/it]Model Responding:  44%|████▍     | 330/750 [06:32<08:08,  1.16s/it]Model Responding:  44%|████▍     | 331/750 [06:33<08:11,  1.17s/it]Model Responding:  44%|████▍     | 332/750 [06:34<08:17,  1.19s/it]Model Responding:  44%|████▍     | 333/750 [06:36<08:26,  1.21s/it]Model Responding:  45%|████▍     | 334/750 [06:37<08:28,  1.22s/it]Model Responding:  45%|████▍     | 335/750 [06:38<08:15,  1.19s/it]Model Responding:  45%|████▍     | 336/750 [06:39<08:13,  1.19s/it]Model Responding:  45%|████▍     | 337/750 [06:40<08:14,  1.20s/it]Model Responding:  45%|████▌     | 338/750 [06:41<08:11,  1.19s/it]Model Responding:  45%|████▌     | 339/750 [06:43<08:11,  1.20s/it]Model Responding:  45%|████▌     | 340/750 [06:44<08:07,  1.19s/it]Model Responding:  45%|████▌     | 341/750 [06:45<08:06,  1.19s/it]Model Responding:  46%|████▌     | 342/750 [06:46<08:05,  1.19s/it]Model Responding:  46%|████▌     | 343/750 [06:47<08:05,  1.19s/it]Model Responding:  46%|████▌     | 344/750 [06:49<08:02,  1.19s/it]Model Responding:  46%|████▌     | 345/750 [06:50<08:00,  1.19s/it]Model Responding:  46%|████▌     | 346/750 [06:51<07:56,  1.18s/it]Model Responding:  46%|████▋     | 347/750 [06:52<07:53,  1.18s/it]Model Responding:  46%|████▋     | 348/750 [06:53<07:45,  1.16s/it]Model Responding:  47%|████▋     | 349/750 [06:54<07:47,  1.16s/it]Model Responding:  47%|████▋     | 350/750 [06:56<07:53,  1.18s/it]Model Responding:  47%|████▋     | 351/750 [06:57<07:49,  1.18s/it]Model Responding:  47%|████▋     | 352/750 [06:58<07:46,  1.17s/it]Model Responding:  47%|████▋     | 353/750 [06:59<07:46,  1.17s/it]Model Responding:  47%|████▋     | 354/750 [07:00<07:46,  1.18s/it]Model Responding:  47%|████▋     | 355/750 [07:01<07:41,  1.17s/it]Model Responding:  47%|████▋     | 356/750 [07:03<07:40,  1.17s/it]Model Responding:  48%|████▊     | 357/750 [07:04<07:38,  1.17s/it]Model Responding:  48%|████▊     | 358/750 [07:05<07:42,  1.18s/it]Model Responding:  48%|████▊     | 359/750 [07:06<07:46,  1.19s/it]Model Responding:  48%|████▊     | 360/750 [07:07<07:41,  1.18s/it]Model Responding:  48%|████▊     | 361/750 [07:09<07:37,  1.18s/it]Model Responding:  48%|████▊     | 362/750 [07:10<07:38,  1.18s/it]Model Responding:  48%|████▊     | 363/750 [07:11<07:56,  1.23s/it]Model Responding:  49%|████▊     | 364/750 [07:12<07:55,  1.23s/it]Model Responding:  49%|████▊     | 365/750 [07:13<07:48,  1.22s/it]Model Responding:  49%|████▉     | 366/750 [07:15<07:43,  1.21s/it]Model Responding:  49%|████▉     | 367/750 [07:16<07:43,  1.21s/it]Model Responding:  49%|████▉     | 368/750 [07:17<07:41,  1.21s/it]Model Responding:  49%|████▉     | 369/750 [07:18<07:30,  1.18s/it]Model Responding:  49%|████▉     | 370/750 [07:19<07:23,  1.17s/it]Model Responding:  49%|████▉     | 371/750 [07:21<07:25,  1.18s/it]Model Responding:  50%|████▉     | 372/750 [07:22<07:28,  1.19s/it]Model Responding:  50%|████▉     | 373/750 [07:23<07:25,  1.18s/it]Model Responding:  50%|████▉     | 374/750 [07:24<07:25,  1.19s/it]Model Responding:  50%|█████     | 375/750 [07:25<07:32,  1.21s/it]Model Responding:  50%|█████     | 376/750 [07:27<07:22,  1.18s/it]Model Responding:  50%|█████     | 377/750 [07:28<07:21,  1.18s/it]Model Responding:  50%|█████     | 378/750 [07:29<07:19,  1.18s/it]Model Responding:  51%|█████     | 379/750 [07:30<07:16,  1.18s/it]Model Responding:  51%|█████     | 380/750 [07:31<07:10,  1.16s/it]Model Responding:  51%|█████     | 381/750 [07:32<07:05,  1.15s/it]Model Responding:  51%|█████     | 382/750 [07:33<07:00,  1.14s/it]Model Responding:  51%|█████     | 383/750 [07:35<07:08,  1.17s/it]Model Responding:  51%|█████     | 384/750 [07:36<07:12,  1.18s/it]Model Responding:  51%|█████▏    | 385/750 [07:37<07:10,  1.18s/it]Model Responding:  51%|█████▏    | 386/750 [07:38<07:08,  1.18s/it]Model Responding:  52%|█████▏    | 387/750 [07:39<07:06,  1.17s/it]Model Responding:  52%|█████▏    | 388/750 [07:41<07:06,  1.18s/it]Model Responding:  52%|█████▏    | 389/750 [07:42<07:05,  1.18s/it]Model Responding:  52%|█████▏    | 390/750 [07:43<07:02,  1.17s/it]Model Responding:  52%|█████▏    | 391/750 [07:44<07:06,  1.19s/it]Model Responding:  52%|█████▏    | 392/750 [07:45<07:03,  1.18s/it]Model Responding:  52%|█████▏    | 393/750 [07:47<07:08,  1.20s/it]Model Responding:  53%|█████▎    | 394/750 [07:48<07:00,  1.18s/it]Model Responding:  53%|█████▎    | 395/750 [07:49<06:53,  1.16s/it]Model Responding:  53%|█████▎    | 396/750 [07:50<06:55,  1.17s/it]Model Responding:  53%|█████▎    | 397/750 [07:51<06:55,  1.18s/it]Model Responding:  53%|█████▎    | 398/750 [07:52<06:48,  1.16s/it]Model Responding:  53%|█████▎    | 399/750 [07:53<06:42,  1.15s/it]Model Responding:  53%|█████▎    | 400/750 [07:55<06:39,  1.14s/it]Model Responding:  53%|█████▎    | 401/750 [07:56<06:40,  1.15s/it]Model Responding:  54%|█████▎    | 402/750 [07:57<06:43,  1.16s/it]Model Responding:  54%|█████▎    | 403/750 [07:58<06:58,  1.21s/it]Model Responding:  54%|█████▍    | 404/750 [07:59<06:56,  1.20s/it]Model Responding:  54%|█████▍    | 405/750 [08:01<06:54,  1.20s/it]Model Responding:  54%|█████▍    | 406/750 [08:02<06:54,  1.21s/it]Model Responding:  54%|█████▍    | 407/750 [08:03<06:54,  1.21s/it]Model Responding:  54%|█████▍    | 408/750 [08:04<06:43,  1.18s/it]Model Responding:  55%|█████▍    | 409/750 [08:05<06:42,  1.18s/it]Model Responding:  55%|█████▍    | 410/750 [08:07<06:44,  1.19s/it]Model Responding:  55%|█████▍    | 411/750 [08:08<06:34,  1.16s/it]Model Responding:  55%|█████▍    | 412/750 [08:09<06:26,  1.14s/it]Model Responding:  55%|█████▌    | 413/750 [08:10<06:22,  1.14s/it]Model Responding:  55%|█████▌    | 414/750 [08:11<06:26,  1.15s/it]Model Responding:  55%|█████▌    | 415/750 [08:12<06:28,  1.16s/it]Model Responding:  55%|█████▌    | 416/750 [08:13<06:29,  1.17s/it]Model Responding:  56%|█████▌    | 417/750 [08:15<06:35,  1.19s/it]Model Responding:  56%|█████▌    | 418/750 [08:16<06:31,  1.18s/it]Model Responding:  56%|█████▌    | 419/750 [08:17<06:32,  1.19s/it]Model Responding:  56%|█████▌    | 420/750 [08:18<06:29,  1.18s/it]Model Responding:  56%|█████▌    | 421/750 [08:19<06:27,  1.18s/it]Model Responding:  56%|█████▋    | 422/750 [08:21<06:24,  1.17s/it]Model Responding:  56%|█████▋    | 423/750 [08:22<06:20,  1.16s/it]Model Responding:  57%|█████▋    | 424/750 [08:23<06:17,  1.16s/it]Model Responding:  57%|█████▋    | 425/750 [08:24<06:18,  1.17s/it]Model Responding:  57%|█████▋    | 426/750 [08:25<06:19,  1.17s/it]Model Responding:  57%|█████▋    | 427/750 [08:26<06:22,  1.18s/it]Model Responding:  57%|█████▋    | 428/750 [08:28<06:26,  1.20s/it]Model Responding:  57%|█████▋    | 429/750 [08:29<06:24,  1.20s/it]Model Responding:  57%|█████▋    | 430/750 [08:30<06:21,  1.19s/it]Model Responding:  57%|█████▋    | 431/750 [08:31<06:19,  1.19s/it]Model Responding:  58%|█████▊    | 432/750 [08:32<06:13,  1.17s/it]Model Responding:  58%|█████▊    | 433/750 [08:33<06:08,  1.16s/it]Model Responding:  58%|█████▊    | 434/750 [08:35<06:17,  1.20s/it]Model Responding:  58%|█████▊    | 435/750 [08:36<06:22,  1.21s/it]Model Responding:  58%|█████▊    | 436/750 [08:37<06:23,  1.22s/it]Model Responding:  58%|█████▊    | 437/750 [08:38<06:16,  1.20s/it]Model Responding:  58%|█████▊    | 438/750 [08:40<06:14,  1.20s/it]Model Responding:  59%|█████▊    | 439/750 [08:41<06:10,  1.19s/it]Model Responding:  59%|█████▊    | 440/750 [08:42<06:09,  1.19s/it]Model Responding:  59%|█████▉    | 441/750 [08:43<06:01,  1.17s/it]Model Responding:  59%|█████▉    | 442/750 [08:44<06:00,  1.17s/it]Model Responding:  59%|█████▉    | 443/750 [08:45<06:01,  1.18s/it]Model Responding:  59%|█████▉    | 444/750 [08:47<06:17,  1.23s/it]Model Responding:  59%|█████▉    | 445/750 [08:48<06:10,  1.22s/it]Model Responding:  59%|█████▉    | 446/750 [08:49<06:04,  1.20s/it]Model Responding:  60%|█████▉    | 447/750 [08:50<06:00,  1.19s/it]Model Responding:  60%|█████▉    | 448/750 [08:51<06:00,  1.19s/it]Model Responding:  60%|█████▉    | 449/750 [08:53<05:58,  1.19s/it]Model Responding:  60%|██████    | 450/750 [08:54<05:55,  1.19s/it]Model Responding:  60%|██████    | 451/750 [08:55<05:55,  1.19s/it]Model Responding:  60%|██████    | 452/750 [08:56<05:54,  1.19s/it]Model Responding:  60%|██████    | 453/750 [08:57<05:52,  1.19s/it]Model Responding:  61%|██████    | 454/750 [08:59<05:51,  1.19s/it]Model Responding:  61%|██████    | 455/750 [09:00<05:50,  1.19s/it]Model Responding:  61%|██████    | 456/750 [09:01<05:47,  1.18s/it]Model Responding:  61%|██████    | 457/750 [09:02<05:50,  1.20s/it]Model Responding:  61%|██████    | 458/750 [09:03<05:51,  1.20s/it]Model Responding:  61%|██████    | 459/750 [09:05<05:42,  1.18s/it]Model Responding:  61%|██████▏   | 460/750 [09:06<05:45,  1.19s/it]Model Responding:  61%|██████▏   | 461/750 [09:07<05:42,  1.19s/it]Model Responding:  62%|██████▏   | 462/750 [09:08<05:39,  1.18s/it]Model Responding:  62%|██████▏   | 463/750 [09:09<05:38,  1.18s/it]Model Responding:  62%|██████▏   | 464/750 [09:10<05:38,  1.18s/it]Model Responding:  62%|██████▏   | 465/750 [09:12<05:37,  1.18s/it]Model Responding:  62%|██████▏   | 466/750 [09:13<05:36,  1.19s/it]Model Responding:  62%|██████▏   | 467/750 [09:14<05:39,  1.20s/it]Model Responding:  62%|██████▏   | 468/750 [09:15<05:36,  1.19s/it]Model Responding:  63%|██████▎   | 469/750 [09:16<05:37,  1.20s/it]Model Responding:  63%|██████▎   | 470/750 [09:18<05:36,  1.20s/it]Model Responding:  63%|██████▎   | 471/750 [09:19<05:36,  1.20s/it]Model Responding:  63%|██████▎   | 472/750 [09:20<05:26,  1.18s/it]Model Responding:  63%|██████▎   | 473/750 [09:21<05:26,  1.18s/it]Model Responding:  63%|██████▎   | 474/750 [09:22<05:25,  1.18s/it]Model Responding:  63%|██████▎   | 475/750 [09:24<05:22,  1.17s/it]Model Responding:  63%|██████▎   | 476/750 [09:25<05:26,  1.19s/it]Model Responding:  64%|██████▎   | 477/750 [09:26<05:24,  1.19s/it]Model Responding:  64%|██████▎   | 478/750 [09:27<05:20,  1.18s/it]Model Responding:  64%|██████▍   | 479/750 [09:28<05:21,  1.19s/it]Model Responding:  64%|██████▍   | 480/750 [09:29<05:19,  1.19s/it]Model Responding:  64%|██████▍   | 481/750 [09:31<05:17,  1.18s/it]Model Responding:  64%|██████▍   | 482/750 [09:32<05:16,  1.18s/it]Model Responding:  64%|██████▍   | 483/750 [09:33<05:15,  1.18s/it]Model Responding:  65%|██████▍   | 484/750 [09:34<05:17,  1.19s/it]Model Responding:  65%|██████▍   | 485/750 [09:35<05:20,  1.21s/it]Model Responding:  65%|██████▍   | 486/750 [09:37<05:27,  1.24s/it]Model Responding:  65%|██████▍   | 487/750 [09:38<05:22,  1.22s/it]Model Responding:  65%|██████▌   | 488/750 [09:39<05:18,  1.22s/it]Model Responding:  65%|██████▌   | 489/750 [09:40<05:17,  1.22s/it]Model Responding:  65%|██████▌   | 490/750 [09:42<05:17,  1.22s/it]Model Responding:  65%|██████▌   | 491/750 [09:43<05:07,  1.19s/it]Model Responding:  66%|██████▌   | 492/750 [09:44<05:05,  1.19s/it]Model Responding:  66%|██████▌   | 493/750 [09:45<05:09,  1.20s/it]Model Responding:  66%|██████▌   | 494/750 [09:46<05:11,  1.22s/it]Model Responding:  66%|██████▌   | 495/750 [09:48<05:08,  1.21s/it]Model Responding:  66%|██████▌   | 496/750 [09:49<05:06,  1.21s/it]Model Responding:  66%|██████▋   | 497/750 [09:50<05:04,  1.21s/it]Model Responding:  66%|██████▋   | 498/750 [09:51<05:03,  1.20s/it]Model Responding:  67%|██████▋   | 499/750 [09:52<05:03,  1.21s/it]Model Responding:  67%|██████▋   | 500/750 [09:54<05:02,  1.21s/it]Model Responding:  67%|██████▋   | 501/750 [09:55<05:00,  1.21s/it]Model Responding:  67%|██████▋   | 502/750 [09:56<05:01,  1.22s/it]Model Responding:  67%|██████▋   | 503/750 [09:57<04:52,  1.18s/it]Model Responding:  67%|██████▋   | 504/750 [09:58<04:45,  1.16s/it]Model Responding:  67%|██████▋   | 505/750 [09:59<04:45,  1.17s/it]Model Responding:  67%|██████▋   | 506/750 [10:01<04:45,  1.17s/it]Model Responding:  68%|██████▊   | 507/750 [10:02<04:47,  1.18s/it]Model Responding:  68%|██████▊   | 508/750 [10:03<04:42,  1.17s/it]Model Responding:  68%|██████▊   | 509/750 [10:04<04:45,  1.19s/it]Model Responding:  68%|██████▊   | 510/750 [10:05<04:44,  1.19s/it]Model Responding:  68%|██████▊   | 511/750 [10:07<04:43,  1.19s/it]Model Responding:  68%|██████▊   | 512/750 [10:08<04:40,  1.18s/it]Model Responding:  68%|██████▊   | 513/750 [10:09<04:40,  1.19s/it]Model Responding:  69%|██████▊   | 514/750 [10:10<04:42,  1.20s/it]Model Responding:  69%|██████▊   | 515/750 [10:11<04:35,  1.17s/it]Model Responding:  69%|██████▉   | 516/750 [10:12<04:35,  1.18s/it]Model Responding:  69%|██████▉   | 517/750 [10:14<04:34,  1.18s/it]Model Responding:  69%|██████▉   | 518/750 [10:15<04:34,  1.18s/it]Model Responding:  69%|██████▉   | 519/750 [10:16<04:32,  1.18s/it]Model Responding:  69%|██████▉   | 520/750 [10:17<04:34,  1.19s/it]Model Responding:  69%|██████▉   | 521/750 [10:18<04:31,  1.19s/it]Model Responding:  70%|██████▉   | 522/750 [10:20<04:31,  1.19s/it]Model Responding:  70%|██████▉   | 523/750 [10:21<04:30,  1.19s/it]Model Responding:  70%|██████▉   | 524/750 [10:22<04:28,  1.19s/it]Model Responding:  70%|███████   | 525/750 [10:23<04:27,  1.19s/it]Model Responding:  70%|███████   | 526/750 [10:24<04:28,  1.20s/it]Model Responding:  70%|███████   | 527/750 [10:26<04:40,  1.26s/it]Model Responding:  70%|███████   | 528/750 [10:27<04:32,  1.23s/it]Model Responding:  71%|███████   | 529/750 [10:28<04:29,  1.22s/it]Model Responding:  71%|███████   | 530/750 [10:29<04:20,  1.19s/it]Model Responding:  71%|███████   | 531/750 [10:30<04:22,  1.20s/it]Model Responding:  71%|███████   | 532/750 [10:32<04:21,  1.20s/it]Model Responding:  71%|███████   | 533/750 [10:33<04:20,  1.20s/it]Model Responding:  71%|███████   | 534/750 [10:34<04:18,  1.20s/it]Model Responding:  71%|███████▏  | 535/750 [10:35<04:20,  1.21s/it]Model Responding:  71%|███████▏  | 536/750 [10:37<04:20,  1.22s/it]Model Responding:  72%|███████▏  | 537/750 [10:38<04:18,  1.21s/it]Model Responding:  72%|███████▏  | 538/750 [10:39<04:15,  1.20s/it]Model Responding:  72%|███████▏  | 539/750 [10:40<04:13,  1.20s/it]Model Responding:  72%|███████▏  | 540/750 [10:41<04:12,  1.20s/it]Model Responding:  72%|███████▏  | 541/750 [10:43<04:11,  1.20s/it]Model Responding:  72%|███████▏  | 542/750 [10:44<04:11,  1.21s/it]Model Responding:  72%|███████▏  | 543/750 [10:45<04:09,  1.20s/it]Model Responding:  73%|███████▎  | 544/750 [10:46<04:11,  1.22s/it]Model Responding:  73%|███████▎  | 545/750 [10:47<04:05,  1.20s/it]Model Responding:  73%|███████▎  | 546/750 [10:49<04:03,  1.19s/it]Model Responding:  73%|███████▎  | 547/750 [10:50<04:01,  1.19s/it]Model Responding:  73%|███████▎  | 548/750 [10:51<03:58,  1.18s/it]Model Responding:  73%|███████▎  | 549/750 [10:52<03:58,  1.19s/it]Model Responding:  73%|███████▎  | 550/750 [10:53<03:58,  1.19s/it]Model Responding:  73%|███████▎  | 551/750 [10:55<04:00,  1.21s/it]Model Responding:  74%|███████▎  | 552/750 [10:56<04:02,  1.23s/it]Model Responding:  74%|███████▎  | 553/750 [10:57<03:59,  1.21s/it]Model Responding:  74%|███████▍  | 554/750 [10:58<03:55,  1.20s/it]Model Responding:  74%|███████▍  | 555/750 [10:59<03:52,  1.19s/it]Model Responding:  74%|███████▍  | 556/750 [11:01<03:50,  1.19s/it]Model Responding:  74%|███████▍  | 557/750 [11:02<03:50,  1.19s/it]Model Responding:  74%|███████▍  | 558/750 [11:03<03:50,  1.20s/it]Model Responding:  75%|███████▍  | 559/750 [11:04<03:48,  1.20s/it]Model Responding:  75%|███████▍  | 560/750 [11:05<03:48,  1.20s/it]Model Responding:  75%|███████▍  | 561/750 [11:07<03:50,  1.22s/it]Model Responding:  75%|███████▍  | 562/750 [11:08<03:46,  1.21s/it]Model Responding:  75%|███████▌  | 563/750 [11:09<03:42,  1.19s/it]Model Responding:  75%|███████▌  | 564/750 [11:10<03:41,  1.19s/it]Model Responding:  75%|███████▌  | 565/750 [11:11<03:41,  1.20s/it]Model Responding:  75%|███████▌  | 566/750 [11:13<03:41,  1.20s/it]Model Responding:  76%|███████▌  | 567/750 [11:14<03:39,  1.20s/it]Model Responding:  76%|███████▌  | 568/750 [11:15<03:39,  1.21s/it]Model Responding:  76%|███████▌  | 569/750 [11:16<03:46,  1.25s/it]Model Responding:  76%|███████▌  | 570/750 [11:18<03:42,  1.23s/it]Model Responding:  76%|███████▌  | 571/750 [11:19<03:37,  1.22s/it]Model Responding:  76%|███████▋  | 572/750 [11:20<03:36,  1.22s/it]Model Responding:  76%|███████▋  | 573/750 [11:21<03:35,  1.22s/it]Model Responding:  77%|███████▋  | 574/750 [11:22<03:28,  1.19s/it]Model Responding:  77%|███████▋  | 575/750 [11:23<03:23,  1.16s/it]Model Responding:  77%|███████▋  | 576/750 [11:25<03:22,  1.16s/it]Model Responding:  77%|███████▋  | 577/750 [11:26<03:22,  1.17s/it]Model Responding:  77%|███████▋  | 578/750 [11:27<03:24,  1.19s/it]Model Responding:  77%|███████▋  | 579/750 [11:28<03:19,  1.17s/it]Model Responding:  77%|███████▋  | 580/750 [11:29<03:18,  1.17s/it]Model Responding:  77%|███████▋  | 581/750 [11:30<03:18,  1.18s/it]Model Responding:  78%|███████▊  | 582/750 [11:32<03:17,  1.18s/it]Model Responding:  78%|███████▊  | 583/750 [11:33<03:17,  1.18s/it]Model Responding:  78%|███████▊  | 584/750 [11:34<03:15,  1.18s/it]Model Responding:  78%|███████▊  | 585/750 [11:35<03:17,  1.19s/it]Model Responding:  78%|███████▊  | 586/750 [11:36<03:11,  1.17s/it]Model Responding:  78%|███████▊  | 587/750 [11:37<03:12,  1.18s/it]Model Responding:  78%|███████▊  | 588/750 [11:39<03:10,  1.17s/it]Model Responding:  79%|███████▊  | 589/750 [11:40<03:09,  1.18s/it]Model Responding:  79%|███████▊  | 590/750 [11:41<03:08,  1.18s/it]Model Responding:  79%|███████▉  | 591/750 [11:42<03:07,  1.18s/it]Model Responding:  79%|███████▉  | 592/750 [11:43<03:05,  1.18s/it]Model Responding:  79%|███████▉  | 593/750 [11:45<03:03,  1.17s/it]Model Responding:  79%|███████▉  | 594/750 [11:46<03:04,  1.18s/it]Model Responding:  79%|███████▉  | 595/750 [11:47<03:03,  1.18s/it]Model Responding:  79%|███████▉  | 596/750 [11:48<03:03,  1.19s/it]Model Responding:  80%|███████▉  | 597/750 [11:49<03:00,  1.18s/it]Model Responding:  80%|███████▉  | 598/750 [11:51<03:01,  1.19s/it]Model Responding:  80%|███████▉  | 599/750 [11:52<02:59,  1.19s/it]Model Responding:  80%|████████  | 600/750 [11:53<02:57,  1.18s/it]Model Responding:  80%|████████  | 601/750 [11:54<02:56,  1.18s/it]Model Responding:  80%|████████  | 602/750 [11:55<02:55,  1.19s/it]Model Responding:  80%|████████  | 603/750 [11:56<02:56,  1.20s/it]Model Responding:  81%|████████  | 604/750 [11:58<02:55,  1.20s/it]Model Responding:  81%|████████  | 605/750 [11:59<02:50,  1.18s/it]Model Responding:  81%|████████  | 606/750 [12:00<02:47,  1.16s/it]Model Responding:  81%|████████  | 607/750 [12:01<02:47,  1.17s/it]Model Responding:  81%|████████  | 608/750 [12:02<02:47,  1.18s/it]Model Responding:  81%|████████  | 609/750 [12:03<02:46,  1.18s/it]Model Responding:  81%|████████▏ | 610/750 [12:05<02:51,  1.22s/it]Model Responding:  81%|████████▏ | 611/750 [12:06<02:49,  1.22s/it]Model Responding:  82%|████████▏ | 612/750 [12:07<02:46,  1.21s/it]Model Responding:  82%|████████▏ | 613/750 [12:08<02:43,  1.19s/it]Model Responding:  82%|████████▏ | 614/750 [12:10<02:41,  1.19s/it]Model Responding:  82%|████████▏ | 615/750 [12:11<02:40,  1.19s/it]Model Responding:  82%|████████▏ | 616/750 [12:12<02:36,  1.17s/it]Model Responding:  82%|████████▏ | 617/750 [12:13<02:32,  1.15s/it]Model Responding:  82%|████████▏ | 618/750 [12:14<02:35,  1.18s/it]Model Responding:  83%|████████▎ | 619/750 [12:15<02:34,  1.18s/it]Model Responding:  83%|████████▎ | 620/750 [12:17<02:33,  1.18s/it]Model Responding:  83%|████████▎ | 621/750 [12:18<02:31,  1.18s/it]Model Responding:  83%|████████▎ | 622/750 [12:19<02:31,  1.18s/it]Model Responding:  83%|████████▎ | 623/750 [12:20<02:30,  1.18s/it]Model Responding:  83%|████████▎ | 624/750 [12:21<02:28,  1.18s/it]Model Responding:  83%|████████▎ | 625/750 [12:23<02:29,  1.19s/it]Model Responding:  83%|████████▎ | 626/750 [12:24<02:26,  1.19s/it]Model Responding:  84%|████████▎ | 627/750 [12:25<02:26,  1.19s/it]Model Responding:  84%|████████▎ | 628/750 [12:26<02:25,  1.19s/it]Model Responding:  84%|████████▍ | 629/750 [12:27<02:22,  1.18s/it]Model Responding:  84%|████████▍ | 630/750 [12:28<02:20,  1.17s/it]Model Responding:  84%|████████▍ | 631/750 [12:30<02:19,  1.17s/it]Model Responding:  84%|████████▍ | 632/750 [12:31<02:19,  1.18s/it]Model Responding:  84%|████████▍ | 633/750 [12:32<02:18,  1.18s/it]Model Responding:  85%|████████▍ | 634/750 [12:33<02:17,  1.19s/it]Model Responding:  85%|████████▍ | 635/750 [12:34<02:18,  1.21s/it]Model Responding:  85%|████████▍ | 636/750 [12:36<02:18,  1.21s/it]Model Responding:  85%|████████▍ | 637/750 [12:37<02:17,  1.22s/it]Model Responding:  85%|████████▌ | 638/750 [12:38<02:14,  1.20s/it]Model Responding:  85%|████████▌ | 639/750 [12:39<02:10,  1.18s/it]Model Responding:  85%|████████▌ | 640/750 [12:40<02:09,  1.17s/it]Model Responding:  85%|████████▌ | 641/750 [12:41<02:09,  1.18s/it]Model Responding:  86%|████████▌ | 642/750 [12:43<02:07,  1.18s/it]Model Responding:  86%|████████▌ | 643/750 [12:44<02:05,  1.17s/it]Model Responding:  86%|████████▌ | 644/750 [12:45<02:06,  1.19s/it]Model Responding:  86%|████████▌ | 645/750 [12:46<02:05,  1.20s/it]Model Responding:  86%|████████▌ | 646/750 [12:47<02:03,  1.19s/it]Model Responding:  86%|████████▋ | 647/750 [12:49<02:00,  1.17s/it]Model Responding:  86%|████████▋ | 648/750 [12:50<01:58,  1.16s/it]Model Responding:  87%|████████▋ | 649/750 [12:51<01:56,  1.15s/it]Model Responding:  87%|████████▋ | 650/750 [12:52<01:55,  1.15s/it]Model Responding:  87%|████████▋ | 651/750 [12:53<01:59,  1.21s/it]Model Responding:  87%|████████▋ | 652/750 [12:55<01:59,  1.21s/it]Model Responding:  87%|████████▋ | 653/750 [12:56<01:58,  1.23s/it]Model Responding:  87%|████████▋ | 654/750 [12:57<01:57,  1.22s/it]Model Responding:  87%|████████▋ | 655/750 [12:58<01:56,  1.22s/it]Model Responding:  87%|████████▋ | 656/750 [12:59<01:54,  1.22s/it]Model Responding:  88%|████████▊ | 657/750 [13:01<01:52,  1.21s/it]Model Responding:  88%|████████▊ | 658/750 [13:02<01:50,  1.20s/it]Model Responding:  88%|████████▊ | 659/750 [13:03<01:48,  1.19s/it]Model Responding:  88%|████████▊ | 660/750 [13:04<01:45,  1.17s/it]Model Responding:  88%|████████▊ | 661/750 [13:05<01:45,  1.19s/it]Model Responding:  88%|████████▊ | 662/750 [13:06<01:43,  1.17s/it]Model Responding:  88%|████████▊ | 663/750 [13:08<01:41,  1.16s/it]Model Responding:  89%|████████▊ | 664/750 [13:09<01:41,  1.18s/it]Model Responding:  89%|████████▊ | 665/750 [13:10<01:40,  1.18s/it]Model Responding:  89%|████████▉ | 666/750 [13:11<01:39,  1.18s/it]Model Responding:  89%|████████▉ | 667/750 [13:12<01:38,  1.19s/it]Model Responding:  89%|████████▉ | 668/750 [13:14<01:37,  1.19s/it]Model Responding:  89%|████████▉ | 669/750 [13:15<01:35,  1.17s/it]Model Responding:  89%|████████▉ | 670/750 [13:16<01:36,  1.20s/it]Model Responding:  89%|████████▉ | 671/750 [13:17<01:34,  1.20s/it]Model Responding:  90%|████████▉ | 672/750 [13:18<01:33,  1.19s/it]Model Responding:  90%|████████▉ | 673/750 [13:20<01:31,  1.19s/it]Model Responding:  90%|████████▉ | 674/750 [13:21<01:30,  1.19s/it]Model Responding:  90%|█████████ | 675/750 [13:22<01:29,  1.19s/it]Model Responding:  90%|█████████ | 676/750 [13:23<01:28,  1.19s/it]Model Responding:  90%|█████████ | 677/750 [13:24<01:27,  1.19s/it]Model Responding:  90%|█████████ | 678/750 [13:26<01:26,  1.20s/it]Model Responding:  91%|█████████ | 679/750 [13:27<01:24,  1.19s/it]Model Responding:  91%|█████████ | 680/750 [13:28<01:21,  1.17s/it]Model Responding:  91%|█████████ | 681/750 [13:29<01:19,  1.15s/it]Model Responding:  91%|█████████ | 682/750 [13:30<01:18,  1.16s/it]Model Responding:  91%|█████████ | 683/750 [13:31<01:18,  1.17s/it]Model Responding:  91%|█████████ | 684/750 [13:33<01:18,  1.18s/it]Model Responding:  91%|█████████▏| 685/750 [13:34<01:17,  1.19s/it]Model Responding:  91%|█████████▏| 686/750 [13:35<01:17,  1.21s/it]Model Responding:  92%|█████████▏| 687/750 [13:36<01:15,  1.20s/it]Model Responding:  92%|█████████▏| 688/750 [13:37<01:13,  1.19s/it]Model Responding:  92%|█████████▏| 689/750 [13:39<01:12,  1.19s/it]Model Responding:  92%|█████████▏| 690/750 [13:40<01:12,  1.20s/it]Model Responding:  92%|█████████▏| 691/750 [13:41<01:09,  1.18s/it]Model Responding:  92%|█████████▏| 692/750 [13:42<01:12,  1.25s/it]Model Responding:  92%|█████████▏| 693/750 [13:44<01:10,  1.23s/it]Model Responding:  93%|█████████▎| 694/750 [13:45<01:08,  1.23s/it]Model Responding:  93%|█████████▎| 695/750 [13:46<01:08,  1.24s/it]Model Responding:  93%|█████████▎| 696/750 [13:47<01:07,  1.25s/it]Model Responding:  93%|█████████▎| 697/750 [13:48<01:05,  1.23s/it]Model Responding:  93%|█████████▎| 698/750 [13:50<01:03,  1.22s/it]Model Responding:  93%|█████████▎| 699/750 [13:51<01:01,  1.21s/it]Model Responding:  93%|█████████▎| 700/750 [13:52<01:00,  1.21s/it]Model Responding:  93%|█████████▎| 701/750 [13:53<00:59,  1.21s/it]Model Responding:  94%|█████████▎| 702/750 [13:54<00:57,  1.20s/it]Model Responding:  94%|█████████▎| 703/750 [13:56<00:56,  1.21s/it]Model Responding:  94%|█████████▍| 704/750 [13:57<00:55,  1.21s/it]Model Responding:  94%|█████████▍| 705/750 [13:58<00:54,  1.20s/it]Model Responding:  94%|█████████▍| 706/750 [13:59<00:52,  1.20s/it]Model Responding:  94%|█████████▍| 707/750 [14:00<00:51,  1.20s/it]Model Responding:  94%|█████████▍| 708/750 [14:02<00:50,  1.20s/it]Model Responding:  95%|█████████▍| 709/750 [14:03<00:49,  1.20s/it]Model Responding:  95%|█████████▍| 710/750 [14:04<00:48,  1.21s/it]Model Responding:  95%|█████████▍| 711/750 [14:05<00:47,  1.21s/it]Model Responding:  95%|█████████▍| 712/750 [14:07<00:46,  1.21s/it]Model Responding:  95%|█████████▌| 713/750 [14:08<00:44,  1.20s/it]Model Responding:  95%|█████████▌| 714/750 [14:09<00:42,  1.18s/it]Model Responding:  95%|█████████▌| 715/750 [14:10<00:40,  1.16s/it]Model Responding:  95%|█████████▌| 716/750 [14:11<00:39,  1.17s/it]Model Responding:  96%|█████████▌| 717/750 [14:12<00:38,  1.18s/it]Model Responding:  96%|█████████▌| 718/750 [14:14<00:37,  1.18s/it]Model Responding:  96%|█████████▌| 719/750 [14:15<00:37,  1.21s/it]Model Responding:  96%|█████████▌| 720/750 [14:16<00:36,  1.21s/it]Model Responding:  96%|█████████▌| 721/750 [14:17<00:35,  1.22s/it]Model Responding:  96%|█████████▋| 722/750 [14:18<00:34,  1.22s/it]Model Responding:  96%|█████████▋| 723/750 [14:20<00:32,  1.21s/it]Model Responding:  97%|█████████▋| 724/750 [14:21<00:31,  1.20s/it]Model Responding:  97%|█████████▋| 725/750 [14:22<00:29,  1.20s/it]Model Responding:  97%|█████████▋| 726/750 [14:23<00:28,  1.20s/it]Model Responding:  97%|█████████▋| 727/750 [14:24<00:27,  1.19s/it]Model Responding:  97%|█████████▋| 728/750 [14:26<00:26,  1.20s/it]Model Responding:  97%|█████████▋| 729/750 [14:27<00:25,  1.20s/it]Model Responding:  97%|█████████▋| 730/750 [14:28<00:23,  1.20s/it]Model Responding:  97%|█████████▋| 731/750 [14:29<00:22,  1.19s/it]Model Responding:  98%|█████████▊| 732/750 [14:30<00:21,  1.19s/it]Model Responding:  98%|█████████▊| 733/750 [14:32<00:20,  1.20s/it]Model Responding:  98%|█████████▊| 734/750 [14:33<00:19,  1.25s/it]Model Responding:  98%|█████████▊| 735/750 [14:34<00:18,  1.25s/it]Model Responding:  98%|█████████▊| 736/750 [14:35<00:17,  1.25s/it]Model Responding:  98%|█████████▊| 737/750 [14:37<00:16,  1.23s/it]Model Responding:  98%|█████████▊| 738/750 [14:38<00:14,  1.22s/it]Model Responding:  99%|█████████▊| 739/750 [14:39<00:13,  1.20s/it]Model Responding:  99%|█████████▊| 740/750 [14:40<00:11,  1.20s/it]Model Responding:  99%|█████████▉| 741/750 [14:41<00:10,  1.18s/it]Model Responding:  99%|█████████▉| 742/750 [14:42<00:09,  1.17s/it]Model Responding:  99%|█████████▉| 743/750 [14:44<00:08,  1.18s/it]Model Responding:  99%|█████████▉| 744/750 [14:45<00:07,  1.19s/it]Model Responding:  99%|█████████▉| 745/750 [14:46<00:06,  1.22s/it]Model Responding:  99%|█████████▉| 746/750 [14:47<00:04,  1.19s/it]Model Responding: 100%|█████████▉| 747/750 [14:48<00:03,  1.19s/it]Model Responding: 100%|█████████▉| 748/750 [14:50<00:02,  1.19s/it]Model Responding: 100%|█████████▉| 749/750 [14:51<00:01,  1.19s/it]Model Responding: 100%|██████████| 750/750 [14:52<00:00,  1.19s/it]Model Responding: 100%|██████████| 750/750 [14:52<00:00,  1.19s/it]
Postprocessing:   0%|          | 0/750 [00:00<?, ?it/s]Postprocessing:   2%|▏         | 13/750 [00:00<00:06, 121.87it/s]Postprocessing:   3%|▎         | 26/750 [00:00<00:06, 115.15it/s]Postprocessing:   5%|▌         | 38/750 [00:00<00:06, 116.02it/s]Postprocessing:   7%|▋         | 50/750 [00:00<00:06, 116.37it/s]Postprocessing:   8%|▊         | 63/750 [00:00<00:05, 119.14it/s]Postprocessing:  10%|█         | 75/750 [00:00<00:05, 118.04it/s]Postprocessing:  12%|█▏        | 87/750 [00:00<00:06, 107.46it/s]Postprocessing:  13%|█▎        | 98/750 [00:00<00:06, 100.24it/s]Postprocessing:  15%|█▍        | 112/750 [00:01<00:05, 108.59it/s]Postprocessing:  17%|█▋        | 124/750 [00:01<00:05, 105.43it/s]Postprocessing:  18%|█▊        | 135/750 [00:01<00:06, 100.87it/s]Postprocessing:  19%|█▉        | 146/750 [00:01<00:05, 101.48it/s]Postprocessing:  21%|██        | 157/750 [00:01<00:05, 103.68it/s]Postprocessing:  23%|██▎       | 169/750 [00:01<00:05, 106.04it/s]Postprocessing:  24%|██▍       | 180/750 [00:01<00:05, 104.43it/s]Postprocessing:  25%|██▌       | 191/750 [00:01<00:05, 104.44it/s]Postprocessing:  27%|██▋       | 204/750 [00:01<00:04, 109.74it/s]Postprocessing:  29%|██▊       | 215/750 [00:01<00:05, 106.40it/s]Postprocessing:  31%|███       | 229/750 [00:02<00:04, 114.38it/s]Postprocessing:  32%|███▏      | 241/750 [00:02<00:04, 115.79it/s]Postprocessing:  34%|███▍      | 254/750 [00:02<00:04, 119.00it/s]Postprocessing:  35%|███▌      | 266/750 [00:02<00:04, 118.65it/s]Postprocessing:  37%|███▋      | 278/750 [00:02<00:04, 115.38it/s]Postprocessing:  39%|███▊      | 290/750 [00:02<00:04, 114.05it/s]Postprocessing:  40%|████      | 302/750 [00:02<00:04, 109.98it/s]Postprocessing:  42%|████▏     | 315/750 [00:02<00:03, 114.94it/s]Postprocessing:  44%|████▎     | 327/750 [00:02<00:03, 111.06it/s]Postprocessing:  45%|████▌     | 339/750 [00:03<00:03, 107.41it/s]Postprocessing:  47%|████▋     | 350/750 [00:03<00:03, 102.45it/s]Postprocessing:  48%|████▊     | 361/750 [00:03<00:03, 97.41it/s] Postprocessing:  49%|████▉     | 371/750 [00:03<00:03, 97.13it/s]Postprocessing:  51%|█████     | 382/750 [00:03<00:03, 100.26it/s]Postprocessing:  52%|█████▏    | 393/750 [00:03<00:03, 100.68it/s]Postprocessing:  54%|█████▍    | 404/750 [00:03<00:03, 99.42it/s] Postprocessing:  55%|█████▌    | 416/750 [00:03<00:03, 102.55it/s]Postprocessing:  57%|█████▋    | 427/750 [00:03<00:03, 103.92it/s]Postprocessing:  58%|█████▊    | 438/750 [00:04<00:03, 93.50it/s] Postprocessing:  60%|██████    | 450/750 [00:04<00:03, 99.17it/s]Postprocessing:  61%|██████▏   | 461/750 [00:04<00:03, 95.88it/s]Postprocessing:  63%|██████▎   | 474/750 [00:04<00:02, 102.79it/s]Postprocessing:  65%|██████▍   | 485/750 [00:04<00:02, 102.74it/s]Postprocessing:  66%|██████▋   | 498/750 [00:04<00:02, 109.16it/s]Postprocessing:  68%|██████▊   | 510/750 [00:04<00:02, 105.38it/s]Postprocessing:  69%|██████▉   | 521/750 [00:04<00:02, 102.80it/s]Postprocessing:  71%|███████   | 532/750 [00:05<00:02, 101.66it/s]Postprocessing:  73%|███████▎  | 545/750 [00:05<00:01, 107.42it/s]Postprocessing:  74%|███████▍  | 558/750 [00:05<00:01, 112.90it/s]Postprocessing:  76%|███████▌  | 571/750 [00:05<00:01, 115.58it/s]Postprocessing:  78%|███████▊  | 583/750 [00:05<00:01, 113.15it/s]Postprocessing:  79%|███████▉  | 596/750 [00:05<00:01, 117.36it/s]Postprocessing:  81%|████████  | 608/750 [00:05<00:01, 114.52it/s]Postprocessing:  83%|████████▎ | 620/750 [00:05<00:01, 100.52it/s]Postprocessing:  84%|████████▍ | 631/750 [00:05<00:01, 102.11it/s]Postprocessing:  86%|████████▌ | 644/750 [00:06<00:00, 108.55it/s]Postprocessing:  87%|████████▋ | 656/750 [00:06<00:00, 110.67it/s]Postprocessing:  89%|████████▉ | 668/750 [00:06<00:00, 109.55it/s]Postprocessing:  91%|█████████ | 680/750 [00:06<00:00, 110.34it/s]Postprocessing:  92%|█████████▏| 692/750 [00:06<00:00, 109.84it/s]Postprocessing:  94%|█████████▍| 704/750 [00:06<00:00, 109.30it/s]Postprocessing:  95%|█████████▌| 715/750 [00:06<00:00, 106.05it/s]Postprocessing:  97%|█████████▋| 726/750 [00:06<00:00, 103.39it/s]Postprocessing:  99%|█████████▊| 739/750 [00:06<00:00, 110.60it/s]Postprocessing: 100%|██████████| 750/750 [00:06<00:00, 107.38it/s]
[32m2024-12-26 15:09:14.162[0m | [1mINFO    [0m | [36mlmms_eval.loggers.evaluation_tracker[0m:[36msave_results_aggregated[0m:[36m188[0m - [1mSaving results aggregated[0m
[32m2024-12-26 15:09:14.166[0m | [1mINFO    [0m | [36mlmms_eval.loggers.evaluation_tracker[0m:[36msave_results_samples[0m:[36m255[0m - [1mSaving per-sample results for: pope_pop[0m
llava (pretrained=liuhaotian/llava-v1.6-vicuna-7b), gen_kwargs: (), limit: None, num_fewshot: None, batch_size: 1
| Tasks  |Version|Filter|n-shot|    Metric    |   |Value |   |Stderr|
|--------|-------|------|-----:|--------------|---|-----:|---|------|
|pope_pop|Yaml   |none  |     0|pope_accuracy |↑  |0.8890|±  |   N/A|
|pope_pop|Yaml   |none  |     0|pope_f1_score |↑  |0.8804|±  |   N/A|
|pope_pop|Yaml   |none  |     0|pope_precision|↑  |0.9541|±  |   N/A|
|pope_pop|Yaml   |none  |     0|pope_recall   |↑  |0.8173|±  |   N/A|
|pope_pop|Yaml   |none  |     0|pope_yes_ratio|↑  |0.5000|±  |   N/A|

[rank0]:[W1226 15:09:18.964114257 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
